{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "import time\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "\n",
    "from response_processing import *\n",
    "from article_processing import create_text_dict_from_folder\n",
    "import traceback\n",
    "from file_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-16k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Model model id=gpt-3.5-turbo-16k-0613 at 0x1cd788b7e30> JSON: {\n",
       "   \"created\": 1685474247,\n",
       "   \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1686675077,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-RizYeOCRqav9e70KnCJXhMlS\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-16k-0613\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-0613 at 0x1cd788f08f0> JSON: {\n",
       "   \"created\": 1686587434,\n",
       "   \"id\": \"gpt-3.5-turbo-0613\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1686767378,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-8NTe6DBDMj9BJf9rJ4eKhgoW\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-0613\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo at 0x1cd788f1430> JSON: {\n",
       "   \"created\": 1677610602,\n",
       "   \"id\": \"gpt-3.5-turbo\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1686673921,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-vXDJwtFoZKeqgwuG1i0eRjFl\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-0301 at 0x1cd788f1670> JSON: {\n",
       "   \"created\": 1677649963,\n",
       "   \"id\": \"gpt-3.5-turbo-0301\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1686673945,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-fgf5WqG21QM7pnaHHZRhsqfb\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-0301\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-16k at 0x1cd788f1730> JSON: {\n",
       "   \"created\": 1683758102,\n",
       "   \"id\": \"gpt-3.5-turbo-16k\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai-internal\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1686675077,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-iSLMWKwNcv96M7wUdUk1Xof5\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-16k\"\n",
       " }]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def openai_models(env=\"api_openai\", query='gpt'):\n",
    "    \"\"\"\n",
    "    List the availabel OpenAI models.\n",
    "    Parameters:\n",
    "        - env (str): Name of environmental variable storing the OpenAI API key.\n",
    "        - query (str): Search term for filtering models.\n",
    "    \"\"\"\n",
    "    openai.api_key = os.getenv(env)\n",
    "    response = openai.Model.list()\n",
    "    filtered_models = [model for model in response['data'] if model['id'].find(query) != -1]\n",
    "\n",
    "    for item in filtered_models:\n",
    "        print(item['id'])\n",
    "    return filtered_models\n",
    "\n",
    "openai_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "chain_results_dict = dict()\n",
    "qna_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create text dictionary\n",
    "folder_path = '../text/2023-06-14 2' # ** UPDATE REQUIRED**\n",
    "\n",
    "encoding='ISO-8859-1'\n",
    "subset=None\n",
    "\n",
    "text_dict = create_text_dict_from_folder(folder_path, encoding=encoding, subset=subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and statistics to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, \\\n",
    "    such as age and sex, within the body of the summary. \\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing or redundant. \\\n",
    "    \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\nwhere the summary is a publication-ready format.\\\n",
    "    \\nDo not label the headline and summary.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "user_simplify_task = [\n",
    "    \"\"\"If needed, rewrite the headline and text using terms appropriate for the audience. If not keep it the same.\\\n",
    "    Follow these steps to accomplish this: \\\n",
    "    \\n1. Check if the content and language are appropriate for the audience. \\\n",
    "    \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "    \\n3. Return the final version of the headline and text to be shown to the audience. \\\n",
    "    \\nIt should be in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\n\\nwhere the summary is in paragraph form.\\\n",
    "    \\n4. Remove the backticks. Do not label the headline and summary. \",\n",
    "    \\n\\nYour audience is\"\"\",\n",
    "]\n",
    "\n",
    "simplify_audience = [\n",
    "    # \"a lay audience\",\n",
    "    \"people who are not science experts\",\n",
    "]\n",
    "\n",
    "user_relevance_task = [\n",
    "    \"\"\"Rewrite the headline and text to include a statement of how it is relevant for the audience. \\\n",
    "    Follow these steps to accomplish this: \\\n",
    "    \\n1. Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things, \\\n",
    "    add a sentence to inform the audience. Otherwise, keep it the same. \\\n",
    "    \\n3. Modify the content if needed to reduce redundancy. \\\n",
    "    \\n4. Check if the content and language are appropriate for the audience. \\\n",
    "    If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "    \\n5. Return the final version of the headline and text to be shown to the audience. \\\n",
    "    \\nIt should be in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\n\\nwhere the summary is in paragraph form.\\\n",
    "    \\n6. Remove the backticks. Do not label the headline and summary. \",\n",
    "    \\n\\nYour audience consists of\"\"\",\n",
    "]\n",
    "\n",
    "relevance_audience = [\n",
    "    \"seniors\",\n",
    "    \"people who enjoy sports\",\n",
    "    # \"people new to resistance training\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "chatbot_id: 2\n",
      "n_choices: 1\n",
      "**text1_prompt00\n",
      "simplify_iteration:  1\n",
      "Task: If needed, rewrite the headline and text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \n",
      "1. Check if the content and language are appropriate for the audience.     \n",
      "2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "3. Return the final version of the headline and text to be shown to the audience.     \n",
      "It should be in this format:    \n",
      "<headline>\n",
      "\n",
      "<summary>    \n",
      "\n",
      "where the summary is in paragraph form.    \n",
      "4. Remove the backticks. Do not label the headline and summary. \",\n",
      "    \n",
      "\n",
      "Your audience is people who are not science experts\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to summarize response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "\t\t...Preparing to summarize response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "**text2_prompt00\n",
      "simplify_iteration:  1\n",
      "Task: If needed, rewrite the headline and text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \n",
      "1. Check if the content and language are appropriate for the audience.     \n",
      "2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "3. Return the final version of the headline and text to be shown to the audience.     \n",
      "It should be in this format:    \n",
      "<headline>\n",
      "\n",
      "<summary>    \n",
      "\n",
      "where the summary is in paragraph form.    \n",
      "4. Remove the backticks. Do not label the headline and summary. \",\n",
      "    \n",
      "\n",
      "Your audience is people who are not science experts\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to summarize response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "\t\t...Preparing to summarize response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "chatbot_id: 2\n",
      "n_choices: 1\n",
      "**text1_prompt00\n",
      "relevance_iteration:  1\n",
      "Task: Rewrite the headline and text to include a statement of how it is relevant for the audience.     Follow these steps to accomplish this:     \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,     add a sentence to inform the audience. Otherwise, keep it the same.     \n",
      "3. Modify the content if needed to reduce redundancy.     \n",
      "4. Check if the content and language are appropriate for the audience.     If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "5. Return the final version of the headline and text to be shown to the audience.     \n",
      "It should be in this format:    \n",
      "<headline>\n",
      "\n",
      "<summary>    \n",
      "\n",
      "where the summary is in paragraph form.    \n",
      "6. Remove the backticks. Do not label the headline and summary. \",\n",
      "    \n",
      "\n",
      "Your audience consists of seniors\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "relevance_iteration:  2\n",
      "Task: Rewrite the headline and text to include a statement of how it is relevant for the audience.     Follow these steps to accomplish this:     \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,     add a sentence to inform the audience. Otherwise, keep it the same.     \n",
      "3. Modify the content if needed to reduce redundancy.     \n",
      "4. Check if the content and language are appropriate for the audience.     If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "5. Return the final version of the headline and text to be shown to the audience.     \n",
      "It should be in this format:    \n",
      "<headline>\n",
      "\n",
      "<summary>    \n",
      "\n",
      "where the summary is in paragraph form.    \n",
      "6. Remove the backticks. Do not label the headline and summary. \",\n",
      "    \n",
      "\n",
      "Your audience consists of people who enjoy sports\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "**text2_prompt00\n",
      "relevance_iteration:  1\n",
      "Task: Rewrite the headline and text to include a statement of how it is relevant for the audience.     Follow these steps to accomplish this:     \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,     add a sentence to inform the audience. Otherwise, keep it the same.     \n",
      "3. Modify the content if needed to reduce redundancy.     \n",
      "4. Check if the content and language are appropriate for the audience.     If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "5. Return the final version of the headline and text to be shown to the audience.     \n",
      "It should be in this format:    \n",
      "<headline>\n",
      "\n",
      "<summary>    \n",
      "\n",
      "where the summary is in paragraph form.    \n",
      "6. Remove the backticks. Do not label the headline and summary. \",\n",
      "    \n",
      "\n",
      "Your audience consists of seniors\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "relevance_iteration:  2\n",
      "Task: Rewrite the headline and text to include a statement of how it is relevant for the audience.     Follow these steps to accomplish this:     \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,     add a sentence to inform the audience. Otherwise, keep it the same.     \n",
      "3. Modify the content if needed to reduce redundancy.     \n",
      "4. Check if the content and language are appropriate for the audience.     If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "5. Return the final version of the headline and text to be shown to the audience.     \n",
      "It should be in this format:    \n",
      "<headline>\n",
      "\n",
      "<summary>    \n",
      "\n",
      "where the summary is in paragraph form.    \n",
      "6. Remove the backticks. Do not label the headline and summary. \",\n",
      "    \n",
      "\n",
      "Your audience consists of people who enjoy sports\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance summary given\n",
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNumber of previous relevance prompts (from Chaining attributes): 1.\n",
      "\n",
      "\ttotal_n_prompts_relevance: 2\n",
      "\n",
      "\tn_previous_prompts_relevance (accounting for number of relevance audiences): 0\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNumber of previous relevance prompts (from Chaining attributes): 1.\n",
      "\n",
      "\ttotal_n_prompts_relevance: 2\n",
      "\n",
      "\tn_previous_prompts_relevance (accounting for number of relevance audiences): 0\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance summary', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "\n",
      "original summaries df columns: Index(['date', 'folder', 'article_title', 'choice', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "\n",
      "Merged DataFrame shape: (4, 25)\n",
      "\n",
      "Columns before adding empty columns: ['date', 'folder', 'article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'relevance audience 1', 'add relevance task people who enjoy sports', 'full relevance task people who enjoy sports', 'summary: people who enjoy sports', 'relevance audience 2', 'add relevance task seniors', 'full add relevance task seniors', 'summary: seniors']\n",
      "Inserting empty columns...\n",
      "\tM (12): original summary content rating, N (13): original summary language rating, O (14): top summary, U (20): simple summary content rating, V (21): simple summary language rating, W (22): top simple summary, AB (27): added relevance content rating, AC (28): added relevance language rating, AD (29): top added relevance, \n",
      "** Merged dataframe shape: (4, 34)\n",
      "['A: date', 'B: folder', 'C: article_title', 'D: choice', 'E: system_role', 'F: model', 'G: text', 'H: prep step', 'I: summarization task', 'J: edit task', 'K: full summarization task', 'L: summary', 'M: original summary content rating', 'N: original summary language rating', 'O: top summary', 'P: simple summary choice', 'Q: audience', 'R: simplify task', 'S: full simplify task', 'T: simple summary', 'U: simple summary content rating', 'V: simple summary language rating', 'W: top simple summary', 'X: relevance audience 1', 'Y: add relevance task people who enjoy sports', 'Z: full relevance task people who enjoy sports', 'AA: summary: people who enjoy sports', 'AB: added relevance content rating', 'AC: added relevance language rating', 'AD: top added relevance', 'AE: relevance audience 2', 'AF: add relevance task seniors', 'AG: full add relevance task seniors', 'AH: summary: seniors']\n",
      "Unable to save pickle\n",
      "File saved:  ../text/2023-04-14/batch_Chaining_summaries_2023-06-14_1023.csv\n",
      "Time completed: 2023-06-14 10:23:41.161040\n",
      "\tDataFrame saved as CSV\n",
      "\n",
      "Saving Chaining object (chatbot)...\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Unable to save pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_attributes_2023-06-14_1023.json\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: folder</th>\n",
       "      <th>C: article_title</th>\n",
       "      <th>D: choice</th>\n",
       "      <th>E: system_role</th>\n",
       "      <th>F: model</th>\n",
       "      <th>G: text</th>\n",
       "      <th>H: prep step</th>\n",
       "      <th>I: summarization task</th>\n",
       "      <th>J: edit task</th>\n",
       "      <th>K: full summarization task</th>\n",
       "      <th>L: summary</th>\n",
       "      <th>M: original summary content rating</th>\n",
       "      <th>N: original summary language rating</th>\n",
       "      <th>O: top summary</th>\n",
       "      <th>P: simple summary choice</th>\n",
       "      <th>Q: audience</th>\n",
       "      <th>R: simplify task</th>\n",
       "      <th>S: full simplify task</th>\n",
       "      <th>T: simple summary</th>\n",
       "      <th>U: simple summary content rating</th>\n",
       "      <th>V: simple summary language rating</th>\n",
       "      <th>W: top simple summary</th>\n",
       "      <th>X: relevance audience 1</th>\n",
       "      <th>Y: add relevance task people who enjoy sports</th>\n",
       "      <th>Z: full relevance task people who enjoy sports</th>\n",
       "      <th>AA: summary: people who enjoy sports</th>\n",
       "      <th>AB: added relevance content rating</th>\n",
       "      <th>AC: added relevance language rating</th>\n",
       "      <th>AD: top added relevance</th>\n",
       "      <th>AE: relevance audience 2</th>\n",
       "      <th>AF: add relevance task seniors</th>\n",
       "      <th>AG: full add relevance task seniors</th>\n",
       "      <th>AH: summary: seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-14 1023</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\\...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Resistance Exercise Has Similar Recovery Response in Young and Middle-Aged Men\\n\\nThis study exa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>Resistance Exercise Has Similar Recovery Response in Young and Middle-Aged Men\\n\\nThis recent st...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Resistance Training Helps Middle-Aged Men Recover from Exercise\\n\\nA recent study found that mid...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Resistance Training Can Help Seniors Maintain Exercise Recovery Response, Study Finds\\n\\nA recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-14 1023</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\\...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Resistance Training May Help Maintain Recovery Response in Middle-Aged Adults\\n\\nThis study comp...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>Resistance Training May Help Middle-Aged Adults Maintain Muscle Recovery\\n\\nA recent study compa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Resistance Training Helps Middle-Aged Adults Maintain Muscle Recovery Response\\n\\nRegular resist...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Resistance Training May Help Seniors Maintain Muscle Recovery Response\\n\\nThis study found that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-14 1023</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Recovery from Eccentric Squat Exercise in Young and Master Athletes: Combining Cold Water Immers...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>Recovery from Squat Exercise: How Cold Water Immersion and Compression Help Young and Older Athl...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Recovery from Squat Exercise: How Cold Water Immersion and Compression Affect Muscle Soreness an...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Recovery from Squat Exercise in Older Athletes: Combining Cold Water Immersion and Compression\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-14 1023</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...</td>\n",
       "      <td>Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...</td>\n",
       "      <td>Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A: date   B: folder  \\\n",
       "0  2023-06-14 1023  2023-04-14   \n",
       "1  2023-06-14 1023  2023-04-14   \n",
       "2  2023-06-14 1023  2023-04-14   \n",
       "3  2023-06-14 1023  2023-04-14   \n",
       "\n",
       "                                                                                      C: article_title  \\\n",
       "0      Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "1      Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "2  Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...   \n",
       "3  Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...   \n",
       "\n",
       "   D: choice  \\\n",
       "0          1   \n",
       "1          2   \n",
       "2          1   \n",
       "3          2   \n",
       "\n",
       "                                                             E: system_role  \\\n",
       "0  You are a journalist writing content based on science research articles.   \n",
       "1  You are a journalist writing content based on science research articles.   \n",
       "2  You are a journalist writing content based on science research articles.   \n",
       "3  You are a journalist writing content based on science research articles.   \n",
       "\n",
       "        F: model  \\\n",
       "0  gpt-3.5-turbo   \n",
       "1  gpt-3.5-turbo   \n",
       "2  gpt-3.5-turbo   \n",
       "3  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                               G: text  \\\n",
       "0  Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\\...   \n",
       "1  Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\\...   \n",
       "2  Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...   \n",
       "3  Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Simi...   \n",
       "\n",
       "                                                                                          H: prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "            I: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                                          J: edit task  \\\n",
       "0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "2  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "3  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "\n",
       "                                                                            K: full summarization task  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                            L: summary  \\\n",
       "0  Resistance Exercise Has Similar Recovery Response in Young and Middle-Aged Men\\n\\nThis study exa...   \n",
       "1  Resistance Training May Help Maintain Recovery Response in Middle-Aged Adults\\n\\nThis study comp...   \n",
       "2  Recovery from Eccentric Squat Exercise in Young and Master Athletes: Combining Cold Water Immers...   \n",
       "3  Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...   \n",
       "\n",
       "  M: original summary content rating N: original summary language rating  \\\n",
       "0                                                                          \n",
       "1                                                                          \n",
       "2                                                                          \n",
       "3                                                                          \n",
       "\n",
       "  O: top summary P: simple summary choice                         Q: audience  \\\n",
       "0                                       1  people who are not science experts   \n",
       "1                                       1  people who are not science experts   \n",
       "2                                       1  people who are not science experts   \n",
       "3                                       1  people who are not science experts   \n",
       "\n",
       "                                                                                      R: simplify task  \\\n",
       "0  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "1  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "2  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "3  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "\n",
       "                                                                                 S: full simplify task  \\\n",
       "0  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "1  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "2  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "3  If needed, rewrite the headline and text using terms appropriate for the audience. If not keep i...   \n",
       "\n",
       "                                                                                     T: simple summary  \\\n",
       "0  Resistance Exercise Has Similar Recovery Response in Young and Middle-Aged Men\\n\\nThis recent st...   \n",
       "1  Resistance Training May Help Middle-Aged Adults Maintain Muscle Recovery\\n\\nA recent study compa...   \n",
       "2  Recovery from Squat Exercise: How Cold Water Immersion and Compression Help Young and Older Athl...   \n",
       "3  Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...   \n",
       "\n",
       "  U: simple summary content rating V: simple summary language rating  \\\n",
       "0                                                                      \n",
       "1                                                                      \n",
       "2                                                                      \n",
       "3                                                                      \n",
       "\n",
       "  W: top simple summary  X: relevance audience 1  \\\n",
       "0                        people who enjoy sports   \n",
       "1                        people who enjoy sports   \n",
       "2                        people who enjoy sports   \n",
       "3                        people who enjoy sports   \n",
       "\n",
       "                                                         Y: add relevance task people who enjoy sports  \\\n",
       "0  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "1  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "2  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "3  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "\n",
       "                                                        Z: full relevance task people who enjoy sports  \\\n",
       "0  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "1  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "2  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "3  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "\n",
       "                                                                  AA: summary: people who enjoy sports  \\\n",
       "0  Resistance Training Helps Middle-Aged Men Recover from Exercise\\n\\nA recent study found that mid...   \n",
       "1  Resistance Training Helps Middle-Aged Adults Maintain Muscle Recovery Response\\n\\nRegular resist...   \n",
       "2  Recovery from Squat Exercise: How Cold Water Immersion and Compression Affect Muscle Soreness an...   \n",
       "3  Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...   \n",
       "\n",
       "  AB: added relevance content rating AC: added relevance language rating  \\\n",
       "0                                                                          \n",
       "1                                                                          \n",
       "2                                                                          \n",
       "3                                                                          \n",
       "\n",
       "  AD: top added relevance AE: relevance audience 2  \\\n",
       "0                                          seniors   \n",
       "1                                          seniors   \n",
       "2                                          seniors   \n",
       "3                                          seniors   \n",
       "\n",
       "                                                                        AF: add relevance task seniors  \\\n",
       "0  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "1  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "2  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "3  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "\n",
       "                                                                   AG: full add relevance task seniors  \\\n",
       "0  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "1  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "2  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "3  Rewrite the headline and text to include a statement of how it is relevant for the audience.    ...   \n",
       "\n",
       "                                                                                  AH: summary: seniors  \n",
       "0  Resistance Training Can Help Seniors Maintain Exercise Recovery Response, Study Finds\\n\\nA recen...  \n",
       "1  Resistance Training May Help Seniors Maintain Muscle Recovery Response\\n\\nThis study found that ...  \n",
       "2  Recovery from Squat Exercise in Older Athletes: Combining Cold Water Immersion and Compression\\n...  \n",
       "3  Master Athletes Recover Similar to Young Athletes After Intensive Squat Exercise, According to S...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance summary': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=''\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    chatbot_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    chatbot_id = chatbot_id if chatbot_id else iteration_id\n",
    "    print('chatbot_id:', chatbot_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results(\n",
    "    chatbot_dict, qna_dict, iteration_id, relevance_audiences=1,\n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].n_previous_prompts['simple_summary']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].n_previous_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts (from Chaining attributes): {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            try:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "            except:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[str(prompt_number)]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "\n",
    "        print(f'\\n\\ttotal_n_prompts_relevance: {total_n_prompts_relevance}')\n",
    "        print(f'\\n\\tn_previous_prompts_relevance (accounting for number of relevance audiences): {total_n_prompts_relevance - relevance_audiences}')\n",
    "        for prompt_number_relevance in range(total_n_prompts_relevance - relevance_audiences +1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            try:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "            except:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[str(prompt_number_relevance)]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = create_qna_df(qna_dict, chatbot_dict, iteration_id, chatbot_id)[iteration_id]\n",
    "    \n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "    try:\n",
    "        qna_df['date'] = pd.Series(\n",
    "            f'{datetime.now().strftime(\"%Y-%m-%d %H%M\")}', index=qna_dict[iteration_id].index)\n",
    "    except:\n",
    "        print('\\tKeeping original summary time stamp')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "    print(f'\\noriginal summaries df columns: {qna_df.columns}\\n')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_column_names = [\n",
    "            'date',\n",
    "            'folder',\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            'edit task',\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance summary\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_column_names = [\n",
    "            'date',\n",
    "            'folder',\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            'edit task',\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance audience 1\",\n",
    "            \"relevance task\",\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance summary',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results[f'full relevance task {relevance_audience_list[0]}'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results[f'add relevance task {relevance_audience_list[1]}'] = new_results[\"relevance task\"]\n",
    "        new_results[f'full add relevance task {relevance_audience_list[1]}'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        new_results['relevance audience 1'] = pd.Series(relevance_audience_list[0], index=new_results.index)\n",
    "        new_results['relevance audience 2'] = pd.Series(relevance_audience_list[1], index=new_results.index)\n",
    "        spreadsheet_column_names.append(f'full relevance task {relevance_audience_list[0]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[0])\n",
    "        spreadsheet_column_names.append('relevance audience 2')\n",
    "        spreadsheet_column_names.append(f'add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(f'full add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_column_names]\n",
    "    new_results.rename(columns={\n",
    "        'relevance task': f'add relevance task {relevance_audience_list[0]}' if pivot==True else 'relevance task',\n",
    "        relevance_audience_list[0]: f'summary: {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[1]: f'summary: {relevance_audience_list[1]}',\n",
    "    }, inplace=True)\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    \"original summary content rating\": \"M\",\n",
    "                    \"original summary language rating\": \"N\",\n",
    "                    \"top summary\": \"O\",\n",
    "                    \"simple summary content rating\": \"U\",\n",
    "                    \"simple summary language rating\": \"V\",\n",
    "                    'top simple summary': 'W',\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    \"original summary content rating\": \"M\",\n",
    "                    \"original summary language rating\": \"N\",\n",
    "                    \"top summary\": \"O\",\n",
    "                    \"simple summary content rating\": \"U\",\n",
    "                    \"simple summary language rating\": \"V\",\n",
    "                    'top simple summary': 'W',\n",
    "                    'added relevance content rating': 'AB',\n",
    "                    'added relevance language rating': 'AC',\n",
    "                    'top added relevance': 'ad',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_column_names = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_column_names)}\n",
    "        for column_name in empty_columns:\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()]\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_column_names[index]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    qna_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return qna_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "# chatbot_id = 0\n",
    "save_outputs = False\n",
    "save = True\n",
    "save = False\n",
    "empty_columns = True\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Merge the results\n",
    "# try:\n",
    "#     qna_dict = merge_all_chaining_results(\n",
    "#         chatbot_dict, qna_dict, iteration_id=iteration_id, relevance_audiences=2, pivot=True,\n",
    "#         empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         save_df=save, save_chatbot=save, \n",
    "#             csv_path=folder_path,\n",
    "#     )\n",
    "#     print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "# except Exception as error:\n",
    "#     exc_type, exc_obj, tb = sys.exc_info()\n",
    "#     f = tb.tb_frame\n",
    "#     lineno = tb.tb_lineno\n",
    "#     file = f.f_code.co_filename\n",
    "#     print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "#     print('Unable to merge results')\n",
    "#     if save:\n",
    "#         save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "#         print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "\n",
    "# qna_dict = merge_all_chaining_results2(\n",
    "#     chatbot_dict, qna_dict, iteration_id=iteration_id, relevance_audiences=2, pivot=True,\n",
    "#     empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         csv_path=folder_path,\n",
    "# )\n",
    "# print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "qna_dict[iteration_id]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
