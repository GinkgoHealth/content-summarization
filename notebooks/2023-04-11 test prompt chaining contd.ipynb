{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize  \n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\src\")\n",
    "from silvhua import *\n",
    "from datetime import datetime\n",
    "# import json\n",
    "# from plotly.subplots import make_subplots\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from summarization import Chatbot, reply, batch_reply\n",
    "from article_processing import create_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "# from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text1 = \"\"\"Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17β-estradiol and progesterone) throughout the menstrual cycle may influence a woman’s pain sensitivity, as well as hydration levels, suggesting possible interactions between hypohydration and menstrual phase on pain. We investigated the effects of mild hypohydration (HYPO, 24 h of fluid restriction) on ischemic pain sensitivity in 14 eumenorrheic women during the early follicular (EF) and mid-luteal (ML) phases of their menstrual cycle. We also examined whether acute water ingestion could reverse the negative effects of hypohydration. Elevated serum osmolality, plasma copeptin, and urine specific gravity indicated mild hypohydration. Compared with euhydration, HYPO reduced pain tolerance (by 34 ± 46 s; P = 0.02, η2p\n",
    "\n",
    "Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17β-estradiol and progesterone) throughout the menstrual cycle may influence a woman’s pain sensitivity, as well as hydration levels, suggesting possible interactions between hypohydration and menstrual phase on pain. We investigated the effects of mild hypohydration (HYPO, 24 h of fluid restriction) on ischemic pain sensitivity in 14 eumenorrheic women during the early follicular (EF) and mid-luteal (ML) phases of their menstrual cycle. We also examined whether acute water ingestion could reverse the negative effects of hypohydration. Elevated serum osmolality, plasma copeptin, and urine specific gravity indicated mild hypohydration. Compared with euhydration, HYPO reduced pain tolerance (by 34 ± 46 s; P = 0.02, η2p\n",
    " = 0.37) and increased ratings of pain intensity (by 0.7 ± 0.7 cm; P = 0.004; η2p\n",
    " = 0.55) and unpleasantness (by 0.7 ± 0.9 cm; P = 0.02; η2p\n",
    " = 0.40); these results were not influenced by menstrual phase. Water ingestion reduced thirst perception (visual analog scale, by 2.3 ± 0.9 cm; P < 0.001, η2p\n",
    " = 0.88) but did not reduce pain sensitivity. Therefore, hypohydration increases pain sensitivity in women with no influence of menstrual phase.\n",
    "\"\"\"\n",
    "\n",
    "test_text2 = \"\"\"Daily Energy Expenditure through the Human Life Course\n",
    "\n",
    "Total daily energy expenditure (“total expenditure”, MJ/d) reflects daily energy needs and is a critical variable in human health and physiology, yet it is unclear how daily expenditure changes over the life course. Here, we analyze a large, globally diverse database of total expenditure measured by the doubly labeled water method for males and females aged 8 days to 95 yr. We show that total expenditure is strongly related to fat free mass in a power-law manner and identify four distinct metabolic life stages. Fat free mass-adjusted daily expenditure accelerates rapidly in neonates (0-1yr) to ~46% above adult values at ~1 yr, declines slowly throughout childhood and adolescence (1-20 yr) to adult levels at ~20 yr, remains stable in adulthood (20-60 yr) even during pregnancy, and declines in older adults (60+ yr). These changes in total expenditure shed new light on human development and aging and should help shape nutrition and health strategies across the lifespan.\n",
    "\"\"\"\n",
    "\n",
    "test_text_dict = create_text_dict([test_text1, test_text2])\n",
    "test_text_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>task part 1</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Take the key points and numerical descriptors to</td>\n",
       "      <td>Summarize for a LinkedIn post</td>\n",
       "      <td>Take the key points and numerical descriptors to Summarize for a LinkedIn post.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prep_step  \\\n",
       "0  Take the key points and numerical descriptors to   \n",
       "\n",
       "                     task part 1  \\\n",
       "0  Summarize for a LinkedIn post   \n",
       "\n",
       "                                                                            prompt  \n",
       "0  Take the key points and numerical descriptors to Summarize for a LinkedIn post.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "prompts_dict = dict()\n",
    "experiment_num = 1\n",
    "\n",
    "prep_step = [\n",
    "    # \"Take the key points to\",\n",
    "    \"Take the key points and numerical descriptors to\",\n",
    "    # \"\"\n",
    "]\n",
    "\n",
    "task_part1 = [\n",
    "    # \"Summarize the article in under 300 characters\",\n",
    "    \"Summarize for a LinkedIn post\",\n",
    "    # \"Summarize for a tweet\",\n",
    "    # \"Summarize in an engaging way\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\"\n",
    "    # \"Summarize the article for a Tiktok post\"\n",
    "]\n",
    "audience = [\n",
    "    # \"lay audience\",\n",
    "    # \"\",\n",
    "    \"seniors\",\n",
    "    # \"people who enjoy sports\"\n",
    "]\n",
    "task_part2 = [\n",
    "    \"\",\n",
    "    \"Use terms a 12-year-old can understand.\",\n",
    "    # \"Assume your audience has no science background.\"\n",
    "    # \"Include the most interesting findings.\",\n",
    "    # \"Include the key take-aways for the reader.\",\n",
    "    # \"Include the implications of the article.\"\n",
    "]\n",
    "\n",
    "task_part3 =[\n",
    "    \"Add 1-2 sentences to make this relevant for\"\n",
    "    # \"Add 1-2 sentences to make this relevant for older adults.\"\n",
    "    # \"Once you are done, add 1-2 sentences to make this relevant for older adults.\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "prompts_df = pd.DataFrame(product(prep_step, task_part1, task_part2, task_part3, audience), \n",
    "    columns=['prep_step', 'task part 1', 'task part 2', 'task part 3', 'audience'])\n",
    "\n",
    "prompts_df = pd.DataFrame(product(prep_step, task_part1), \n",
    "    columns=['prep_step', 'task part 1'])\n",
    "\n",
    "\n",
    "prompts_df['prompt'] = prompts_df.apply(\n",
    "    lambda row: f\"{row['prep_step']} {row['task part 1']}.\", \n",
    "    axis=1)\n",
    "# prompts_df['simplify'] = prompts_df.apply(\n",
    "#     lambda row: f\" {row['task part 2'] if row['task part 2'] else ''}\", \n",
    "#     axis=1)\n",
    "# prompts_df['relevance'] = prompts_df.apply(\n",
    "#     lambda row: f\" {row['task part 3']} {row['audience']} \" if row['audience'] else '', \n",
    "#     axis=1) \n",
    "prompts_dict[experiment_num] = prompts_df\n",
    "prompts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\t**API request failed**\n",
      "\t...Success!\n",
      "temp_qna_dict index: RangeIndex(start=0, stop=2, step=1)\n",
      "**Text #2 prompt #0 of 0**\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "temp_qna_dict index: Index(['article_title', 'model', 'prompt', 'response_01', 'response_02',\n",
      "       'system_role', 'text'],\n",
      "      dtype='object')\n",
      "Error concatenating DataFrames\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Chaining:\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "\n",
    "    def summarize(self, task, model=\"gpt-3.5-turbo\", temperature=0.7, n_choices=5, max_tokens=1000,\n",
    "          text_key=['text_discussion'],\n",
    "        system_role = \"You are an expert at science communication.\"\n",
    "        ):\n",
    "        \"\"\"\n",
    "        SH 2023-04-11 12:18: Same as the user-defined `reply` function, but re-written as a class method.\n",
    "        Send a ChatCompletion request to ChatGPT via the Chatbot class.\n",
    "\n",
    "        Requrired paramaters:\n",
    "            - task (str): Task to include in ChatGPT prompt.\n",
    "            - text (str): Text to feed to GPT for summarization.\n",
    "\n",
    "        Optional parameters\n",
    "            - system_role (str): ChatGPT parameter. \n",
    "                Default is \"You are an expert at science communication.\"\n",
    "            - temperature (float): ChatGPT parameter. Default is 0.7.\n",
    "            - n_choices (int): Number of ChatGPT responses to generate. Default is 5.\n",
    "            - max_tokens (int): Token limit for ChatGPT response.\n",
    "            - model (str): ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "        \"\"\"\n",
    "        chatbot = Chatbot(self.text,\n",
    "            system_role=system_role, model=model, temperature=temperature, n_choices=n_choices,\n",
    "            max_tokens=max_tokens\n",
    "            )\n",
    "        prompt = chatbot.create_prompt(task)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() # use an ordered dictionary instead of a regular dictionary\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = system_role\n",
    "        self.qna['prompt'] = task\n",
    "        self.qna['model'] = model\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt)\n",
    "        except:\n",
    "            print('\\t**API request failed**')\n",
    "            return self.qna, chatbot\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.qna[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna[f'text'] = self.text\n",
    "            return self.qna\n",
    "        except:\n",
    "            print('\\t**Error with response parsing**')\n",
    "            return self.qna\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, system_role='You are an expert at science communication.',\n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, max_tokens=1000, \n",
    "                    simplify_iteration=None\n",
    "                    ):\n",
    "        self.simplify_bot_dict = dict()\n",
    "        self.simple_summary_dict = dict()\n",
    "        for key, summary in self.summaries_dict.items():\n",
    "            new_key = re.sub(r'response', rf'simple_summary{str(simplify_iteration)}', key)\n",
    "            self.simplify_bot_dict[new_key] = Chatbot(\n",
    "                summary, system_role=system_role,\n",
    "                model=model, temperature=temperature, n_choices=n_choices, max_tokens=max_tokens\n",
    "                )\n",
    "            simplify_prompt = self.simplify_bot_dict[new_key].create_prompt(simplify_task)\n",
    "            try:\n",
    "                self.simple_summary_dict[new_key] = self.simplify_bot_dict[new_key].gpt(simplify_prompt).choices[0][\"message\"][\"content\"]\n",
    "                print(f'\\t...Summary given')\n",
    "            except:\n",
    "                self.simple_summary_dict[new_key] = self.simplify_bot_dict[new_key].gpt(simplify_prompt)\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "        self.simple_summary_dict['simplify_task'] = simplify_task\n",
    "        self.qna = {**self.qna, **self.simple_summary_dict}\n",
    "        self.qna.update({'text': self.qna.pop('text')})\n",
    "        return self.simple_summary_dict\n",
    "\n",
    "def batch_summarize_chain(text_dict, prompts_df, qna_dict,  chatbot_dict, iteration_id, n_choices=5,\n",
    "    prompt_column='prompt',\n",
    "    save_outputs=False, filename=None, append_version=False,\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - prompts_df: DataFrame containing the prompts.\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "        - prompt_column (str): Name of the column in the prompts_df containing the user input.\n",
    "\n",
    "    \"\"\"\n",
    "    temp_qna_dict = dict()\n",
    "    prompts_df = prompts_df.reset_index(drop=True)\n",
    "    qna_dfs_list = []\n",
    "    chatbot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        temp_qna_dict[key] = OrderedDict()\n",
    "        for index, input in prompts_df[prompt_column].items():\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            try:\n",
    "                chatbot = Chaining(text)\n",
    "                temp_qna_dict[key][index] = chatbot.summarize(input, n_choices=n_choices)\n",
    "                chatbot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "            except:\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "        try:\n",
    "            prompts_df = prompts_df.drop([prompt_column, 'system_role'])\n",
    "        except:\n",
    "            pass\n",
    "        print('temp_qna_dict index:', pd.DataFrame(temp_qna_dict[key]).index)\n",
    "        try:\n",
    "            updated_qna_dict = pd.concat([\n",
    "                pd.DataFrame(temp_qna_dict[key]),\n",
    "                prompts_df.transpose()\n",
    "            ])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('Error concatenating prompts DataFrame')\n",
    "            return temp_qna_dict, chatbot_dict\n",
    "        try:\n",
    "            qna_dfs_list.append(updated_qna_dict)\n",
    "            qna_dict[iteration_id] = pd.concat(qna_dfs_list, axis=1)\n",
    "            if save_outputs:\n",
    "                try:\n",
    "                    append_version = append_version if filename else False\n",
    "                    filename = filename if filename else f'{datetime.now().strftime(\"%Y-%m-%d_%H%M\")}_prompt_experiments_{\"{:02d}\".format(iteration_id)}'\n",
    "                    savepickle(qna_dict[iteration_id], filename=filename, path=pickle_path, append_version=append_version)\n",
    "                    save_csv(qna_dict[iteration_id], filename=filename, path=pickle_path, append_version=append_version)\n",
    "                except:\n",
    "                    print('Unable to save outputs')\n",
    "        except:\n",
    "            print('Error concatenating DataFrames')\n",
    "    return qna_dict, chatbot_dict\n",
    "\n",
    "def simplify_chaining_dict(simplify_prompts, qna_chain_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None,\n",
    "    prompt_column='simplify', simplify_iteration=None\n",
    "    ):\n",
    "\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    simple_summaries_dict = dict()\n",
    "    if type(simplify_prompts) == str:\n",
    "        simplify_prompts = [simplify_prompts]\n",
    "    elif type(simplify_prompts) == pd.core.frame.DataFrame:\n",
    "        simplify_prompts = [prompt for prompt in simplify_prompts[prompt_column].unique() if len(prompt) >1]\n",
    "    else:\n",
    "        simplify_prompts = [prompt for prompt in simplify_prompts if len(prompt) >1]\n",
    "    for text_prompt_key in chaining_bot_dict:\n",
    "        print(f'**{text_prompt_key}')\n",
    "        summary_keys = [key for key in chaining_bot_dict[text_prompt_key].qna if 'response' in key]\n",
    "\n",
    "        for summary_key in summary_keys:\n",
    "            print(f'\\tSimplifying {summary_key}...')\n",
    "            for index, prompt in enumerate(simplify_prompts):\n",
    "                print(f'\\t...Prompt: {prompt}')\n",
    "                simple_summaries_dict[index] = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, \n",
    "                    simplify_iteration=index if len(simplify_prompts) > 1 else simplify_iteration\n",
    "                    )\n",
    "        try:\n",
    "            temp_qna_chain_dict = pd.concat([qna_chain_dict[summary_iteration_id], pd.DataFrame(simple_summaries_dict)])\n",
    "            qna_chain_dict[iteration_id] = temp_qna_chain_dict\n",
    "            print('Simple summaries added to original DataFrame')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('Unable to concatenate simple summary DataFrame to original DataFrame')\n",
    "            qna_chain_dict[iteration_id] = simple_summaries_dict\n",
    "\n",
    "    return qna_chain_dict\n",
    "\n",
    "\n",
    "\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "qna_dict = dict()\n",
    "qna_chain_dict = dict()\n",
    "chatbot_dict = dict()\n",
    "\n",
    "qna_dict, chaining_dict = batch_summarize_chain(test_text_dict, prompts_df, qna_dict, chatbot_dict, \n",
    "    iteration_id=iteration_id, n_choices=n_choices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'article_title': 'Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17β-estradiol and progesterone) throughout the menstrual cycle may influence a woman’s pain sensitivity, as well as hydration levels, suggesting possible interactions between hypohydration and menstrual phase on pain. We investigated the effects of mild hypohydration (HYPO, 24 h of fluid restriction) on ischemic pain sensitivity in 14 eumenorrheic women during the early follicular (EF) and mid-luteal (ML) phases of their menstrual cycle. We also examined whether acute water ingestion could reverse the negative effects of hypohydration. Elevated serum osmolality, plasma copeptin, and urine specific gravity indicated mild hypohydration. Compared with euhydration, HYPO reduced pain tolerance (by 34 ± 46 s; P = 0.02, η2p', 'system_role': 'You are an expert at science communication.', 'prompt': 'Take the key points and numerical descriptors to Summarize for a LinkedIn post.', 'model': 'gpt-3.5-turbo'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;summarization.Chatbot object at 0x000001EEF6D555B0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_step</th>\n",
       "      <td>Take the key points and numerical descriptors to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task part 1</th>\n",
       "      <td>Summarize for a LinkedIn post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <td>Take the key points and numerical descriptors to Summarize for a LinkedIn post.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n",
       "0            {'article_title': 'Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17β-estradiol and progesterone) throughout the menstrual cycle may influence a woman’s pain sensitivity, as well as hydration levels, suggesting possible interactions between hypohydration and menstrual phase on pain. We investigated the effects of mild hypohydration (HYPO, 24 h of fluid restriction) on ischemic pain sensitivity in 14 eumenorrheic women during the early follicular (EF) and mid-luteal (ML) phases of their menstrual cycle. We also examined whether acute water ingestion could reverse the negative effects of hypohydration. Elevated serum osmolality, plasma copeptin, and urine specific gravity indicated mild hypohydration. Compared with euhydration, HYPO reduced pain tolerance (by 34 ± 46 s; P = 0.02, η2p', 'system_role': 'You are an expert at science communication.', 'prompt': 'Take the key points and numerical descriptors to Summarize for a LinkedIn post.', 'model': 'gpt-3.5-turbo'}\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <summarization.Chatbot object at 0x000001EEF6D555B0>\n",
       "prep_step                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Take the key points and numerical descriptors to\n",
       "task part 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Summarize for a LinkedIn post\n",
       "prompt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Take the key points and numerical descriptors to Summarize for a LinkedIn post."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
