{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 rows to the database...\n",
      "\ttitle 1\n",
      "\ttitle 2\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric, Boolean\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class GPT_queue(Base):\n",
    "    __tablename__ = 'gpt_queue'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    body = mapped_column(Text)\n",
    "    sent_to_sources = mapped_column(Boolean)\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'gpt_queue':\n",
    "                    data = GPT_queue(\n",
    "                        title=row['title'],\n",
    "                        body=row['body']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "                elif table == 'feed':\n",
    "                    source = session.query(Feed).filter_by(\n",
    "                        title=row['title'],\n",
    "                        journal=row['journal'],\n",
    "                        doi=row['doi']\n",
    "                    ).first()\n",
    "                    if source:\n",
    "                        print(f'\\tAlready exists in the database: {row[\"title\"]}.')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "iteration = 1\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article'],\n",
    "    2: ['title 2', 'this is the body of the second article']\n",
    "}, index=['title', 'body']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 rows to the database...\n",
      "\ttitle 3\n",
      "\ttitle 4\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "iteration = 2\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 3', 'this is the body'],\n",
    "    2: ['title 4', 'this is the body']\n",
    "}, index=['title', 'body']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 rows to the database...\n",
      "\ttitle 5\n",
      "\ttitle 6\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "iteration = 2.1\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 5', 'this is the body'],\n",
    "    2: ['title 6', 'this is the body']\n",
    "}, index=['title', 'body']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1 rows to the database...\n",
      "\tTrends in Self-Reported Adherence to Healthy Lifestyle Behaviors\n",
      "Data added successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trends in Self-Reported Adherence to Healthy L...</td>\n",
       "      <td>Key Points\\nQuestion  What were trends in life...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Trends in Self-Reported Adherence to Healthy L...   \n",
       "\n",
       "                                                body  \n",
       "0  Key Points\\nQuestion  What were trends in life...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = [\n",
    "    'Trends in Self-Reported Adherence to Healthy Lifestyle Behaviors',\n",
    "]\n",
    "body = [\n",
    "    \"\"\"Key Points\n",
    "Question  What were trends in lifestyle factors among US adults from the 1999-2000 cycle to the combined 2017 to March 2020 cycle of the National Health and Nutrition Examination Survey?\n",
    "\n",
    "Findings  In this cross-sectional study including 47 852 adults, improvements were observed in smoking habits, diet quality, and physical activity levels, but with a decrease in healthy weight and no significant change in moderate or less alcohol consumption. Overall, the prevalence of having at least 4 factors at a healthy level increased from 16% to 20%, but with worsening disparities by age group and persistent disparities by race and ethnicity and socioeconomic level.\n",
    "\n",
    "Meaning  These findings suggest that efforts are still warranted to improve lifestyle in US adults, with attention on equity.\"\"\",\n",
    "]\n",
    "test_text[iteration] = pd.DataFrame([title, body], index=['title', 'body']).transpose()\n",
    "bulk_append(test_text[iteration], table='gpt_queue')\n",
    "test_text[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2: Include \"section\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 rows to the database...\n",
      "\ttitle 1\n",
      "\ttitle 2\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric, Boolean\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class GPT_queue(Base):\n",
    "    __tablename__ = 'gpt_queue'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    body = mapped_column(Text)\n",
    "    section = mapped_column(String(100))\n",
    "    sent_to_sources = mapped_column(Boolean)\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'gpt_queue':\n",
    "                    data = GPT_queue(\n",
    "                        title=row['title'],\n",
    "                        body=row['body'],\n",
    "                        section=row['section']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "                elif table == 'feed':\n",
    "                    source = session.query(Feed).filter_by(\n",
    "                        title=row['title'],\n",
    "                        journal=row['journal'],\n",
    "                        doi=row['doi']\n",
    "                    ).first()\n",
    "                    if source:\n",
    "                        print(f'\\tAlready exists in the database: {row[\"title\"]}.')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "iteration = 2.3\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article', 'discussion'],\n",
    "    2: ['title 2', 'this is the body of the second article', None]\n",
    "}, index=['title', 'body', 'section']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 3: Include \"sent_to_sources\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 rows to the database...\n",
      "\ttitle 1\n",
      "\ttitle 2\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric, Boolean\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class GPT_queue(Base):\n",
    "    __tablename__ = 'gpt_queue'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    body = mapped_column(Text)\n",
    "    section = mapped_column(String(100))\n",
    "    sent_to_sources = mapped_column(Boolean)\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'gpt_queue':\n",
    "                    data = GPT_queue(\n",
    "                        title=row['title'],\n",
    "                        body=row['body'],\n",
    "                        section=row['section'],\n",
    "                        sent_to_sources=row['sent_to_sources']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "                elif table == 'feed':\n",
    "                    source = session.query(Feed).filter_by(\n",
    "                        title=row['title'],\n",
    "                        journal=row['journal'],\n",
    "                        doi=row['doi']\n",
    "                    ).first()\n",
    "                    if source:\n",
    "                        print(f'\\tAlready exists in the database: {row[\"title\"]}.')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "iteration = 3\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article', 'discussion', False],\n",
    "    2: ['title 2', 'this is the body of the second article', None, False]\n",
    "}, index=['title', 'body', 'section', 'sent_to_sources']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1 rows to the database...\n",
      "\ttitle 1\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "iteration = 3.1\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article', 'discussion', 1],\n",
    "    # 2: ['title 2', 'this is the body of the second article', 'discussion', 1]\n",
    "}, index=['title', 'body', 'section', 'sent_to_sources']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename table to `ai_queue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 rows to the database...\n",
      "\ttitle 1\n",
      "\ttitle 2\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric, Boolean\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class AI_queue(Base):\n",
    "    __tablename__ = 'ai_queue'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    body = mapped_column(Text)\n",
    "    section = mapped_column(String(100))\n",
    "    sent_to_sources = mapped_column(Boolean)\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'ai_queue':\n",
    "                    data = AI_queue(\n",
    "                        title=row['title'],\n",
    "                        body=row['body'],\n",
    "                        section=row['section'],\n",
    "                        sent_to_sources=row['sent_to_sources']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "                elif table == 'feed':\n",
    "                    source = session.query(Feed).filter_by(\n",
    "                        title=row['title'],\n",
    "                        journal=row['journal'],\n",
    "                        doi=row['doi']\n",
    "                    ).first()\n",
    "                    if source:\n",
    "                        print(f'\\tAlready exists in the database: {row[\"title\"]}.')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "iteration = 3.1\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article', 'discussion', True],\n",
    "    2: ['title 2', 'this is the body of the second article', 'full', False]\n",
    "}, index=['title', 'body', 'section', 'sent_to_sources']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='ai_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from ai_queue ORDER BY id ASC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>section</th>\n",
       "      <th>sent_to_sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>title 1</td>\n",
       "      <td>this is the body of the first article</td>\n",
       "      <td>discussion</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>title 2</td>\n",
       "      <td>this is the body of the second article</td>\n",
       "      <td>full</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    title                                    body     section  \\\n",
       "0   1  title 1   this is the body of the first article  discussion   \n",
       "1   2  title 2  this is the body of the second article        full   \n",
       "\n",
       "   sent_to_sources  \n",
       "0             True  \n",
       "1            False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_table(table='ai_queue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename it back to gpt_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1 rows to the database...\n",
      "\ttitle 1\n",
      "Data added successfully!\n",
      "Query: SELECT * from gpt_queue ORDER BY id ASC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>sent_to_sources</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Trends in Self-Reported Adherence to Healthy L...</td>\n",
       "      <td>Introduction\\nAdhering to healthy lifestyle fa...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Lifestyle Enrichment in Later Life and Its Ass...</td>\n",
       "      <td>Introduction\\nIn 2022, there were 55 million i...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>A systematic review of ecological momentary as...</td>\n",
       "      <td>1 INTRODUCTION\\nDieting is the self-imposed re...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>title 1</td>\n",
       "      <td>this is the body of the first article</td>\n",
       "      <td>True</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  Trends in Self-Reported Adherence to Healthy L...   \n",
       "1  24  Lifestyle Enrichment in Later Life and Its Ass...   \n",
       "2  25  A systematic review of ecological momentary as...   \n",
       "3  26                                            title 1   \n",
       "\n",
       "                                                body sent_to_sources  \\\n",
       "0  Introduction\\nAdhering to healthy lifestyle fa...           False   \n",
       "1  Introduction\\nIn 2022, there were 55 million i...           False   \n",
       "2  1 INTRODUCTION\\nDieting is the self-imposed re...            None   \n",
       "3              this is the body of the first article            True   \n",
       "\n",
       "      section  \n",
       "0              \n",
       "1              \n",
       "2              \n",
       "3  discussion  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric, Boolean\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class GPT_queue(Base):\n",
    "    __tablename__ = 'gpt_queue'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    body = mapped_column(Text)\n",
    "    section = mapped_column(String(100))\n",
    "    sent_to_sources = mapped_column(Boolean)\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'gpt_queue':\n",
    "                    data = GPT_queue(\n",
    "                        title=row['title'],\n",
    "                        body=row['body'],\n",
    "                        section=row['section'],\n",
    "                        sent_to_sources=row['sent_to_sources']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "                elif table == 'feed':\n",
    "                    source = session.query(Feed).filter_by(\n",
    "                        title=row['title'],\n",
    "                        journal=row['journal'],\n",
    "                        doi=row['doi']\n",
    "                    ).first()\n",
    "                    if source:\n",
    "                        print(f'\\tAlready exists in the database: {row[\"title\"]}.')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "iteration = 3.2\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article', 'discussion', True],\n",
    "}, index=['title', 'body', 'section', 'sent_to_sources']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')\n",
    "get_table(table='gpt_queue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `main.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric, Boolean\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class GPT_queue(Base):\n",
    "    __tablename__ = 'gpt_queue'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    body = mapped_column(Text)\n",
    "    section = mapped_column(String(100))\n",
    "    sent_to_sources = mapped_column(Boolean)\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'gpt_queue':\n",
    "                    data = GPT_queue(\n",
    "                        title=row['title'],\n",
    "                        body=row['body'],\n",
    "                        section=row['section'],\n",
    "                        sent_to_sources=row['sent_to_sources']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "                elif table == 'feed':\n",
    "                    source = session.query(Feed).filter_by(\n",
    "                        title=row['title'],\n",
    "                        journal=row['journal'],\n",
    "                        doi=row['doi']\n",
    "                    ).first()\n",
    "                    if source:\n",
    "                        print(f'\\tAlready exists in the database: {row[\"title\"]}.')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "iteration = 4\n",
    "test_text[iteration] = pd.DataFrame({\n",
    "    1: ['title 1', 'this is the body of the first article', 'discussion', True],\n",
    "}, index=['title', 'body', 'section', 'sent_to_sources']).transpose()\n",
    "test_text[iteration]\n",
    "\n",
    "bulk_append(test_text[iteration], table='gpt_queue')\n",
    "get_table(table='gpt_queue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
