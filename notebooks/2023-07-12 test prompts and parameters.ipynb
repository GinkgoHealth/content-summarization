{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_dict = dict()\n",
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "save = True\n",
    "# save_outputs = False\n",
    "save_outputs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copied from [previous notebook](2023-07-11%20create%20summaries%20table.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    original_headline = mapped_column(String(255))\n",
    "    simple_summary = mapped_column(Text)\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=5):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    df[summary_column] = df[summary_column].apply(json.loads)\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: x['headline'])\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: x['audience'])\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: x['body'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "## Add rows from references dataframe\n",
    "# bulk_append(references_df)\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=3)\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# Add rows from results to summaries and prompts table\n",
    "bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the SQLAlchemy objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from summaries\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) #\n",
    "    simple_summary = mapped_column(Text)\n",
    "    # rating_simple_content = mapped_column(Integer) #\n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    df[summary_column] = df[summary_column].apply(json.loads)\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: x['headline'])\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: x['audience'])\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: x['body'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=3)\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # # chaining_dict[iteration_id]\n",
    "# qna_dict = create_summaries_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "#     )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "# qna_dict[iteration_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>original_summary</th>\n",
       "      <th>original_headline</th>\n",
       "      <th>simple_summary</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>choice</th>\n",
       "      <th>rating_original_content</th>\n",
       "      <th>rating_simple_content</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-07-12 06:35:24.458418+00:00</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>New Research on Recovery from Exercise in Midd...</td>\n",
       "      <td>Check out this new research that shows how par...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-07-12 06:12:32.880097+00:00</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>New Study Shows How Exercise Impacts Muscle Re...</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-07-12 06:35:24.458418+00:00</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>New Research Shows How Recreational Training C...</td>\n",
       "      <td>New research suggests that engaging in regular...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-07-12 06:35:28.609483+00:00</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Study Shows Nutritional Intervention Reduc...</td>\n",
       "      <td>A recent study has shown that a simple dietary...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-07-12 06:35:28.609483+00:00</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Study Shows Nutritional Intervention Can R...</td>\n",
       "      <td>A recent study has found that a simple dietary...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2023-07-12 06:35:33.993335+00:00</td>\n",
       "      <td>Exercise snacks, which are short bouts of vigo...</td>\n",
       "      <td>New Research Shows Exercise Snacks Improve Hea...</td>\n",
       "      <td>New research has found that short bursts of vi...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2023-07-12 06:35:33.993335+00:00</td>\n",
       "      <td>Exercise snacks, short bursts of vigorous exer...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Way to Impro...</td>\n",
       "      <td>Exercise snacks are a convenient and time-effi...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        timestamp  \\\n",
       "0   2 2023-07-12 06:35:24.458418+00:00   \n",
       "1   1 2023-07-12 06:12:32.880097+00:00   \n",
       "2   3 2023-07-12 06:35:24.458418+00:00   \n",
       "3   4 2023-07-12 06:35:28.609483+00:00   \n",
       "4   5 2023-07-12 06:35:28.609483+00:00   \n",
       "5   6 2023-07-12 06:35:33.993335+00:00   \n",
       "6   7 2023-07-12 06:35:33.993335+00:00   \n",
       "\n",
       "                                    original_summary  \\\n",
       "0  A recent study compared the recovery response ...   \n",
       "1  A recent study compared the recovery response ...   \n",
       "2  A recent study compared the recovery response ...   \n",
       "3  A recent study found that a high calcium and h...   \n",
       "4  A recent study found that a high calcium and h...   \n",
       "5  Exercise snacks, which are short bouts of vigo...   \n",
       "6  Exercise snacks, short bursts of vigorous exer...   \n",
       "\n",
       "                                   original_headline  \\\n",
       "0  New Research on Recovery from Exercise in Midd...   \n",
       "1  New Study Shows How Exercise Impacts Muscle Re...   \n",
       "2  New Research Shows How Recreational Training C...   \n",
       "3  New Study Shows Nutritional Intervention Reduc...   \n",
       "4  New Study Shows Nutritional Intervention Can R...   \n",
       "5  New Research Shows Exercise Snacks Improve Hea...   \n",
       "6  Exercise Snacks: A Time-Efficient Way to Impro...   \n",
       "\n",
       "                                      simple_summary  prompt_id  reference_id  \\\n",
       "0  Check out this new research that shows how par...          5             1   \n",
       "1  A recent study compared the recovery response ...          5             1   \n",
       "2  New research suggests that engaging in regular...          5             1   \n",
       "3  A recent study has shown that a simple dietary...          5             2   \n",
       "4  A recent study has found that a simple dietary...          5             2   \n",
       "5  New research has found that short bursts of vi...          5             3   \n",
       "6  Exercise snacks are a convenient and time-effi...          5             3   \n",
       "\n",
       "   choice  rating_original_content  rating_simple_content  \\\n",
       "0       1                        3                      3   \n",
       "1       1                        3                      3   \n",
       "2       2                        4                      2   \n",
       "3       1                        4                      3   \n",
       "4       2                        4                      4   \n",
       "5       1                        3                      3   \n",
       "6       2                        3                      4   \n",
       "\n",
       "                    model temperature  \n",
       "0  gpt-3.5-turbo-16k-0613         0.7  \n",
       "1  gpt-3.5-turbo-16k-0613         0.7  \n",
       "2  gpt-3.5-turbo-16k-0613         0.7  \n",
       "3  gpt-3.5-turbo-16k-0613         0.7  \n",
       "4  gpt-3.5-turbo-16k-0613         0.7  \n",
       "5  gpt-3.5-turbo-16k-0613         0.7  \n",
       "6  gpt-3.5-turbo-16k-0613         0.7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0613\n",
      "gpt-4-0314\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-4\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "from orm_summarize import openai_models\n",
    "models_available = openai_models(env=\"api_openai\", query='gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0613\n",
      "gpt-4-0314\n",
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "models_available = openai_models(env=\"api_openai\", query='4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate summaries with prompts imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources LIMIT 3\n",
      "**Text #1 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-4\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-4\n",
      "\t\tRequesting 2 choices using gpt-4\n",
      "An error occurred on line 246 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_23984\\3007662155.py : Rate limit reached for 10KTPM-200RPM in organization org-4l8HUKDtXhH0T7iFErf1JSJg on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-4\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-4\n",
      "\t\tRequesting 2 choices using gpt-4\n",
      "An error occurred on line 246 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_23984\\3007662155.py : Rate limit reached for 10KTPM-200RPM in organization org-4l8HUKDtXhH0T7iFErf1JSJg on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-4\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-4\n",
      "\t\tRequesting 2 choices using gpt-4\n",
      "An error occurred on line 246 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_23984\\3007662155.py : Rate limit reached for 10KTPM-200RPM in organization org-4l8HUKDtXhH0T7iFErf1JSJg on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "1_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_1102.json\n",
      "Processing 1_prompt00...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 399\u001b[0m\n\u001b[0;32m    390\u001b[0m chaining_dict \u001b[39m=\u001b[39m batch_summarize(\n\u001b[0;32m    391\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task, \n\u001b[0;32m    392\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m \u001b[39m# # chaining_dict[iteration_id]\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m    400\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id\n\u001b[0;32m    401\u001b[0m     )\n\u001b[0;32m    402\u001b[0m \u001b[39m# Add rows from results to summaries and prompts table\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39m# bulk_append(qna_dict[iteration_id])\u001b[39;00m\n\u001b[0;32m    404\u001b[0m qna_dict[iteration_id]\n",
      "Cell \u001b[1;32mIn[24], line 342\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mfor\u001b[39;00m chatbot_key \u001b[39min\u001b[39;00m chatbot_dict[chatbot_id]\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    339\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mchatbot_key\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    340\u001b[0m     dfs_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m    341\u001b[0m         chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna, \n\u001b[1;32m--> 342\u001b[0m         index\u001b[39m=\u001b[39m[choice \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39;49mqna[\u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[0;32m    343\u001b[0m         )\n\u001b[0;32m    345\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    346\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) #\n",
    "    simple_summary = mapped_column(Text)\n",
    "    # rating_simple_content = mapped_column(Integer) #\n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    df[summary_column] = df[summary_column].apply(json.loads)\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: x['headline'])\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: x['audience'])\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: x['body'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=3)\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1: Increase temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources\n",
      "**Text #1 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "1_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_1124.json\n",
      "Processing 1_prompt00...\n",
      "Processing 2_prompt00...\n",
      "Processing 3_prompt00...\n",
      "Processing 4_prompt00...\n",
      "Processing 5_prompt00...\n",
      "Processing 6_prompt00...\n",
      "Original summaries DataFrame shape: (12, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 11:23:53.713910-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A new study compared young and middle-aged adu...</td>\n",
       "      <td>New Research on the Impact of Aging and Exerci...</td>\n",
       "      <td>Check out this new study comparing young and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 11:23:53.713910-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>2</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>New Study on Aging and Exercise</td>\n",
       "      <td>A new study has found that regular resistance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 11:23:56.749327-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New study shows calcium and protein interventi...</td>\n",
       "      <td>A recent study has shown that a simple dietary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 11:23:56.749327-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found promising results for a h...</td>\n",
       "      <td>Nutritional Intervention Reduces Fracture Risk...</td>\n",
       "      <td>A recent study found that a tailored high calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 11:24:01.173618-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short bouts of vigorous ex...</td>\n",
       "      <td>Discover the Benefits of Exercise Snacks: A Fa...</td>\n",
       "      <td>Exercise snacks are short bursts of vigorous e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-12 11:24:01.173618-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Key points: Exercise snacks are brief bouts of...</td>\n",
       "      <td>Improve your health with exercise snacks</td>\n",
       "      <td>Introducing exercise snacks- short and intense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-12 11:24:08.390067-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study in a controlled hospital-based ...</td>\n",
       "      <td>New Study Reveals Surprising Links Between Foo...</td>\n",
       "      <td>This study offers valuable information about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-12 11:24:08.390067-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>2</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New study examines the impact of food cues and...</td>\n",
       "      <td>Researchers have found that exposure to certai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-12 11:24:11.716996-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Chronic pain affects a significant portion of ...</td>\n",
       "      <td>Study finds that mild dehydration increases pa...</td>\n",
       "      <td>A recent study discovered that not getting eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-12 11:24:11.716996-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A study found that mild dehydration can increa...</td>\n",
       "      <td>New Research Reveals that Dehydration Increase...</td>\n",
       "      <td>Did you know that being properly hydrated can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-07-12 11:24:15.883109-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma, or the discrimination and mistr...</td>\n",
       "      <td>Weight Stigma Linked to Negative Health Behaviors</td>\n",
       "      <td>Weight stigma negatively affects people's heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-07-12 11:24:15.883109-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\n...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>This study found that weight stigma is associa...</td>\n",
       "      <td>New research links weight stigma to negative h...</td>\n",
       "      <td>New study reveals that weight stigma can lead ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "0   2023-07-12 11:23:53.713910-07:00             1   \n",
       "1   2023-07-12 11:23:53.713910-07:00             1   \n",
       "2   2023-07-12 11:23:56.749327-07:00             2   \n",
       "3   2023-07-12 11:23:56.749327-07:00             2   \n",
       "4   2023-07-12 11:24:01.173618-07:00             3   \n",
       "5   2023-07-12 11:24:01.173618-07:00             3   \n",
       "6   2023-07-12 11:24:08.390067-07:00             4   \n",
       "7   2023-07-12 11:24:08.390067-07:00             4   \n",
       "8   2023-07-12 11:24:11.716996-07:00             5   \n",
       "9   2023-07-12 11:24:11.716996-07:00             5   \n",
       "10  2023-07-12 11:24:15.883109-07:00             6   \n",
       "11  2023-07-12 11:24:15.883109-07:00             6   \n",
       "\n",
       "                                        article_title  choice  \\\n",
       "0   Comparisons in the Recovery Response From Resi...       1   \n",
       "1   Comparisons in the Recovery Response From Resi...       2   \n",
       "2   Effect of dietary sources of calcium and prote...       1   \n",
       "3   Effect of dietary sources of calcium and prote...       2   \n",
       "4   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "5   Exercise Snacks A Novel Strategy to Improve Ca...       2   \n",
       "6   Food craving, cortisol and ghrelin responses i...       1   \n",
       "7   Food craving, cortisol and ghrelin responses i...       2   \n",
       "8   Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "9   Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "10  Weight stigma and health behaviors: evidence f...       1   \n",
       "11  Weight stigma and health behaviors: evidence f...       2   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Decreases in muscle mass, function, and neurom...   \n",
       "1   Decreases in muscle mass, function, and neurom...   \n",
       "2   Longevity increases the proportion of older ad...   \n",
       "3   Longevity increases the proportion of older ad...   \n",
       "4   We define exercise snacks as isolated ?1-min b...   \n",
       "5   We define exercise snacks as isolated ?1-min b...   \n",
       "6   The United States is at the forefront of the g...   \n",
       "7   The United States is at the forefront of the g...   \n",
       "8   Pain is recognized as a public health problem ...   \n",
       "9   Pain is recognized as a public health problem ...   \n",
       "10  Weight stigma is pervasive. Higher weight indi...   \n",
       "11  Weight stigma is pervasive. Higher weight indi...   \n",
       "\n",
       "                     system_role                   model  temperature  \\\n",
       "0   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "1   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "2   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "3   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "4   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "5   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "6   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "7   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "8   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "9   You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "10  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "11  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "\n",
       "                                            prep_step  \\\n",
       "0   In the summary, cover the following informatio...   \n",
       "1   In the summary, cover the following informatio...   \n",
       "2   In the summary, cover the following informatio...   \n",
       "3   In the summary, cover the following informatio...   \n",
       "4   In the summary, cover the following informatio...   \n",
       "5   In the summary, cover the following informatio...   \n",
       "6   In the summary, cover the following informatio...   \n",
       "7   In the summary, cover the following informatio...   \n",
       "8   In the summary, cover the following informatio...   \n",
       "9   In the summary, cover the following informatio...   \n",
       "10  In the summary, cover the following informatio...   \n",
       "11  In the summary, cover the following informatio...   \n",
       "\n",
       "                                summarize_task  \\\n",
       "0   1. Summarize the text for a LinkedIn post.   \n",
       "1   1. Summarize the text for a LinkedIn post.   \n",
       "2   1. Summarize the text for a LinkedIn post.   \n",
       "3   1. Summarize the text for a LinkedIn post.   \n",
       "4   1. Summarize the text for a LinkedIn post.   \n",
       "5   1. Summarize the text for a LinkedIn post.   \n",
       "6   1. Summarize the text for a LinkedIn post.   \n",
       "7   1. Summarize the text for a LinkedIn post.   \n",
       "8   1. Summarize the text for a LinkedIn post.   \n",
       "9   1. Summarize the text for a LinkedIn post.   \n",
       "10  1. Summarize the text for a LinkedIn post.   \n",
       "11  1. Summarize the text for a LinkedIn post.   \n",
       "\n",
       "                                            edit_task  \\\n",
       "0   Once you have written your text message:     \\...   \n",
       "1   Once you have written your text message:     \\...   \n",
       "2   Once you have written your text message:     \\...   \n",
       "3   Once you have written your text message:     \\...   \n",
       "4   Once you have written your text message:     \\...   \n",
       "5   Once you have written your text message:     \\...   \n",
       "6   Once you have written your text message:     \\...   \n",
       "7   Once you have written your text message:     \\...   \n",
       "8   Once you have written your text message:     \\...   \n",
       "9   Once you have written your text message:     \\...   \n",
       "10  Once you have written your text message:     \\...   \n",
       "11  Once you have written your text message:     \\...   \n",
       "\n",
       "                                        simplify_task  \\\n",
       "0   3. If needed, rewrite the text using terms app...   \n",
       "1   3. If needed, rewrite the text using terms app...   \n",
       "2   3. If needed, rewrite the text using terms app...   \n",
       "3   3. If needed, rewrite the text using terms app...   \n",
       "4   3. If needed, rewrite the text using terms app...   \n",
       "5   3. If needed, rewrite the text using terms app...   \n",
       "6   3. If needed, rewrite the text using terms app...   \n",
       "7   3. If needed, rewrite the text using terms app...   \n",
       "8   3. If needed, rewrite the text using terms app...   \n",
       "9   3. If needed, rewrite the text using terms app...   \n",
       "10  3. If needed, rewrite the text using terms app...   \n",
       "11  3. If needed, rewrite the text using terms app...   \n",
       "\n",
       "                      simplify_audience  \\\n",
       "0   people without a science background   \n",
       "1   people without a science background   \n",
       "2   people without a science background   \n",
       "3   people without a science background   \n",
       "4   people without a science background   \n",
       "5   people without a science background   \n",
       "6   people without a science background   \n",
       "7   people without a science background   \n",
       "8   people without a science background   \n",
       "9   people without a science background   \n",
       "10  people without a science background   \n",
       "11  people without a science background   \n",
       "\n",
       "                                          format_task  \\\n",
       "0   4. Return your final response in a JSON format...   \n",
       "1   4. Return your final response in a JSON format...   \n",
       "2   4. Return your final response in a JSON format...   \n",
       "3   4. Return your final response in a JSON format...   \n",
       "4   4. Return your final response in a JSON format...   \n",
       "5   4. Return your final response in a JSON format...   \n",
       "6   4. Return your final response in a JSON format...   \n",
       "7   4. Return your final response in a JSON format...   \n",
       "8   4. Return your final response in a JSON format...   \n",
       "9   4. Return your final response in a JSON format...   \n",
       "10  4. Return your final response in a JSON format...   \n",
       "11  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                  full_summarize_task                  folder  \\\n",
       "0   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "1   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "2   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "3   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "4   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "5   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "6   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "7   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "8   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "9   1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "10  1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "11  1. Summarize the text for a LinkedIn post.\\n\\n...  text/2023-07-11 for db   \n",
       "\n",
       "                                              summary  \\\n",
       "0   A new study compared young and middle-aged adu...   \n",
       "1   A recent study compared the recovery response ...   \n",
       "2   A recent study found that a high calcium and h...   \n",
       "3   A recent study found promising results for a h...   \n",
       "4   Exercise snacks are short bouts of vigorous ex...   \n",
       "5   Key points: Exercise snacks are brief bouts of...   \n",
       "6   A recent study in a controlled hospital-based ...   \n",
       "7   A recent study conducted in a controlled hospi...   \n",
       "8   Chronic pain affects a significant portion of ...   \n",
       "9   A study found that mild dehydration can increa...   \n",
       "10  Weight stigma, or the discrimination and mistr...   \n",
       "11  This study found that weight stigma is associa...   \n",
       "\n",
       "                                             headline  \\\n",
       "0   New Research on the Impact of Aging and Exerci...   \n",
       "1                     New Study on Aging and Exercise   \n",
       "2   New study shows calcium and protein interventi...   \n",
       "3   Nutritional Intervention Reduces Fracture Risk...   \n",
       "4   Discover the Benefits of Exercise Snacks: A Fa...   \n",
       "5            Improve your health with exercise snacks   \n",
       "6   New Study Reveals Surprising Links Between Foo...   \n",
       "7   New study examines the impact of food cues and...   \n",
       "8   Study finds that mild dehydration increases pa...   \n",
       "9   New Research Reveals that Dehydration Increase...   \n",
       "10  Weight Stigma Linked to Negative Health Behaviors   \n",
       "11  New research links weight stigma to negative h...   \n",
       "\n",
       "                                       simple_summary  \n",
       "0   Check out this new study comparing young and m...  \n",
       "1   A new study has found that regular resistance ...  \n",
       "2   A recent study has shown that a simple dietary...  \n",
       "3   A recent study found that a tailored high calc...  \n",
       "4   Exercise snacks are short bursts of vigorous e...  \n",
       "5   Introducing exercise snacks- short and intense...  \n",
       "6   This study offers valuable information about h...  \n",
       "7   Researchers have found that exposure to certai...  \n",
       "8   A recent study discovered that not getting eno...  \n",
       "9   Did you know that being properly hydrated can ...  \n",
       "10  Weight stigma negatively affects people's heal...  \n",
       "11  New study reveals that weight stigma can lead ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) #\n",
    "    simple_summary = mapped_column(Text)\n",
    "    # rating_simple_content = mapped_column(Integer) #\n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    df[summary_column] = df[summary_column].apply(json.loads)\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: x['headline'])\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: x['audience'])\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: x['body'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit)\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 12 rows to the database...\n",
      "\tReference #1: New Research on the Impact of Aging and Exercise on Muscle Function and Recovery\n",
      "\tReference #1: New Study on Aging and Exercise\n",
      "\tReference #2: New study shows calcium and protein intervention reduces fracture and fall risk in older adults\n",
      "\tReference #2: Nutritional Intervention Reduces Fracture Risk in Older Adults\n",
      "\tReference #3: Discover the Benefits of Exercise Snacks: A Fast and Feasible Way to Improve Health\n",
      "\tReference #3: Improve your health with exercise snacks\n",
      "\tReference #4: New Study Reveals Surprising Links Between Food Cravings, Stress, and Weight\n",
      "\tReference #4: New study examines the impact of food cues and stress on cravings and intake of highly palatable foods\n",
      "\tReference #5: Study finds that mild dehydration increases pain sensitivity in women\n",
      "\tReference #5: New Research Reveals that Dehydration Increases Pain Sensitivity in Women\n",
      "\tReference #6: Weight Stigma Linked to Negative Health Behaviors\n",
      "\tReference #6: New research links weight stigma to negative health behaviors: [Highlight Key Points]\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources\n",
      "**Text #4 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_1410.json\n",
      "Processing 4_prompt00...\n",
      "Processing 5_prompt00...\n",
      "Processing 6_prompt00...\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 5 column 2 (char 848)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 405\u001b[0m\n\u001b[0;32m    396\u001b[0m chaining_dict \u001b[39m=\u001b[39m batch_summarize(\n\u001b[0;32m    397\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task, \n\u001b[0;32m    398\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    402\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m    403\u001b[0m     )\n\u001b[0;32m    404\u001b[0m \u001b[39m# # chaining_dict[iteration_id]\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m    406\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id\n\u001b[0;32m    407\u001b[0m     )\n\u001b[0;32m    408\u001b[0m \u001b[39m# Add rows from results to summaries and prompts table\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[39m# bulk_append(qna_dict[iteration_id])\u001b[39;00m\n\u001b[0;32m    410\u001b[0m qna_dict[iteration_id]\n",
      "Cell \u001b[1;32mIn[28], line 350\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    344\u001b[0m     dfs_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m    345\u001b[0m         chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna, \n\u001b[0;32m    346\u001b[0m         index\u001b[39m=\u001b[39m[choice \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[0;32m    347\u001b[0m         )\n\u001b[0;32m    349\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 350\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    351\u001b[0m columns \u001b[39m=\u001b[39m qna_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    352\u001b[0m columns\u001b[39m.\u001b[39mremove(\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 368\u001b[0m, in \u001b[0;36mextract_summary\u001b[1;34m(df, summary_column)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_summary\u001b[39m(df, summary_column\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    367\u001b[0m     \u001b[39m# Convert the string to JSON\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     df[summary_column] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39;49mapply(json\u001b[39m.\u001b[39;49mloads)\n\u001b[0;32m    370\u001b[0m     \u001b[39m# Extract 'headline' and 'body' values\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 5 column 2 (char 848)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        rating_original_content=row['rating_original_content'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        rating_simple_content=row['rating_simple_content'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    df[summary_column] = df[summary_column].apply(json.loads)\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: x['headline'])\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: x['audience'])\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: x['body'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.1\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit).tail(3)\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1.1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qna_dict[iteration_id]\n",
      "\u001b[1;31mKeyError\u001b[0m: 1.1"
     ]
    }
   ],
   "source": [
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4_prompt00...\n",
      "Processing 5_prompt00...\n",
      "Processing 6_prompt00...\n",
      "Error converting summary column to JSON: Expecting property name enclosed in double quotes: line 5 column 2 (char 848); will do row by row\n",
      "Error converting summary 5 to JSON: Expecting property name enclosed in double quotes: line 5 column 2 (char 848)\n",
      "Original summaries DataFrame shape: (6, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 14:10:05.214512-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the global obesity epidemic with 67% of its population ...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled setting found that exposure to food cues and stress can...</td>\n",
       "      <td>New Study Reveals How Food Cues and Stress Increase Cravings for Unhealthy Foods</td>\n",
       "      <td>Discover how exposure to food cues and stress can affect our cravings for unhealthy foods: the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 14:10:05.214512-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...</td>\n",
       "      <td>2</td>\n",
       "      <td>The United States is at the forefront of the global obesity epidemic with 67% of its population ...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>In a recent study conducted in a controlled hospital setting, researchers found that exposure to...</td>\n",
       "      <td>New Study Shows That Food Cues and Stress Increase Cravings and Intake of Unhealthy Foods</td>\n",
       "      <td>A recent study conducted in a controlled hospital setting found that exposures to food cues and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 14:10:08.562822-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration increases pain sensitivity in women, supporting previ...</td>\n",
       "      <td>New Research Shows Dehydration Can Affect Pain Sensitivity in Women</td>\n",
       "      <td>Dehydration can have a negative impact on pain response in women, according to new research. It'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 14:10:08.562822-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can increase experimental pain sensitivity in women, ...</td>\n",
       "      <td>New research shows that dehydration increases pain sensitivity in women</td>\n",
       "      <td>Have you ever considered the effects of dehydration on pain perception? Recent research shows th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 14:10:12.012633-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma negatively affects health behaviors such as eating, physical activity, alcohol use...</td>\n",
       "      <td>Weight Stigma and its Impact on Health Behaviors</td>\n",
       "      <td>New study highlights the negative impact of weight stigma on eating, exercise, alcohol use, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-12 14:10:12.012633-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>2</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight discrimination is associated with negative effects on physical health and multiple health...</td>\n",
       "      <td>Weight stigma and health behaviors: Key findings from recent research</td>\n",
       "      <td>Weight discrimination can impact physical health and health behaviors like eating, alcohol use, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-12 14:10:05.214512-07:00             4   \n",
       "1  2023-07-12 14:10:05.214512-07:00             4   \n",
       "2  2023-07-12 14:10:08.562822-07:00             5   \n",
       "3  2023-07-12 14:10:08.562822-07:00             5   \n",
       "4  2023-07-12 14:10:12.012633-07:00             6   \n",
       "5  2023-07-12 14:10:12.012633-07:00             6   \n",
       "\n",
       "                                                                                         article_title  \\\n",
       "0  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...   \n",
       "1  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...   \n",
       "2                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "3                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "4                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "5                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       2   \n",
       "2       1   \n",
       "3       2   \n",
       "4       1   \n",
       "5       2   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  The United States is at the forefront of the global obesity epidemic with 67% of its population ...   \n",
       "1  The United States is at the forefront of the global obesity epidemic with 67% of its population ...   \n",
       "2  Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...   \n",
       "3  Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...   \n",
       "4  Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...   \n",
       "5  Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...   \n",
       "\n",
       "                    system_role                   model  temperature  \\\n",
       "0  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "3  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "4  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "5  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          1.5   \n",
       "\n",
       "                                                                                             prep_step  \\\n",
       "0  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "1  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "2  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "3  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "4  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "5  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "\n",
       "                               summarize_task  \\\n",
       "0  1. Summarize the text for a LinkedIn post.   \n",
       "1  1. Summarize the text for a LinkedIn post.   \n",
       "2  1. Summarize the text for a LinkedIn post.   \n",
       "3  1. Summarize the text for a LinkedIn post.   \n",
       "4  1. Summarize the text for a LinkedIn post.   \n",
       "5  1. Summarize the text for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit_task  \\\n",
       "0  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "1  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "2  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "3  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "4  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "5  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "\n",
       "                                                                                         simplify_task  \\\n",
       "0  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "1  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "2  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "3  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "4  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "5  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "\n",
       "                     simplify_audience  \\\n",
       "0  people without a science background   \n",
       "1  people without a science background   \n",
       "2  people without a science background   \n",
       "3  people without a science background   \n",
       "4  people without a science background   \n",
       "5  people without a science background   \n",
       "\n",
       "                                                                                           format_task  \\\n",
       "0  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "1  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "2  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "3  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "4  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "5  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "\n",
       "                                                                                   full_summarize_task  \\\n",
       "0  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "1  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "2  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "3  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "4  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "5  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "\n",
       "                   folder  \\\n",
       "0  text/2023-07-11 for db   \n",
       "1  text/2023-07-11 for db   \n",
       "2  text/2023-07-11 for db   \n",
       "3  text/2023-07-11 for db   \n",
       "4  text/2023-07-11 for db   \n",
       "5  text/2023-07-11 for db   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  A recent study conducted in a controlled setting found that exposure to food cues and stress can...   \n",
       "1  In a recent study conducted in a controlled hospital setting, researchers found that exposure to...   \n",
       "2  A recent study found that mild dehydration increases pain sensitivity in women, supporting previ...   \n",
       "3  A recent study found that mild dehydration can increase experimental pain sensitivity in women, ...   \n",
       "4  Weight stigma negatively affects health behaviors such as eating, physical activity, alcohol use...   \n",
       "5  Weight discrimination is associated with negative effects on physical health and multiple health...   \n",
       "\n",
       "                                                                                    headline  \\\n",
       "0           New Study Reveals How Food Cues and Stress Increase Cravings for Unhealthy Foods   \n",
       "1  New Study Shows That Food Cues and Stress Increase Cravings and Intake of Unhealthy Foods   \n",
       "2                        New Research Shows Dehydration Can Affect Pain Sensitivity in Women   \n",
       "3                    New research shows that dehydration increases pain sensitivity in women   \n",
       "4                                           Weight Stigma and its Impact on Health Behaviors   \n",
       "5                      Weight stigma and health behaviors: Key findings from recent research   \n",
       "\n",
       "                                                                                        simple_summary  \n",
       "0  Discover how exposure to food cues and stress can affect our cravings for unhealthy foods: the l...  \n",
       "1  A recent study conducted in a controlled hospital setting found that exposures to food cues and ...  \n",
       "2  Dehydration can have a negative impact on pain response in women, according to new research. It'...  \n",
       "3  Have you ever considered the effects of dehydration on pain perception? Recent research shows th...  \n",
       "4  New study highlights the negative impact of weight stigma on eating, exercise, alcohol use, and ...  \n",
       "5  Weight discrimination can impact physical health and health behaviors like eating, alcohol use, ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi']\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        # rating_original_content=row['rating_original_content'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        # rating_simple_content=row['rating_simple_content'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            value = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary).group(1)\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.1\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=article_limit).tail(3)\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>{\"headline\": \"New Study Reveals How Food Cues and Stress Increase Cravings for Unhealthy Foods\",\\n\"body\": \"A recent study conducted in a controlled setting found that exposure to food cues and stress can significantly increase cravings for highly palatable foods. The study also showed that these cravings directly predicted subsequent intake of unhealthy snacks. Furthermore, the hormone ghrelin was found to play a role in promoting food cravings, particularly in individuals who are overweight. The findings highlight the need for greater understanding of the biobehavioral processes that contribute to overeating and weight gain.\",\\n\"audience\": \"Discover how exposure to food cues and stress can affect our cravings for unhealthy foods: the latest research sheds light on the role of hormonal responses and the potential impact on weight management.\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>{\\n  \"headline\": \"New Study Shows That Food Cues and Stress Increase Cravings and Intake of Unhealthy Foods\",\\n  \"body\": \"In a recent study conducted in a controlled hospital setting, researchers found that exposure to food cues and stress both significantly increased cravings for highly palatable (HP) foods. These cravings, in turn, predicted greater intake of HP foods. Additionally, the study revealed that specific hormones, such as ghrelin and cortisol, may play a role in food motivation and intake. The findings highlight the potential factors influencing overeating and weight gain, and provide insights into the biobehavioral processes driving unhealthy food consumption.\",\\n  \"audience\": \"A recent study conducted in a controlled hospital setting found that exposures to food cues and stress may increase unhealthy food cravings and intake. The findings suggest important factors to consider in controlling food consumption and understanding the impact on weight gain.\" \\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>{\"headline\": \"New Research Shows Dehydration Can Affect Pain Sensitivity in Women\",\\n\"body\": \"A recent study found that mild dehydration increases pain sensitivity in women, supporting previous research in men. The study also investigated the effects of menstrual phase on pain sensitivity, but found no significant difference. Interestingly, acute water ingestion did not reduce pain sensitivity in hypohydrated participants. This research highlights the importance of staying properly hydrated to manage pain symptoms.\",\\n\"audience\": \"Dehydration can have a negative impact on pain response in women, according to new research. It's essential to focus on staying hydrated to help manage pain effectively.\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>{\"headline\": \"New research shows that dehydration increases pain sensitivity in women\", \\n\"body\": \"A recent study found that mild dehydration can increase experimental pain sensitivity in women, leading to decreased pain tolerance and increased pain intensity and unpleasantness. The study also examined the effects of menstrual phase on pain sensitivity, but found that it did not greatly impact pain perception. Additionally, acute water ingestion did not reduce pain sensitivity. This research highlights the importance of maintaining adequate hydration for women's wellbeing and suggests a link between dehydration and pain perception.\", \\n\"audience\": \"Have you ever considered the effects of dehydration on pain perception? Recent research shows that even mild dehydration can affect how we perceive pain. This is particularly important for women, as they may experience greater pain sensitivity under dehydrated conditions. Ensuring proper hydration can play a role in managing pain symptoms and supporting overall health.\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>{\"headline\": \"Weight Stigma and its Impact on Health Behaviors\",\\n \"body\": \"Weight stigma negatively affects health behaviors such as eating, physical activity, alcohol use, and sleep, according to a US study. The research highlights that weight stigma is associated with disordered eating, higher alcohol consumption, and poorer sleep quality. It also found that weight stigma affects health behaviors across different weights. This shows the need to reduce weight stigma and promote weight-inclusive health approaches.\",\\n \"audience\": \"New study highlights the negative impact of weight stigma on eating, exercise, alcohol use, and sleep. It affects people of all weights. Let's work towards promoting more inclusive health approaches to avoid detrimental effects.\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>{\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\\n }</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   folder  \\\n",
       "0  text/2023-07-11 for db   \n",
       "1  text/2023-07-11 for db   \n",
       "2  text/2023-07-11 for db   \n",
       "3  text/2023-07-11 for db   \n",
       "4  text/2023-07-11 for db   \n",
       "5  text/2023-07-11 for db   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  summary  \n",
       "0                                                                                                                                                                                 {\"headline\": \"New Study Reveals How Food Cues and Stress Increase Cravings for Unhealthy Foods\",\\n\"body\": \"A recent study conducted in a controlled setting found that exposure to food cues and stress can significantly increase cravings for highly palatable foods. The study also showed that these cravings directly predicted subsequent intake of unhealthy snacks. Furthermore, the hormone ghrelin was found to play a role in promoting food cravings, particularly in individuals who are overweight. The findings highlight the need for greater understanding of the biobehavioral processes that contribute to overeating and weight gain.\",\\n\"audience\": \"Discover how exposure to food cues and stress can affect our cravings for unhealthy foods: the latest research sheds light on the role of hormonal responses and the potential impact on weight management.\"}  \n",
       "1                                               {\\n  \"headline\": \"New Study Shows That Food Cues and Stress Increase Cravings and Intake of Unhealthy Foods\",\\n  \"body\": \"In a recent study conducted in a controlled hospital setting, researchers found that exposure to food cues and stress both significantly increased cravings for highly palatable (HP) foods. These cravings, in turn, predicted greater intake of HP foods. Additionally, the study revealed that specific hormones, such as ghrelin and cortisol, may play a role in food motivation and intake. The findings highlight the potential factors influencing overeating and weight gain, and provide insights into the biobehavioral processes driving unhealthy food consumption.\",\\n  \"audience\": \"A recent study conducted in a controlled hospital setting found that exposures to food cues and stress may increase unhealthy food cravings and intake. The findings suggest important factors to consider in controlling food consumption and understanding the impact on weight gain.\" \\n}  \n",
       "2                                                                                                                                                                                                                                                                                                                                    {\"headline\": \"New Research Shows Dehydration Can Affect Pain Sensitivity in Women\",\\n\"body\": \"A recent study found that mild dehydration increases pain sensitivity in women, supporting previous research in men. The study also investigated the effects of menstrual phase on pain sensitivity, but found no significant difference. Interestingly, acute water ingestion did not reduce pain sensitivity in hypohydrated participants. This research highlights the importance of staying properly hydrated to manage pain symptoms.\",\\n\"audience\": \"Dehydration can have a negative impact on pain response in women, according to new research. It's essential to focus on staying hydrated to help manage pain effectively.\"}  \n",
       "3  {\"headline\": \"New research shows that dehydration increases pain sensitivity in women\", \\n\"body\": \"A recent study found that mild dehydration can increase experimental pain sensitivity in women, leading to decreased pain tolerance and increased pain intensity and unpleasantness. The study also examined the effects of menstrual phase on pain sensitivity, but found that it did not greatly impact pain perception. Additionally, acute water ingestion did not reduce pain sensitivity. This research highlights the importance of maintaining adequate hydration for women's wellbeing and suggests a link between dehydration and pain perception.\", \\n\"audience\": \"Have you ever considered the effects of dehydration on pain perception? Recent research shows that even mild dehydration can affect how we perceive pain. This is particularly important for women, as they may experience greater pain sensitivity under dehydrated conditions. Ensuring proper hydration can play a role in managing pain symptoms and supporting overall health.\"}  \n",
       "4                                                                                                                                                                                                                                                                        {\"headline\": \"Weight Stigma and its Impact on Health Behaviors\",\\n \"body\": \"Weight stigma negatively affects health behaviors such as eating, physical activity, alcohol use, and sleep, according to a US study. The research highlights that weight stigma is associated with disordered eating, higher alcohol consumption, and poorer sleep quality. It also found that weight stigma affects health behaviors across different weights. This shows the need to reduce weight stigma and promote weight-inclusive health approaches.\",\\n \"audience\": \"New study highlights the negative impact of weight stigma on eating, exercise, alcohol use, and sleep. It affects people of all weights. Let's work towards promoting more inclusive health approaches to avoid detrimental effects.\"}  \n",
       "5                                                                                                                                                                                   {\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\\n }  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id][['folder', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\\n }'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].loc[5, 'summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\\n }'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].loc[5, 'summary'].replace(r'\",\\n', r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\\n }'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].loc[5, 'summary'].rstrip(',\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 5 column 2 (char 848)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeight stigma and health behaviors: Key findings from recent research\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\u001b[39maudience\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m }\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m json\u001b[39m.\u001b[39;49mloads(text)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 5 column 2 (char 848)"
     ]
    }
   ],
   "source": [
    "text = '{\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\\n }'\n",
    "json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Weight stigma and health behaviors: Key findings from recent research',\n",
       " 'body': 'Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.',\n",
       " 'audience': 'Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '{\\n  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\\n  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\\n  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\"\\n }'\n",
    "json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {\"headline\": \"New Study Reveals How Food Cues and Stress Increase Cravings for Unhealthy Foods\",\n",
      "\"body\": \"A recent study conducted in a controlled setting found that exposure to food cues and stress can significantly increase cravings for highly palatable foods. The study also showed that these cravings directly predicted subsequent intake of unhealthy snacks. Furthermore, the hormone ghrelin was found to play a role in promoting food cravings, particularly in individuals who are overweight. The findings highlight the need for greater understanding of the biobehavioral processes that contribute to overeating and weight gain.\",\n",
      "\"audience\": \"Discover how exposure to food cues and stress can affect our cravings for unhealthy foods: the latest research sheds light on the role of hormonal responses and the potential impact on weight management.\"}\n",
      "\n",
      "1 {\n",
      "  \"headline\": \"New Study Shows That Food Cues and Stress Increase Cravings and Intake of Unhealthy Foods\",\n",
      "  \"body\": \"In a recent study conducted in a controlled hospital setting, researchers found that exposure to food cues and stress both significantly increased cravings for highly palatable (HP) foods. These cravings, in turn, predicted greater intake of HP foods. Additionally, the study revealed that specific hormones, such as ghrelin and cortisol, may play a role in food motivation and intake. The findings highlight the potential factors influencing overeating and weight gain, and provide insights into the biobehavioral processes driving unhealthy food consumption.\",\n",
      "  \"audience\": \"A recent study conducted in a controlled hospital setting found that exposures to food cues and stress may increase unhealthy food cravings and intake. The findings suggest important factors to consider in controlling food consumption and understanding the impact on weight gain.\" \n",
      "}\n",
      "\n",
      "2 {\"headline\": \"New Research Shows Dehydration Can Affect Pain Sensitivity in Women\",\n",
      "\"body\": \"A recent study found that mild dehydration increases pain sensitivity in women, supporting previous research in men. The study also investigated the effects of menstrual phase on pain sensitivity, but found no significant difference. Interestingly, acute water ingestion did not reduce pain sensitivity in hypohydrated participants. This research highlights the importance of staying properly hydrated to manage pain symptoms.\",\n",
      "\"audience\": \"Dehydration can have a negative impact on pain response in women, according to new research. It's essential to focus on staying hydrated to help manage pain effectively.\"}\n",
      "\n",
      "3 {\"headline\": \"New research shows that dehydration increases pain sensitivity in women\", \n",
      "\"body\": \"A recent study found that mild dehydration can increase experimental pain sensitivity in women, leading to decreased pain tolerance and increased pain intensity and unpleasantness. The study also examined the effects of menstrual phase on pain sensitivity, but found that it did not greatly impact pain perception. Additionally, acute water ingestion did not reduce pain sensitivity. This research highlights the importance of maintaining adequate hydration for women's wellbeing and suggests a link between dehydration and pain perception.\", \n",
      "\"audience\": \"Have you ever considered the effects of dehydration on pain perception? Recent research shows that even mild dehydration can affect how we perceive pain. This is particularly important for women, as they may experience greater pain sensitivity under dehydrated conditions. Ensuring proper hydration can play a role in managing pain symptoms and supporting overall health.\"}\n",
      "\n",
      "4 {\"headline\": \"Weight Stigma and its Impact on Health Behaviors\",\n",
      " \"body\": \"Weight stigma negatively affects health behaviors such as eating, physical activity, alcohol use, and sleep, according to a US study. The research highlights that weight stigma is associated with disordered eating, higher alcohol consumption, and poorer sleep quality. It also found that weight stigma affects health behaviors across different weights. This shows the need to reduce weight stigma and promote weight-inclusive health approaches.\",\n",
      " \"audience\": \"New study highlights the negative impact of weight stigma on eating, exercise, alcohol use, and sleep. It affects people of all weights. Let's work towards promoting more inclusive health approaches to avoid detrimental effects.\"}\n",
      "\n",
      "5 {\n",
      "  \"headline\": \"Weight stigma and health behaviors: Key findings from recent research\",\n",
      "  \"body\": \"Weight discrimination is associated with negative effects on physical health and multiple health behaviors including eating behavior, alcohol use, and sleep. Research found that weight stigma is significantly associated with poorer health behaviors, independent of BMI. These findings suggest the need to reduce weight stigma and employ more weight-inclusive approaches to health promotion.\",\n",
      "  \"audience\": \"Weight discrimination can impact physical health and health behaviors like eating, alcohol use, and sleep. Research, in a diverse U.S. sample, found that weight stigma is associated with poorer health behaviors, regardless of body mass index. Addressing weight stigma is important for promoting healthy behaviors and overall well-being.\",\n",
      " }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in qna_dict[iteration_id]['summary'].items():\n",
    "    print(index, row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in qna_dict[iteration_id].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].apply(lambda row: print(row.index), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add rows to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 6 rows to the database...\n",
      "\tReference #4: New Study Reveals How Food Cues and Stress Increase Cravings for Unhealthy Foods\n",
      "\tReference #4: New Study Shows That Food Cues and Stress Increase Cravings and Intake of Unhealthy Foods\n",
      "\tReference #5: New Research Shows Dehydration Can Affect Pain Sensitivity in Women\n",
      "\tReference #5: New research shows that dehydration increases pain sensitivity in women\n",
      "\tReference #6: Weight Stigma and its Impact on Health Behaviors\n",
      "\tReference #6: Weight stigma and health behaviors: Key findings from recent research\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Add text type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 5\n",
      "**Text #6 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_2151.json\n",
      "Processing 6_prompt00...\n",
      "Processing 5_prompt00...\n",
      "Processing 4_prompt00...\n",
      "Processing 3_prompt00...\n",
      "Processing 2_prompt00...\n",
      "Original summaries DataFrame shape: (5, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        # rating_original_content=row['rating_original_content'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        # rating_simple_content=row['rating_simple_content'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            value = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary).group(1)\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.12\n",
    "article_limit = 5\n",
    "temperature = 0.7\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit, order='DESC')\n",
    "# sources_df\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# # bulk_append(qna_dict[iteration_id])\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 21:50:42.131220-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that weight stigma is associated with poorer health behaviors, including di...</td>\n",
       "      <td>New Study Shows Weight Stigma Negatively Impacts Health Behaviors</td>\n",
       "      <td>A recent study found that being stigmatized for weight can negatively impact health behaviors, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 21:50:45.985609-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can increase pain sensitivity in women. The research ...</td>\n",
       "      <td>New Research Shows Dehydration Increases Pain Sensitivity in Women</td>\n",
       "      <td>New research has found that dehydration can make women more sensitive to pain. This study shows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 21:50:49.903727-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the global obesity epidemic with 67% of its population ...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospital-based setting found that exposure to food cues...</td>\n",
       "      <td>New Study Reveals the Impact of Food Cues and Stress on Food Cravings and Intake</td>\n",
       "      <td>A recent study conducted in a controlled hospital-based setting found that exposure to food cues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 21:50:53.596360-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Cardiometabolic Health</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min bouts of vigorous exercise performed periodically t...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are isolated bouts of vigorous exercise lasting ?1 min and performed periodicall...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Approach to Improve Health</td>\n",
       "      <td>Discover the benefits of exercise snacks, a time-efficient approach to improve your health. Exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 21:50:58.023523-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older adults in the population. The accompanying increased...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and high protein nutritional intervention can significa...</td>\n",
       "      <td>New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults</td>\n",
       "      <td>A recent study has found that a simple nutritional intervention can significantly reduce the ris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-12 21:50:42.131220-07:00             6   \n",
       "1  2023-07-12 21:50:45.985609-07:00             5   \n",
       "2  2023-07-12 21:50:49.903727-07:00             4   \n",
       "3  2023-07-12 21:50:53.596360-07:00             3   \n",
       "4  2023-07-12 21:50:58.023523-07:00             2   \n",
       "\n",
       "                                                                                         article_title  \\\n",
       "0                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "1                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "2  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...   \n",
       "3                                   Exercise Snacks A Novel Strategy to Improve Cardiometabolic Health   \n",
       "4  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...   \n",
       "1  Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...   \n",
       "2  The United States is at the forefront of the global obesity epidemic with 67% of its population ...   \n",
       "3  We define exercise snacks as isolated ?1-min bouts of vigorous exercise performed periodically t...   \n",
       "4  Longevity increases the proportion of older adults in the population. The accompanying increased...   \n",
       "\n",
       "                    system_role                   model  temperature  \\\n",
       "0  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "3  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "4  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "\n",
       "                                                                                             prep_step  \\\n",
       "0  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "1  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "2  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "3  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "4  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "\n",
       "                               summarize_task  \\\n",
       "0  1. Summarize the text for a LinkedIn post.   \n",
       "1  1. Summarize the text for a LinkedIn post.   \n",
       "2  1. Summarize the text for a LinkedIn post.   \n",
       "3  1. Summarize the text for a LinkedIn post.   \n",
       "4  1. Summarize the text for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit_task  \\\n",
       "0  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "1  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "2  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "3  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "4  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "\n",
       "                                                                                         simplify_task  \\\n",
       "0  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "1  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "2  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "3  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "4  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "\n",
       "                     simplify_audience  \\\n",
       "0  people without a science background   \n",
       "1  people without a science background   \n",
       "2  people without a science background   \n",
       "3  people without a science background   \n",
       "4  people without a science background   \n",
       "\n",
       "                                                                                           format_task  \\\n",
       "0  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "1  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "2  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "3  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "4  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "\n",
       "                                                                                   full_summarize_task  \\\n",
       "0  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "1  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "2  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "3  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "4  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "\n",
       "                   folder  \\\n",
       "0  text/2023-07-11 for db   \n",
       "1  text/2023-07-11 for db   \n",
       "2  text/2023-07-11 for db   \n",
       "3  text/2023-07-11 for db   \n",
       "4  text/2023-07-11 for db   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  A recent study found that weight stigma is associated with poorer health behaviors, including di...   \n",
       "1  A recent study found that mild dehydration can increase pain sensitivity in women. The research ...   \n",
       "2  A recent study conducted in a controlled hospital-based setting found that exposure to food cues...   \n",
       "3  Exercise snacks are isolated bouts of vigorous exercise lasting ?1 min and performed periodicall...   \n",
       "4  A recent study found that a high calcium and high protein nutritional intervention can significa...   \n",
       "\n",
       "                                                                           headline  \\\n",
       "0                 New Study Shows Weight Stigma Negatively Impacts Health Behaviors   \n",
       "1                New Research Shows Dehydration Increases Pain Sensitivity in Women   \n",
       "2  New Study Reveals the Impact of Food Cues and Stress on Food Cravings and Intake   \n",
       "3                      Exercise Snacks: A Time-Efficient Approach to Improve Health   \n",
       "4    New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults   \n",
       "\n",
       "                                                                                        simple_summary  \n",
       "0  A recent study found that being stigmatized for weight can negatively impact health behaviors, s...  \n",
       "1  New research has found that dehydration can make women more sensitive to pain. This study shows ...  \n",
       "2  A recent study conducted in a controlled hospital-based setting found that exposure to food cues...  \n",
       "3  Discover the benefits of exercise snacks, a time-efficient approach to improve your health. Exer...  \n",
       "4  A recent study has found that a simple nutritional intervention can significantly reduce the ris...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 5 rows to the database...\n",
      "\tReference #6: New Study Shows Weight Stigma Negatively Impacts Health Behaviors\n",
      "\tReference #5: New Research Shows Dehydration Increases Pain Sensitivity in Women\n",
      "\tReference #4: New Study Reveals the Impact of Food Cues and Stress on Food Cravings and Intake\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #2: New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id ASC\n",
      "**Text #1 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "1_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_2154.json\n",
      "Processing 1_prompt00...\n",
      "Processing 2_prompt00...\n",
      "Processing 3_prompt00...\n",
      "Processing 4_prompt00...\n",
      "Processing 5_prompt00...\n",
      "Processing 6_prompt00...\n",
      "Original summaries DataFrame shape: (6, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 6 rows to the database...\n",
      "\tReference #1: New Study Shows How Exercise Recovery Changes with Age\n",
      "\tReference #2: New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #4: New Research Reveals the Impact of Food Cues and Stress on Food Cravings and Intake\n",
      "\tReference #5: New research shows that dehydration can increase pain sensitivity in women\n",
      "\tReference #6: Weight Stigma and Its Impact on Health Behaviors\n",
      "Data added successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 21:54:07.125162-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study examined the recovery response from high-volume resistance exercise in young and ...</td>\n",
       "      <td>New Study Shows How Exercise Recovery Changes with Age</td>\n",
       "      <td>A recent study found that middle-aged individuals who regularly engage in resistance training ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 21:54:10.534358-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older adults in the population. The accompanying increased...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and high protein nutritional intervention can reduce th...</td>\n",
       "      <td>New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults</td>\n",
       "      <td>A recent study has found that a specific nutritional intervention can help reduce the risk of fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 21:54:13.766795-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Cardiometabolic Health</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min bouts of vigorous exercise performed periodically t...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short bursts of vigorous exercise performed periodically throughout the day....</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Approach to Improve Health</td>\n",
       "      <td>Exercise snacks are a convenient and effective way to improve health and fitness. They involve s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 21:54:18.510281-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the global obesity epidemic with 67% of its population ...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study investigated the effects of food cues and stress on highly palatable food craving...</td>\n",
       "      <td>New Research Reveals the Impact of Food Cues and Stress on Food Cravings and Intake</td>\n",
       "      <td>Check out this new study that explores how food cues and stress can impact our food cravings and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 21:54:23.960373-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can lead to increased pain sensitivity in women. The ...</td>\n",
       "      <td>New research shows that dehydration can increase pain sensitivity in women</td>\n",
       "      <td>New research suggests that staying hydrated is crucial for managing pain in women. A recent stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-12 21:54:28.320657-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and has negative consequences on physical health. It is associated wi...</td>\n",
       "      <td>Weight Stigma and Its Impact on Health Behaviors</td>\n",
       "      <td>Weight stigma affects individuals of all body sizes and has a significant impact on their health...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-12 21:54:07.125162-07:00             1   \n",
       "1  2023-07-12 21:54:10.534358-07:00             2   \n",
       "2  2023-07-12 21:54:13.766795-07:00             3   \n",
       "3  2023-07-12 21:54:18.510281-07:00             4   \n",
       "4  2023-07-12 21:54:23.960373-07:00             5   \n",
       "5  2023-07-12 21:54:28.320657-07:00             6   \n",
       "\n",
       "                                                                                         article_title  \\\n",
       "0      Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2                                   Exercise Snacks A Novel Strategy to Improve Cardiometabolic Health   \n",
       "3  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...   \n",
       "4                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "5                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "5       1   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...   \n",
       "1  Longevity increases the proportion of older adults in the population. The accompanying increased...   \n",
       "2  We define exercise snacks as isolated ?1-min bouts of vigorous exercise performed periodically t...   \n",
       "3  The United States is at the forefront of the global obesity epidemic with 67% of its population ...   \n",
       "4  Pain is recognized as a public health problem (1). Chronic pain [i.e., pain that persists for ?3...   \n",
       "5  Weight stigma is pervasive. Higher weight individuals are stigmatized across many contexts, incl...   \n",
       "\n",
       "                    system_role                   model  temperature  \\\n",
       "0  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "3  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "4  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "5  You are a helpful assistant.  gpt-3.5-turbo-16k-0613          0.7   \n",
       "\n",
       "                                                                                             prep_step  \\\n",
       "0  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "1  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "2  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "3  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "4  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "5  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "\n",
       "                               summarize_task  \\\n",
       "0  1. Summarize the text for a LinkedIn post.   \n",
       "1  1. Summarize the text for a LinkedIn post.   \n",
       "2  1. Summarize the text for a LinkedIn post.   \n",
       "3  1. Summarize the text for a LinkedIn post.   \n",
       "4  1. Summarize the text for a LinkedIn post.   \n",
       "5  1. Summarize the text for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit_task  \\\n",
       "0  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "1  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "2  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "3  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "4  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "5  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "\n",
       "                                                                                         simplify_task  \\\n",
       "0  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "1  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "2  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "3  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "4  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "5  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "\n",
       "                     simplify_audience  \\\n",
       "0  people without a science background   \n",
       "1  people without a science background   \n",
       "2  people without a science background   \n",
       "3  people without a science background   \n",
       "4  people without a science background   \n",
       "5  people without a science background   \n",
       "\n",
       "                                                                                           format_task  \\\n",
       "0  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "1  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "2  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "3  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "4  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "5  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "\n",
       "                                                                                   full_summarize_task  \\\n",
       "0  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "1  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "2  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "3  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "4  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "5  1. Summarize the text for a LinkedIn post.\\n\\nIn the summary, cover the following information:  ...   \n",
       "\n",
       "                   folder  \\\n",
       "0  text/2023-07-11 for db   \n",
       "1  text/2023-07-11 for db   \n",
       "2  text/2023-07-11 for db   \n",
       "3  text/2023-07-11 for db   \n",
       "4  text/2023-07-11 for db   \n",
       "5  text/2023-07-11 for db   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  A recent study examined the recovery response from high-volume resistance exercise in young and ...   \n",
       "1  A recent study found that a high calcium and high protein nutritional intervention can reduce th...   \n",
       "2  Exercise snacks are short bursts of vigorous exercise performed periodically throughout the day....   \n",
       "3  A recent study investigated the effects of food cues and stress on highly palatable food craving...   \n",
       "4  A recent study found that mild dehydration can lead to increased pain sensitivity in women. The ...   \n",
       "5  Weight stigma is pervasive and has negative consequences on physical health. It is associated wi...   \n",
       "\n",
       "                                                                              headline  \\\n",
       "0                               New Study Shows How Exercise Recovery Changes with Age   \n",
       "1       New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults   \n",
       "2                         Exercise Snacks: A Time-Efficient Approach to Improve Health   \n",
       "3  New Research Reveals the Impact of Food Cues and Stress on Food Cravings and Intake   \n",
       "4           New research shows that dehydration can increase pain sensitivity in women   \n",
       "5                                     Weight Stigma and Its Impact on Health Behaviors   \n",
       "\n",
       "                                                                                        simple_summary  \n",
       "0  A recent study found that middle-aged individuals who regularly engage in resistance training ca...  \n",
       "1  A recent study has found that a specific nutritional intervention can help reduce the risk of fa...  \n",
       "2  Exercise snacks are a convenient and effective way to improve health and fitness. They involve s...  \n",
       "3  Check out this new study that explores how food cues and stress can impact our food cravings and...  \n",
       "4  New research suggests that staying hydrated is crucial for managing pain in women. A recent stud...  \n",
       "5  Weight stigma affects individuals of all body sizes and has a significant impact on their health...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters\n",
    "iteration_id = 1.13\n",
    "article_limit = None\n",
    "temperature = 0.7\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit)\n",
    "# sources_df\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 new prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Describe the interesting points of the research to your coworker.',\n",
       " '1. Summarize for an instagram post.',\n",
       " '1. Tell your friend about the research in a text message.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "summarize_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 5\n",
      "**Text #6 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_2203.json\n",
      "Processing 6_prompt00...\n",
      "Processing 6_prompt01...\n",
      "Processing 6_prompt02...\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 5_prompt02...\n",
      "Processing 4_prompt00...\n",
      "Processing 4_prompt01...\n",
      "Processing 4_prompt02...\n",
      "Processing 3_prompt00...\n",
      "Processing 3_prompt01...\n",
      "Processing 3_prompt02...\n",
      "Processing 2_prompt00...\n",
      "Processing 2_prompt01...\n",
      "Processing 2_prompt02...\n",
      "Original summaries DataFrame shape: (45, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        # rating_original_content=row['rating_original_content'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        # rating_simple_content=row['rating_simple_content'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            value = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary).group(1)\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.4\n",
    "article_limit = 5\n",
    "temperature = 0.7\n",
    "n_choices = 3\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit, order='DESC')\n",
    "# sources_df\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# # bulk_append(qna_dict[iteration_id])\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 45 rows to the database...\n",
      "\tReference #6: New research reveals the negative impact of weight stigma on health behaviors\n",
      "\tReference #6: New Research Shows How Weight Stigma Affects Health Behaviors\n",
      "\tReference #6: New Research Shows Weight Stigma Affects Health Behaviors\n",
      "\tReference #6: Weight Stigma and Health Behaviors: New Research Findings\n",
      "\tReference #6: How weight stigma affects health behaviors\n",
      "\tReference #6: Weight stigma and its impact on health behaviors\n",
      "\tReference #6: New Research Shows Weight Stigma Negatively Affects Health Behaviors\n",
      "\tReference #6: New Research Reveals the Impact of Weight Stigma on Health Behaviors\n",
      "\tReference #6: New Research Reveals Impact of Weight Stigma on Health Behaviors\n",
      "\tReference #5: New Research Shows Dehydration Can Increase Pain Sensitivity in Women\n",
      "\tReference #5: New research shows that dehydration can increase pain sensitivity in women\n",
      "\tReference #5: New Research Reveals How Dehydration Can Impact Pain Sensitivity\n",
      "\tReference #5: New Research Shows Dehydration May Increase Pain Sensitivity in Women\n",
      "\tReference #5: New research shows that mild dehydration can increase pain sensitivity in women\n",
      "\tReference #5: New Study Shows Hydration Affects Pain Sensitivity in Women\n",
      "\tReference #5: New research shows that dehydration can increase pain sensitivity\n",
      "\tReference #5: New research shows that dehydration can increase pain sensitivity\n",
      "\tReference #5: New research shows that dehydration can increase pain sensitivity in women\n",
      "\tReference #4: New Study: Food Cues and Stress Increase Cravings for Unhealthy Foods\n",
      "\tReference #4: New research on the impact of food cues and stress on food cravings and intake\n",
      "\tReference #4: New Study Finds Stress and Food Cues Increase Cravings for Unhealthy Foods\n",
      "\tReference #4: New Research Highlights the Impact of Food Cues and Stress on Food Cravings and Intake\n",
      "\tReference #4: New Research on Food Craving and Intake\n",
      "\tReference #4: New research reveals how food cues and stress affect food cravings and intake\n",
      "\tReference #4: New research on food cravings and stress-induced eating\n",
      "\tReference #4: New Research Reveals the Impact of Food Cues and Stress on Cravings and Snacking\n",
      "\tReference #4: New research reveals the impact of food cues and stress on overeating\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Way to Improve Fitness and Health\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Way to Improve Health\n",
      "\tReference #3: Get Fit with Exercise Snacks: Quick and Effective Workouts\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #3: New Research Reveals an Easy and Time-Efficient Way to Improve Health\n",
      "\tReference #3: New Research Shows Quick Exercise Snacks Improve Health\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #2: Nutritional intervention reduces falls and fractures in older adults\n",
      "\tReference #2: New Research Shows High Calcium and Protein Diet Reduces Fracture Risk in Older Adults\n",
      "\tReference #2: New Study Shows Nutritional Intervention Reduces Fracture Risk in Older Adults\n",
      "\tReference #2: New Research Shows Nutritional Intervention Can Reduce Falls and Fractures in Older Adults\n",
      "\tReference #2: New Research Finds Nutritional Intervention Can Reduce Fracture Risk in Older Adults\n",
      "\tReference #2: New research shows a simple dietary intervention can reduce the risk of falls and fractures in older adults\n",
      "\tReference #2: New research shows that a simple nutritional intervention can reduce the risk of falls and fractures in older adults\n",
      "\tReference #2: New research shows a simple dietary intervention can reduce the risk of falls and fractures in older adults\n",
      "\tReference #2: New Research Shows Nutritional Intervention Can Reduce Fracture Risk\n",
      "Data added successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 22:02:20.768572-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and can negatively ...</td>\n",
       "      <td>New research reveals the negative impact of we...</td>\n",
       "      <td>New research has shown that weight stigma can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 22:02:20.768572-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma has negative effects on health b...</td>\n",
       "      <td>New Research Shows How Weight Stigma Affects H...</td>\n",
       "      <td>Weight stigma negatively impacts health behavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 22:02:20.768572-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>3</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that weight stigma, or di...</td>\n",
       "      <td>New Research Shows Weight Stigma Affects Healt...</td>\n",
       "      <td>New research has shown that weight stigma, or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 22:02:26.456220-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>New research shows that weight stigma has a si...</td>\n",
       "      <td>Weight Stigma and Health Behaviors: New Resear...</td>\n",
       "      <td>New research reveals that weight stigma can ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 22:02:26.456220-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma can have negative effects on phy...</td>\n",
       "      <td>How weight stigma affects health behaviors</td>\n",
       "      <td>Discover how weight stigma can affect your hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-12 22:02:26.456220-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>3</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and can negatively ...</td>\n",
       "      <td>Weight stigma and its impact on health behaviors</td>\n",
       "      <td>Weight stigma is a serious issue that affects ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-12 22:02:30.384190-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma, or the discrimination against i...</td>\n",
       "      <td>New Research Shows Weight Stigma Negatively Af...</td>\n",
       "      <td>New research has found that weight stigma, or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-12 22:02:30.384190-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma, the discrimination and mistreat...</td>\n",
       "      <td>New Research Reveals the Impact of Weight Stig...</td>\n",
       "      <td>New research has shown that weight stigma, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-12 22:02:30.384190-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>3</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma, or discrimination against indiv...</td>\n",
       "      <td>New Research Reveals Impact of Weight Stigma o...</td>\n",
       "      <td>Weight stigma, or discrimination based on weig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-12 22:02:34.779773-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New Research Shows Dehydration Can Increase Pa...</td>\n",
       "      <td>New research suggests that not drinking enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-07-12 22:02:34.779773-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New research shows that dehydration can increa...</td>\n",
       "      <td>New research shows that dehydration can increa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-07-12 22:02:34.779773-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New Research Reveals How Dehydration Can Impac...</td>\n",
       "      <td>New research has shown that not drinking enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-07-12 22:02:39.715011-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Recent research found that mild dehydration ca...</td>\n",
       "      <td>New Research Shows Dehydration May Increase Pa...</td>\n",
       "      <td>New research suggests that not drinking enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-07-12 22:02:39.715011-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration, ca...</td>\n",
       "      <td>New research shows that mild dehydration can i...</td>\n",
       "      <td>New research has found that not drinking enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-07-12 22:02:39.715011-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New Study Shows Hydration Affects Pain Sensiti...</td>\n",
       "      <td>Did you know that staying hydrated can affect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-07-12 22:02:44.030955-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New research shows that dehydration can increa...</td>\n",
       "      <td>New research has shown that not drinking enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-07-12 22:02:44.030955-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New research shows that dehydration can increa...</td>\n",
       "      <td>New research has shown that dehydration can in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-07-12 22:02:44.030955-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New research shows that dehydration can increa...</td>\n",
       "      <td>Did you know that not drinking enough water ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-07-12 22:02:49.366340-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New Study: Food Cues and Stress Increase Cravi...</td>\n",
       "      <td>New research suggests that food cues and stres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-07-12 22:02:49.366340-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>2</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study examined the effects of exposur...</td>\n",
       "      <td>New research on the impact of food cues and st...</td>\n",
       "      <td>Check out this interesting research that explo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-07-12 22:02:49.366340-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>3</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a hospital setting...</td>\n",
       "      <td>New Study Finds Stress and Food Cues Increase ...</td>\n",
       "      <td>A new study has found that stress and food cue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-07-12 22:02:54.044488-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New Research Highlights the Impact of Food Cue...</td>\n",
       "      <td>Check out this fascinating study that shows ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-07-12 22:02:54.044488-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>2</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that exposure to food cue...</td>\n",
       "      <td>New Research on Food Craving and Intake</td>\n",
       "      <td>New research suggests that exposure to food cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-07-12 22:02:54.044488-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>3</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New research reveals how food cues and stress ...</td>\n",
       "      <td>Ever wondered why you crave junk food when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-07-12 22:02:57.401173-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study investigated the effects of foo...</td>\n",
       "      <td>New research on food cravings and stress-induc...</td>\n",
       "      <td>Check out this new research on how food cravin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-07-12 22:02:57.401173-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>2</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New Research Reveals the Impact of Food Cues a...</td>\n",
       "      <td>New research has shown that exposure to food c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-07-12 22:02:57.401173-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>3</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New research reveals the impact of food cues a...</td>\n",
       "      <td>Researchers have found that exposure to food c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-07-12 22:03:01.980049-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks, which are short bursts of vig...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Approach to ...</td>\n",
       "      <td>Exercise snacks are short bursts of vigorous e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-07-12 22:03:01.980049-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short, intense bursts of e...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Approach to ...</td>\n",
       "      <td>Exercise snacks are a convenient and time-effi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-07-12 22:03:01.980049-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short bouts of vigorous ex...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Way to Impro...</td>\n",
       "      <td>Exercise snacks are a simple and effective way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-07-12 22:03:07.155879-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short bouts of vigorous ex...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Way to Impro...</td>\n",
       "      <td>Learn how exercise snacks, short bursts of vig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-07-12 22:03:07.155879-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are isolated bouts of vigorous...</td>\n",
       "      <td>Get Fit with Exercise Snacks: Quick and Effect...</td>\n",
       "      <td>Looking to get fit? Try exercise snacks! These...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-07-12 22:03:07.155879-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short bursts of vigorous e...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Approach to ...</td>\n",
       "      <td>Exercise snacks are short bursts of vigorous e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-07-12 22:03:11.657022-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks, short bursts of vigorous exer...</td>\n",
       "      <td>New Research Reveals an Easy and Time-Efficien...</td>\n",
       "      <td>New research has found a simple and convenient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-07-12 22:03:11.657022-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks, which are short bursts of vig...</td>\n",
       "      <td>New Research Shows Quick Exercise Snacks Impro...</td>\n",
       "      <td>Did you know that short bursts of exercise thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-07-12 22:03:11.657022-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short bursts of vigorous e...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Approach to ...</td>\n",
       "      <td>Get fit and improve your health with exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-07-12 22:03:17.151134-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>Nutritional intervention reduces falls and fra...</td>\n",
       "      <td>A recent study found that increasing the intak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-07-12 22:03:17.151134-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Research Shows High Calcium and Protein Di...</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-07-12 22:03:17.151134-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>3</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Study Shows Nutritional Intervention Reduc...</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-07-12 22:03:21.754936-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Research Shows Nutritional Intervention Ca...</td>\n",
       "      <td>New research has found that a specific diet ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-07-12 22:03:21.754936-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Research Finds Nutritional Intervention Ca...</td>\n",
       "      <td>New research shows that a simple dietary inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-07-12 22:03:21.754936-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>3</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that increasing calcium a...</td>\n",
       "      <td>New research shows a simple dietary interventi...</td>\n",
       "      <td>New research suggests that increasing calcium ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-07-12 22:03:25.512596-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New research shows that a simple nutritional i...</td>\n",
       "      <td>New research shows that a simple change in die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-07-12 22:03:25.512596-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that increasing calcium a...</td>\n",
       "      <td>New research shows a simple dietary interventi...</td>\n",
       "      <td>A recent study found that increasing calcium a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-07-12 22:03:25.512596-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>3</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that a high calcium and h...</td>\n",
       "      <td>New Research Shows Nutritional Intervention Ca...</td>\n",
       "      <td>New research has found that a specific diet in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "0   2023-07-12 22:02:20.768572-07:00             6   \n",
       "1   2023-07-12 22:02:20.768572-07:00             6   \n",
       "2   2023-07-12 22:02:20.768572-07:00             6   \n",
       "3   2023-07-12 22:02:26.456220-07:00             6   \n",
       "4   2023-07-12 22:02:26.456220-07:00             6   \n",
       "5   2023-07-12 22:02:26.456220-07:00             6   \n",
       "6   2023-07-12 22:02:30.384190-07:00             6   \n",
       "7   2023-07-12 22:02:30.384190-07:00             6   \n",
       "8   2023-07-12 22:02:30.384190-07:00             6   \n",
       "9   2023-07-12 22:02:34.779773-07:00             5   \n",
       "10  2023-07-12 22:02:34.779773-07:00             5   \n",
       "11  2023-07-12 22:02:34.779773-07:00             5   \n",
       "12  2023-07-12 22:02:39.715011-07:00             5   \n",
       "13  2023-07-12 22:02:39.715011-07:00             5   \n",
       "14  2023-07-12 22:02:39.715011-07:00             5   \n",
       "15  2023-07-12 22:02:44.030955-07:00             5   \n",
       "16  2023-07-12 22:02:44.030955-07:00             5   \n",
       "17  2023-07-12 22:02:44.030955-07:00             5   \n",
       "18  2023-07-12 22:02:49.366340-07:00             4   \n",
       "19  2023-07-12 22:02:49.366340-07:00             4   \n",
       "20  2023-07-12 22:02:49.366340-07:00             4   \n",
       "21  2023-07-12 22:02:54.044488-07:00             4   \n",
       "22  2023-07-12 22:02:54.044488-07:00             4   \n",
       "23  2023-07-12 22:02:54.044488-07:00             4   \n",
       "24  2023-07-12 22:02:57.401173-07:00             4   \n",
       "25  2023-07-12 22:02:57.401173-07:00             4   \n",
       "26  2023-07-12 22:02:57.401173-07:00             4   \n",
       "27  2023-07-12 22:03:01.980049-07:00             3   \n",
       "28  2023-07-12 22:03:01.980049-07:00             3   \n",
       "29  2023-07-12 22:03:01.980049-07:00             3   \n",
       "30  2023-07-12 22:03:07.155879-07:00             3   \n",
       "31  2023-07-12 22:03:07.155879-07:00             3   \n",
       "32  2023-07-12 22:03:07.155879-07:00             3   \n",
       "33  2023-07-12 22:03:11.657022-07:00             3   \n",
       "34  2023-07-12 22:03:11.657022-07:00             3   \n",
       "35  2023-07-12 22:03:11.657022-07:00             3   \n",
       "36  2023-07-12 22:03:17.151134-07:00             2   \n",
       "37  2023-07-12 22:03:17.151134-07:00             2   \n",
       "38  2023-07-12 22:03:17.151134-07:00             2   \n",
       "39  2023-07-12 22:03:21.754936-07:00             2   \n",
       "40  2023-07-12 22:03:21.754936-07:00             2   \n",
       "41  2023-07-12 22:03:21.754936-07:00             2   \n",
       "42  2023-07-12 22:03:25.512596-07:00             2   \n",
       "43  2023-07-12 22:03:25.512596-07:00             2   \n",
       "44  2023-07-12 22:03:25.512596-07:00             2   \n",
       "\n",
       "                                        article_title  choice  \\\n",
       "0   Weight stigma and health behaviors: evidence f...       1   \n",
       "1   Weight stigma and health behaviors: evidence f...       2   \n",
       "2   Weight stigma and health behaviors: evidence f...       3   \n",
       "3   Weight stigma and health behaviors: evidence f...       1   \n",
       "4   Weight stigma and health behaviors: evidence f...       2   \n",
       "5   Weight stigma and health behaviors: evidence f...       3   \n",
       "6   Weight stigma and health behaviors: evidence f...       1   \n",
       "7   Weight stigma and health behaviors: evidence f...       2   \n",
       "8   Weight stigma and health behaviors: evidence f...       3   \n",
       "9   Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "10  Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "11  Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "12  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "13  Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "14  Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "15  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "16  Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "17  Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "18  Food craving, cortisol and ghrelin responses i...       1   \n",
       "19  Food craving, cortisol and ghrelin responses i...       2   \n",
       "20  Food craving, cortisol and ghrelin responses i...       3   \n",
       "21  Food craving, cortisol and ghrelin responses i...       1   \n",
       "22  Food craving, cortisol and ghrelin responses i...       2   \n",
       "23  Food craving, cortisol and ghrelin responses i...       3   \n",
       "24  Food craving, cortisol and ghrelin responses i...       1   \n",
       "25  Food craving, cortisol and ghrelin responses i...       2   \n",
       "26  Food craving, cortisol and ghrelin responses i...       3   \n",
       "27  Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "28  Exercise Snacks A Novel Strategy to Improve Ca...       2   \n",
       "29  Exercise Snacks A Novel Strategy to Improve Ca...       3   \n",
       "30  Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "31  Exercise Snacks A Novel Strategy to Improve Ca...       2   \n",
       "32  Exercise Snacks A Novel Strategy to Improve Ca...       3   \n",
       "33  Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "34  Exercise Snacks A Novel Strategy to Improve Ca...       2   \n",
       "35  Exercise Snacks A Novel Strategy to Improve Ca...       3   \n",
       "36  Effect of dietary sources of calcium and prote...       1   \n",
       "37  Effect of dietary sources of calcium and prote...       2   \n",
       "38  Effect of dietary sources of calcium and prote...       3   \n",
       "39  Effect of dietary sources of calcium and prote...       1   \n",
       "40  Effect of dietary sources of calcium and prote...       2   \n",
       "41  Effect of dietary sources of calcium and prote...       3   \n",
       "42  Effect of dietary sources of calcium and prote...       1   \n",
       "43  Effect of dietary sources of calcium and prote...       2   \n",
       "44  Effect of dietary sources of calcium and prote...       3   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Weight stigma is pervasive. Higher weight indi...   \n",
       "1   Weight stigma is pervasive. Higher weight indi...   \n",
       "2   Weight stigma is pervasive. Higher weight indi...   \n",
       "3   Weight stigma is pervasive. Higher weight indi...   \n",
       "4   Weight stigma is pervasive. Higher weight indi...   \n",
       "5   Weight stigma is pervasive. Higher weight indi...   \n",
       "6   Weight stigma is pervasive. Higher weight indi...   \n",
       "7   Weight stigma is pervasive. Higher weight indi...   \n",
       "8   Weight stigma is pervasive. Higher weight indi...   \n",
       "9   Pain is recognized as a public health problem ...   \n",
       "10  Pain is recognized as a public health problem ...   \n",
       "11  Pain is recognized as a public health problem ...   \n",
       "12  Pain is recognized as a public health problem ...   \n",
       "13  Pain is recognized as a public health problem ...   \n",
       "14  Pain is recognized as a public health problem ...   \n",
       "15  Pain is recognized as a public health problem ...   \n",
       "16  Pain is recognized as a public health problem ...   \n",
       "17  Pain is recognized as a public health problem ...   \n",
       "18  The United States is at the forefront of the g...   \n",
       "19  The United States is at the forefront of the g...   \n",
       "20  The United States is at the forefront of the g...   \n",
       "21  The United States is at the forefront of the g...   \n",
       "22  The United States is at the forefront of the g...   \n",
       "23  The United States is at the forefront of the g...   \n",
       "24  The United States is at the forefront of the g...   \n",
       "25  The United States is at the forefront of the g...   \n",
       "26  The United States is at the forefront of the g...   \n",
       "27  We define exercise snacks as isolated ?1-min b...   \n",
       "28  We define exercise snacks as isolated ?1-min b...   \n",
       "29  We define exercise snacks as isolated ?1-min b...   \n",
       "30  We define exercise snacks as isolated ?1-min b...   \n",
       "31  We define exercise snacks as isolated ?1-min b...   \n",
       "32  We define exercise snacks as isolated ?1-min b...   \n",
       "33  We define exercise snacks as isolated ?1-min b...   \n",
       "34  We define exercise snacks as isolated ?1-min b...   \n",
       "35  We define exercise snacks as isolated ?1-min b...   \n",
       "36  Longevity increases the proportion of older ad...   \n",
       "37  Longevity increases the proportion of older ad...   \n",
       "38  Longevity increases the proportion of older ad...   \n",
       "39  Longevity increases the proportion of older ad...   \n",
       "40  Longevity increases the proportion of older ad...   \n",
       "41  Longevity increases the proportion of older ad...   \n",
       "42  Longevity increases the proportion of older ad...   \n",
       "43  Longevity increases the proportion of older ad...   \n",
       "44  Longevity increases the proportion of older ad...   \n",
       "\n",
       "                                          system_role                   model  \\\n",
       "0   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "8   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "9   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "10  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "11  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "12  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "13  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "14  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "15  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "16  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "17  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "18  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "19  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "20  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "21  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "22  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "23  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "24  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "25  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "26  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "27  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "28  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "29  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "30  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "31  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "32  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "33  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "34  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "35  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "36  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "37  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "38  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "39  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "40  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "41  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "42  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "43  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "44  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "    temperature                                          prep_step  \\\n",
       "0           0.7  In the summary, cover the following informatio...   \n",
       "1           0.7  In the summary, cover the following informatio...   \n",
       "2           0.7  In the summary, cover the following informatio...   \n",
       "3           0.7  In the summary, cover the following informatio...   \n",
       "4           0.7  In the summary, cover the following informatio...   \n",
       "5           0.7  In the summary, cover the following informatio...   \n",
       "6           0.7  In the summary, cover the following informatio...   \n",
       "7           0.7  In the summary, cover the following informatio...   \n",
       "8           0.7  In the summary, cover the following informatio...   \n",
       "9           0.7  In the summary, cover the following informatio...   \n",
       "10          0.7  In the summary, cover the following informatio...   \n",
       "11          0.7  In the summary, cover the following informatio...   \n",
       "12          0.7  In the summary, cover the following informatio...   \n",
       "13          0.7  In the summary, cover the following informatio...   \n",
       "14          0.7  In the summary, cover the following informatio...   \n",
       "15          0.7  In the summary, cover the following informatio...   \n",
       "16          0.7  In the summary, cover the following informatio...   \n",
       "17          0.7  In the summary, cover the following informatio...   \n",
       "18          0.7  In the summary, cover the following informatio...   \n",
       "19          0.7  In the summary, cover the following informatio...   \n",
       "20          0.7  In the summary, cover the following informatio...   \n",
       "21          0.7  In the summary, cover the following informatio...   \n",
       "22          0.7  In the summary, cover the following informatio...   \n",
       "23          0.7  In the summary, cover the following informatio...   \n",
       "24          0.7  In the summary, cover the following informatio...   \n",
       "25          0.7  In the summary, cover the following informatio...   \n",
       "26          0.7  In the summary, cover the following informatio...   \n",
       "27          0.7  In the summary, cover the following informatio...   \n",
       "28          0.7  In the summary, cover the following informatio...   \n",
       "29          0.7  In the summary, cover the following informatio...   \n",
       "30          0.7  In the summary, cover the following informatio...   \n",
       "31          0.7  In the summary, cover the following informatio...   \n",
       "32          0.7  In the summary, cover the following informatio...   \n",
       "33          0.7  In the summary, cover the following informatio...   \n",
       "34          0.7  In the summary, cover the following informatio...   \n",
       "35          0.7  In the summary, cover the following informatio...   \n",
       "36          0.7  In the summary, cover the following informatio...   \n",
       "37          0.7  In the summary, cover the following informatio...   \n",
       "38          0.7  In the summary, cover the following informatio...   \n",
       "39          0.7  In the summary, cover the following informatio...   \n",
       "40          0.7  In the summary, cover the following informatio...   \n",
       "41          0.7  In the summary, cover the following informatio...   \n",
       "42          0.7  In the summary, cover the following informatio...   \n",
       "43          0.7  In the summary, cover the following informatio...   \n",
       "44          0.7  In the summary, cover the following informatio...   \n",
       "\n",
       "                                       summarize_task  \\\n",
       "0   1. Describe the interesting points of the rese...   \n",
       "1   1. Describe the interesting points of the rese...   \n",
       "2   1. Describe the interesting points of the rese...   \n",
       "3                 1. Summarize for an instagram post.   \n",
       "4                 1. Summarize for an instagram post.   \n",
       "5                 1. Summarize for an instagram post.   \n",
       "6   1. Tell your friend about the research in a te...   \n",
       "7   1. Tell your friend about the research in a te...   \n",
       "8   1. Tell your friend about the research in a te...   \n",
       "9   1. Describe the interesting points of the rese...   \n",
       "10  1. Describe the interesting points of the rese...   \n",
       "11  1. Describe the interesting points of the rese...   \n",
       "12                1. Summarize for an instagram post.   \n",
       "13                1. Summarize for an instagram post.   \n",
       "14                1. Summarize for an instagram post.   \n",
       "15  1. Tell your friend about the research in a te...   \n",
       "16  1. Tell your friend about the research in a te...   \n",
       "17  1. Tell your friend about the research in a te...   \n",
       "18  1. Describe the interesting points of the rese...   \n",
       "19  1. Describe the interesting points of the rese...   \n",
       "20  1. Describe the interesting points of the rese...   \n",
       "21                1. Summarize for an instagram post.   \n",
       "22                1. Summarize for an instagram post.   \n",
       "23                1. Summarize for an instagram post.   \n",
       "24  1. Tell your friend about the research in a te...   \n",
       "25  1. Tell your friend about the research in a te...   \n",
       "26  1. Tell your friend about the research in a te...   \n",
       "27  1. Describe the interesting points of the rese...   \n",
       "28  1. Describe the interesting points of the rese...   \n",
       "29  1. Describe the interesting points of the rese...   \n",
       "30                1. Summarize for an instagram post.   \n",
       "31                1. Summarize for an instagram post.   \n",
       "32                1. Summarize for an instagram post.   \n",
       "33  1. Tell your friend about the research in a te...   \n",
       "34  1. Tell your friend about the research in a te...   \n",
       "35  1. Tell your friend about the research in a te...   \n",
       "36  1. Describe the interesting points of the rese...   \n",
       "37  1. Describe the interesting points of the rese...   \n",
       "38  1. Describe the interesting points of the rese...   \n",
       "39                1. Summarize for an instagram post.   \n",
       "40                1. Summarize for an instagram post.   \n",
       "41                1. Summarize for an instagram post.   \n",
       "42  1. Tell your friend about the research in a te...   \n",
       "43  1. Tell your friend about the research in a te...   \n",
       "44  1. Tell your friend about the research in a te...   \n",
       "\n",
       "                                            edit_task  \\\n",
       "0   Once you have written your text message:     \\...   \n",
       "1   Once you have written your text message:     \\...   \n",
       "2   Once you have written your text message:     \\...   \n",
       "3   Once you have written your text message:     \\...   \n",
       "4   Once you have written your text message:     \\...   \n",
       "5   Once you have written your text message:     \\...   \n",
       "6   Once you have written your text message:     \\...   \n",
       "7   Once you have written your text message:     \\...   \n",
       "8   Once you have written your text message:     \\...   \n",
       "9   Once you have written your text message:     \\...   \n",
       "10  Once you have written your text message:     \\...   \n",
       "11  Once you have written your text message:     \\...   \n",
       "12  Once you have written your text message:     \\...   \n",
       "13  Once you have written your text message:     \\...   \n",
       "14  Once you have written your text message:     \\...   \n",
       "15  Once you have written your text message:     \\...   \n",
       "16  Once you have written your text message:     \\...   \n",
       "17  Once you have written your text message:     \\...   \n",
       "18  Once you have written your text message:     \\...   \n",
       "19  Once you have written your text message:     \\...   \n",
       "20  Once you have written your text message:     \\...   \n",
       "21  Once you have written your text message:     \\...   \n",
       "22  Once you have written your text message:     \\...   \n",
       "23  Once you have written your text message:     \\...   \n",
       "24  Once you have written your text message:     \\...   \n",
       "25  Once you have written your text message:     \\...   \n",
       "26  Once you have written your text message:     \\...   \n",
       "27  Once you have written your text message:     \\...   \n",
       "28  Once you have written your text message:     \\...   \n",
       "29  Once you have written your text message:     \\...   \n",
       "30  Once you have written your text message:     \\...   \n",
       "31  Once you have written your text message:     \\...   \n",
       "32  Once you have written your text message:     \\...   \n",
       "33  Once you have written your text message:     \\...   \n",
       "34  Once you have written your text message:     \\...   \n",
       "35  Once you have written your text message:     \\...   \n",
       "36  Once you have written your text message:     \\...   \n",
       "37  Once you have written your text message:     \\...   \n",
       "38  Once you have written your text message:     \\...   \n",
       "39  Once you have written your text message:     \\...   \n",
       "40  Once you have written your text message:     \\...   \n",
       "41  Once you have written your text message:     \\...   \n",
       "42  Once you have written your text message:     \\...   \n",
       "43  Once you have written your text message:     \\...   \n",
       "44  Once you have written your text message:     \\...   \n",
       "\n",
       "                                        simplify_task  \\\n",
       "0   3. If needed, rewrite the text using terms app...   \n",
       "1   3. If needed, rewrite the text using terms app...   \n",
       "2   3. If needed, rewrite the text using terms app...   \n",
       "3   3. If needed, rewrite the text using terms app...   \n",
       "4   3. If needed, rewrite the text using terms app...   \n",
       "5   3. If needed, rewrite the text using terms app...   \n",
       "6   3. If needed, rewrite the text using terms app...   \n",
       "7   3. If needed, rewrite the text using terms app...   \n",
       "8   3. If needed, rewrite the text using terms app...   \n",
       "9   3. If needed, rewrite the text using terms app...   \n",
       "10  3. If needed, rewrite the text using terms app...   \n",
       "11  3. If needed, rewrite the text using terms app...   \n",
       "12  3. If needed, rewrite the text using terms app...   \n",
       "13  3. If needed, rewrite the text using terms app...   \n",
       "14  3. If needed, rewrite the text using terms app...   \n",
       "15  3. If needed, rewrite the text using terms app...   \n",
       "16  3. If needed, rewrite the text using terms app...   \n",
       "17  3. If needed, rewrite the text using terms app...   \n",
       "18  3. If needed, rewrite the text using terms app...   \n",
       "19  3. If needed, rewrite the text using terms app...   \n",
       "20  3. If needed, rewrite the text using terms app...   \n",
       "21  3. If needed, rewrite the text using terms app...   \n",
       "22  3. If needed, rewrite the text using terms app...   \n",
       "23  3. If needed, rewrite the text using terms app...   \n",
       "24  3. If needed, rewrite the text using terms app...   \n",
       "25  3. If needed, rewrite the text using terms app...   \n",
       "26  3. If needed, rewrite the text using terms app...   \n",
       "27  3. If needed, rewrite the text using terms app...   \n",
       "28  3. If needed, rewrite the text using terms app...   \n",
       "29  3. If needed, rewrite the text using terms app...   \n",
       "30  3. If needed, rewrite the text using terms app...   \n",
       "31  3. If needed, rewrite the text using terms app...   \n",
       "32  3. If needed, rewrite the text using terms app...   \n",
       "33  3. If needed, rewrite the text using terms app...   \n",
       "34  3. If needed, rewrite the text using terms app...   \n",
       "35  3. If needed, rewrite the text using terms app...   \n",
       "36  3. If needed, rewrite the text using terms app...   \n",
       "37  3. If needed, rewrite the text using terms app...   \n",
       "38  3. If needed, rewrite the text using terms app...   \n",
       "39  3. If needed, rewrite the text using terms app...   \n",
       "40  3. If needed, rewrite the text using terms app...   \n",
       "41  3. If needed, rewrite the text using terms app...   \n",
       "42  3. If needed, rewrite the text using terms app...   \n",
       "43  3. If needed, rewrite the text using terms app...   \n",
       "44  3. If needed, rewrite the text using terms app...   \n",
       "\n",
       "                      simplify_audience  \\\n",
       "0   people without a science background   \n",
       "1   people without a science background   \n",
       "2   people without a science background   \n",
       "3   people without a science background   \n",
       "4   people without a science background   \n",
       "5   people without a science background   \n",
       "6   people without a science background   \n",
       "7   people without a science background   \n",
       "8   people without a science background   \n",
       "9   people without a science background   \n",
       "10  people without a science background   \n",
       "11  people without a science background   \n",
       "12  people without a science background   \n",
       "13  people without a science background   \n",
       "14  people without a science background   \n",
       "15  people without a science background   \n",
       "16  people without a science background   \n",
       "17  people without a science background   \n",
       "18  people without a science background   \n",
       "19  people without a science background   \n",
       "20  people without a science background   \n",
       "21  people without a science background   \n",
       "22  people without a science background   \n",
       "23  people without a science background   \n",
       "24  people without a science background   \n",
       "25  people without a science background   \n",
       "26  people without a science background   \n",
       "27  people without a science background   \n",
       "28  people without a science background   \n",
       "29  people without a science background   \n",
       "30  people without a science background   \n",
       "31  people without a science background   \n",
       "32  people without a science background   \n",
       "33  people without a science background   \n",
       "34  people without a science background   \n",
       "35  people without a science background   \n",
       "36  people without a science background   \n",
       "37  people without a science background   \n",
       "38  people without a science background   \n",
       "39  people without a science background   \n",
       "40  people without a science background   \n",
       "41  people without a science background   \n",
       "42  people without a science background   \n",
       "43  people without a science background   \n",
       "44  people without a science background   \n",
       "\n",
       "                                          format_task  \\\n",
       "0   4. Return your final response in a JSON format...   \n",
       "1   4. Return your final response in a JSON format...   \n",
       "2   4. Return your final response in a JSON format...   \n",
       "3   4. Return your final response in a JSON format...   \n",
       "4   4. Return your final response in a JSON format...   \n",
       "5   4. Return your final response in a JSON format...   \n",
       "6   4. Return your final response in a JSON format...   \n",
       "7   4. Return your final response in a JSON format...   \n",
       "8   4. Return your final response in a JSON format...   \n",
       "9   4. Return your final response in a JSON format...   \n",
       "10  4. Return your final response in a JSON format...   \n",
       "11  4. Return your final response in a JSON format...   \n",
       "12  4. Return your final response in a JSON format...   \n",
       "13  4. Return your final response in a JSON format...   \n",
       "14  4. Return your final response in a JSON format...   \n",
       "15  4. Return your final response in a JSON format...   \n",
       "16  4. Return your final response in a JSON format...   \n",
       "17  4. Return your final response in a JSON format...   \n",
       "18  4. Return your final response in a JSON format...   \n",
       "19  4. Return your final response in a JSON format...   \n",
       "20  4. Return your final response in a JSON format...   \n",
       "21  4. Return your final response in a JSON format...   \n",
       "22  4. Return your final response in a JSON format...   \n",
       "23  4. Return your final response in a JSON format...   \n",
       "24  4. Return your final response in a JSON format...   \n",
       "25  4. Return your final response in a JSON format...   \n",
       "26  4. Return your final response in a JSON format...   \n",
       "27  4. Return your final response in a JSON format...   \n",
       "28  4. Return your final response in a JSON format...   \n",
       "29  4. Return your final response in a JSON format...   \n",
       "30  4. Return your final response in a JSON format...   \n",
       "31  4. Return your final response in a JSON format...   \n",
       "32  4. Return your final response in a JSON format...   \n",
       "33  4. Return your final response in a JSON format...   \n",
       "34  4. Return your final response in a JSON format...   \n",
       "35  4. Return your final response in a JSON format...   \n",
       "36  4. Return your final response in a JSON format...   \n",
       "37  4. Return your final response in a JSON format...   \n",
       "38  4. Return your final response in a JSON format...   \n",
       "39  4. Return your final response in a JSON format...   \n",
       "40  4. Return your final response in a JSON format...   \n",
       "41  4. Return your final response in a JSON format...   \n",
       "42  4. Return your final response in a JSON format...   \n",
       "43  4. Return your final response in a JSON format...   \n",
       "44  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                  full_summarize_task                  folder  \\\n",
       "0   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "1   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "2   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "3   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "4   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "5   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "6   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "7   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "8   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "9   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "10  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "11  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "12  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "13  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "14  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "15  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "16  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "17  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "18  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "19  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "20  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "21  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "22  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "23  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "24  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "25  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "26  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "27  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "28  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "29  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "30  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "31  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "32  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "33  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "34  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "35  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "36  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "37  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "38  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "39  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "40  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "41  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "42  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "43  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "44  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Weight stigma is pervasive and can negatively ...   \n",
       "1   Weight stigma has negative effects on health b...   \n",
       "2   A recent study found that weight stigma, or di...   \n",
       "3   New research shows that weight stigma has a si...   \n",
       "4   Weight stigma can have negative effects on phy...   \n",
       "5   Weight stigma is pervasive and can negatively ...   \n",
       "6   Weight stigma, or the discrimination against i...   \n",
       "7   Weight stigma, the discrimination and mistreat...   \n",
       "8   Weight stigma, or discrimination against indiv...   \n",
       "9   A recent study found that mild dehydration can...   \n",
       "10  A recent study found that mild dehydration can...   \n",
       "11  A recent study found that mild dehydration can...   \n",
       "12  Recent research found that mild dehydration ca...   \n",
       "13  A recent study found that mild dehydration, ca...   \n",
       "14  A recent study found that mild dehydration can...   \n",
       "15  A recent study found that mild dehydration can...   \n",
       "16  A recent study found that mild dehydration can...   \n",
       "17  A recent study found that mild dehydration can...   \n",
       "18  A recent study conducted in a controlled hospi...   \n",
       "19  A recent study examined the effects of exposur...   \n",
       "20  A recent study conducted in a hospital setting...   \n",
       "21  A recent study conducted in a controlled hospi...   \n",
       "22  A recent study found that exposure to food cue...   \n",
       "23  A recent study conducted in a controlled hospi...   \n",
       "24  A recent study investigated the effects of foo...   \n",
       "25  A recent study conducted in a controlled hospi...   \n",
       "26  A recent study conducted in a controlled hospi...   \n",
       "27  Exercise snacks, which are short bursts of vig...   \n",
       "28  Exercise snacks are short, intense bursts of e...   \n",
       "29  Exercise snacks are short bouts of vigorous ex...   \n",
       "30  Exercise snacks are short bouts of vigorous ex...   \n",
       "31  Exercise snacks are isolated bouts of vigorous...   \n",
       "32  Exercise snacks are short bursts of vigorous e...   \n",
       "33  Exercise snacks, short bursts of vigorous exer...   \n",
       "34  Exercise snacks, which are short bursts of vig...   \n",
       "35  Exercise snacks are short bursts of vigorous e...   \n",
       "36  A recent study found that a high calcium and h...   \n",
       "37  A recent study found that a high calcium and h...   \n",
       "38  A recent study found that a high calcium and h...   \n",
       "39  A recent study found that a high calcium and h...   \n",
       "40  A recent study found that a high calcium and h...   \n",
       "41  A recent study found that increasing calcium a...   \n",
       "42  A recent study found that a high calcium and h...   \n",
       "43  A recent study found that increasing calcium a...   \n",
       "44  A recent study found that a high calcium and h...   \n",
       "\n",
       "                                             headline  \\\n",
       "0   New research reveals the negative impact of we...   \n",
       "1   New Research Shows How Weight Stigma Affects H...   \n",
       "2   New Research Shows Weight Stigma Affects Healt...   \n",
       "3   Weight Stigma and Health Behaviors: New Resear...   \n",
       "4          How weight stigma affects health behaviors   \n",
       "5    Weight stigma and its impact on health behaviors   \n",
       "6   New Research Shows Weight Stigma Negatively Af...   \n",
       "7   New Research Reveals the Impact of Weight Stig...   \n",
       "8   New Research Reveals Impact of Weight Stigma o...   \n",
       "9   New Research Shows Dehydration Can Increase Pa...   \n",
       "10  New research shows that dehydration can increa...   \n",
       "11  New Research Reveals How Dehydration Can Impac...   \n",
       "12  New Research Shows Dehydration May Increase Pa...   \n",
       "13  New research shows that mild dehydration can i...   \n",
       "14  New Study Shows Hydration Affects Pain Sensiti...   \n",
       "15  New research shows that dehydration can increa...   \n",
       "16  New research shows that dehydration can increa...   \n",
       "17  New research shows that dehydration can increa...   \n",
       "18  New Study: Food Cues and Stress Increase Cravi...   \n",
       "19  New research on the impact of food cues and st...   \n",
       "20  New Study Finds Stress and Food Cues Increase ...   \n",
       "21  New Research Highlights the Impact of Food Cue...   \n",
       "22            New Research on Food Craving and Intake   \n",
       "23  New research reveals how food cues and stress ...   \n",
       "24  New research on food cravings and stress-induc...   \n",
       "25  New Research Reveals the Impact of Food Cues a...   \n",
       "26  New research reveals the impact of food cues a...   \n",
       "27  Exercise Snacks: A Time-Efficient Approach to ...   \n",
       "28  Exercise Snacks: A Time-Efficient Approach to ...   \n",
       "29  Exercise Snacks: A Time-Efficient Way to Impro...   \n",
       "30  Exercise Snacks: A Time-Efficient Way to Impro...   \n",
       "31  Get Fit with Exercise Snacks: Quick and Effect...   \n",
       "32  Exercise Snacks: A Time-Efficient Approach to ...   \n",
       "33  New Research Reveals an Easy and Time-Efficien...   \n",
       "34  New Research Shows Quick Exercise Snacks Impro...   \n",
       "35  Exercise Snacks: A Time-Efficient Approach to ...   \n",
       "36  Nutritional intervention reduces falls and fra...   \n",
       "37  New Research Shows High Calcium and Protein Di...   \n",
       "38  New Study Shows Nutritional Intervention Reduc...   \n",
       "39  New Research Shows Nutritional Intervention Ca...   \n",
       "40  New Research Finds Nutritional Intervention Ca...   \n",
       "41  New research shows a simple dietary interventi...   \n",
       "42  New research shows that a simple nutritional i...   \n",
       "43  New research shows a simple dietary interventi...   \n",
       "44  New Research Shows Nutritional Intervention Ca...   \n",
       "\n",
       "                                       simple_summary  \n",
       "0   New research has shown that weight stigma can ...  \n",
       "1   Weight stigma negatively impacts health behavi...  \n",
       "2   New research has shown that weight stigma, or ...  \n",
       "3   New research reveals that weight stigma can ne...  \n",
       "4   Discover how weight stigma can affect your hea...  \n",
       "5   Weight stigma is a serious issue that affects ...  \n",
       "6   New research has found that weight stigma, or ...  \n",
       "7   New research has shown that weight stigma, the...  \n",
       "8   Weight stigma, or discrimination based on weig...  \n",
       "9   New research suggests that not drinking enough...  \n",
       "10  New research shows that dehydration can increa...  \n",
       "11  New research has shown that not drinking enoug...  \n",
       "12  New research suggests that not drinking enough...  \n",
       "13  New research has found that not drinking enoug...  \n",
       "14  Did you know that staying hydrated can affect ...  \n",
       "15  New research has shown that not drinking enoug...  \n",
       "16  New research has shown that dehydration can in...  \n",
       "17  Did you know that not drinking enough water ca...  \n",
       "18  New research suggests that food cues and stres...  \n",
       "19  Check out this interesting research that explo...  \n",
       "20  A new study has found that stress and food cue...  \n",
       "21  Check out this fascinating study that shows ho...  \n",
       "22  New research suggests that exposure to food cu...  \n",
       "23  Ever wondered why you crave junk food when you...  \n",
       "24  Check out this new research on how food cravin...  \n",
       "25  New research has shown that exposure to food c...  \n",
       "26  Researchers have found that exposure to food c...  \n",
       "27  Exercise snacks are short bursts of vigorous e...  \n",
       "28  Exercise snacks are a convenient and time-effi...  \n",
       "29  Exercise snacks are a simple and effective way...  \n",
       "30  Learn how exercise snacks, short bursts of vig...  \n",
       "31  Looking to get fit? Try exercise snacks! These...  \n",
       "32  Exercise snacks are short bursts of vigorous e...  \n",
       "33  New research has found a simple and convenient...  \n",
       "34  Did you know that short bursts of exercise thr...  \n",
       "35  Get fit and improve your health with exercise ...  \n",
       "36  A recent study found that increasing the intak...  \n",
       "37  A recent study found that a high calcium and h...  \n",
       "38  A recent study found that a high calcium and h...  \n",
       "39  New research has found that a specific diet ca...  \n",
       "40  New research shows that a simple dietary inter...  \n",
       "41  New research suggests that increasing calcium ...  \n",
       "42  New research shows that a simple change in die...  \n",
       "43  A recent study found that increasing calcium a...  \n",
       "44  New research has found that a specific diet in...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 add system role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id ASC\n",
      "**Text #1 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #1 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #1 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "1_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "1_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "1_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt02\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-12_2217.json\n",
      "Processing 1_prompt00...\n",
      "Processing 1_prompt01...\n",
      "Processing 1_prompt02...\n",
      "Processing 2_prompt00...\n",
      "Processing 2_prompt01...\n",
      "Processing 2_prompt02...\n",
      "Processing 3_prompt00...\n",
      "Processing 3_prompt01...\n",
      "Processing 3_prompt02...\n",
      "Processing 4_prompt00...\n",
      "Processing 4_prompt01...\n",
      "Processing 4_prompt02...\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 5_prompt02...\n",
      "Processing 6_prompt00...\n",
      "Processing 6_prompt01...\n",
      "Processing 6_prompt02...\n",
      "Error converting summary column to JSON: Expecting ',' delimiter: line 5 column 553 (char 1332); will do row by row\n",
      "Error converting summary 11 to JSON: Expecting ',' delimiter: line 5 column 553 (char 1332)\n",
      "Error converting summary 12 to JSON: Expecting property name enclosed in double quotes: line 3 column 396 (char 1498)\n",
      "Error converting summary 15 to JSON: Invalid control character at: line 2 column 451 (char 550)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 384\u001b[0m, in \u001b[0;36mextract_summary.<locals>.extract_value_from_key\u001b[1;34m(summary, key)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     \u001b[39mreturn\u001b[39;00m summary[key]\n\u001b[0;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 425\u001b[0m\n\u001b[0;32m    416\u001b[0m chaining_dict \u001b[39m=\u001b[39m batch_summarize(\n\u001b[0;32m    417\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task, \n\u001b[0;32m    418\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m    423\u001b[0m     )\n\u001b[0;32m    424\u001b[0m \u001b[39m# # chaining_dict[iteration_id]\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m    426\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[39m# # Add rows from results to summaries and prompts table\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[39m# bulk_append(qna_dict[iteration_id])\u001b[39;00m\n\u001b[0;32m    430\u001b[0m qna_dict[iteration_id]\n",
      "Cell \u001b[1;32mIn[11], line 353\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    347\u001b[0m     dfs_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m    348\u001b[0m         chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna, \n\u001b[0;32m    349\u001b[0m         index\u001b[39m=\u001b[39m[choice \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[0;32m    350\u001b[0m         )\n\u001b[0;32m    352\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 353\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    354\u001b[0m columns \u001b[39m=\u001b[39m qna_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    355\u001b[0m columns\u001b[39m.\u001b[39mremove(\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 391\u001b[0m, in \u001b[0;36mextract_summary\u001b[1;34m(df, summary_column)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39m# Extract 'headline' and 'body' values\u001b[39;00m\n\u001b[0;32m    390\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: extract_value_from_key(x, \u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m--> 391\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msimple_summary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: extract_value_from_key(x, \u001b[39m'\u001b[39;49m\u001b[39maudience\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m    392\u001b[0m df[summary_column] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: extract_value_from_key(x, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    394\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[11], line 391\u001b[0m, in \u001b[0;36mextract_summary.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39m# Extract 'headline' and 'body' values\u001b[39;00m\n\u001b[0;32m    390\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: extract_value_from_key(x, \u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m--> 391\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msimple_summary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: extract_value_from_key(x, \u001b[39m'\u001b[39;49m\u001b[39maudience\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m    392\u001b[0m df[summary_column] \u001b[39m=\u001b[39m df[summary_column]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: extract_value_from_key(x, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    394\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "Cell \u001b[1;32mIn[11], line 386\u001b[0m, in \u001b[0;36mextract_summary.<locals>.extract_value_from_key\u001b[1;34m(summary, key)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[39mreturn\u001b[39;00m summary[key]\n\u001b[0;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m--> 386\u001b[0m     value \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msearch(\u001b[39mrf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mkey\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms*\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m([^\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]+)\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m, summary)\u001b[39m.\u001b[39;49mgroup(\u001b[39m1\u001b[39m)\n\u001b[0;32m    387\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            value = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary).group(1)\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.5\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit)\n",
    "# sources_df\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sample_Chaining_attr in module response_processing:\n",
      "\n",
      "sample_Chaining_attr(chaining_dict, iteration_id)\n",
      "    Look at the first set of attributes/results from the Chaining instances.\n",
      "    \n",
      "    Parameters:\n",
      "        - chaining_dict (dict): Dictionary of Chaining instances, \n",
      "            simple_summaries, or added relevance summaries.\n",
      "        - iteration_id (int or float): iteration_id of when the scripts were run.\n",
      "    \n",
      "    Returns: \n",
      "        (dict) Results from the first text and prompt combination.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sample_Chaining_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'New Research: Minimizing Muscle Loss as You Age',\n",
       " 'body': 'Key points: Changes in muscle mass, function, and neuromuscular activation contribute to declines in quality of life as we age. However, participating in recreational resistance training can help minimize these declines. Middle-aged adults (40-59 years) showed similar recovery from exercise compared to younger adults (18-30 years) in terms of muscle strength, muscle soreness, inflammation levels, and muscle damage. These findings can help us understand the importance of exercise in maintaining muscle function as we get older.',\n",
       " 'audience': 'Key points: Changes in muscle mass and function as we age can be minimized by participating in regular resistance training. Middle-aged adults recover from exercise similarly to younger adults in terms of strength, soreness, inflammation, and muscle damage. This underscores the importance of exercise for maintaining muscle function as we age.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(sample_Chaining_attr(chaining_dict, iteration_id)['qna']['summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_prompt00': <__main__.Chaining at 0x2a207fd3e10>,\n",
       " '1_prompt01': <__main__.Chaining at 0x2a20806e590>,\n",
       " '1_prompt02': <__main__.Chaining at 0x2a20846af10>,\n",
       " '2_prompt00': <__main__.Chaining at 0x2a20846b550>,\n",
       " '2_prompt01': <__main__.Chaining at 0x2a2080e9fd0>,\n",
       " '2_prompt02': <__main__.Chaining at 0x2a20846a6d0>,\n",
       " '3_prompt00': <__main__.Chaining at 0x2a2080eb450>,\n",
       " '3_prompt01': <__main__.Chaining at 0x2a2080d7390>,\n",
       " '3_prompt02': <__main__.Chaining at 0x2a2080d4290>,\n",
       " '4_prompt00': <__main__.Chaining at 0x2a2080d5110>,\n",
       " '4_prompt01': <__main__.Chaining at 0x2a2080d5150>,\n",
       " '4_prompt02': <__main__.Chaining at 0x2a2080d79d0>,\n",
       " '5_prompt00': <__main__.Chaining at 0x2a2080d6ad0>,\n",
       " '5_prompt01': <__main__.Chaining at 0x2a207fd29d0>,\n",
       " '5_prompt02': <__main__.Chaining at 0x2a207fd1ed0>,\n",
       " '6_prompt00': <__main__.Chaining at 0x2a2080d6050>,\n",
       " '6_prompt01': <__main__.Chaining at 0x2a2080d4090>,\n",
       " '6_prompt02': <__main__.Chaining at 0x2a20846e5d0>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug json decode error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1_prompt00...\n",
      "Processing 1_prompt01...\n",
      "Processing 1_prompt02...\n",
      "Processing 2_prompt00...\n",
      "Processing 2_prompt01...\n",
      "Processing 2_prompt02...\n",
      "Processing 3_prompt00...\n",
      "Processing 3_prompt01...\n",
      "Processing 3_prompt02...\n",
      "Processing 4_prompt00...\n",
      "Processing 4_prompt01...\n",
      "Processing 4_prompt02...\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 5_prompt02...\n",
      "Processing 6_prompt00...\n",
      "Processing 6_prompt01...\n",
      "Processing 6_prompt02...\n",
      "Error converting summary column to JSON: Expecting ',' delimiter: line 5 column 553 (char 1332); will do row by row\n",
      "Error converting summary 11 to JSON: Expecting ',' delimiter: line 5 column 553 (char 1332)\n",
      "Error converting summary 12 to JSON: Expecting property name enclosed in double quotes: line 3 column 396 (char 1498)\n",
      "Error converting summary 15 to JSON: Invalid control character at: line 2 column 451 (char 550)\n",
      "Original summaries DataFrame shape: (18, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 22:15:58.976371-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Key points: Changes in muscle mass, function, ...</td>\n",
       "      <td>New Research: Minimizing Muscle Loss as You Age</td>\n",
       "      <td>Key points: Changes in muscle mass and functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 22:16:03.042046-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>New Study Shows How Regular Exercise Can Help ...</td>\n",
       "      <td>Did you know that regular exercise can help co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 22:16:06.087321-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study investigated the recovery respo...</td>\n",
       "      <td>New Research Explores Aging and Muscle Recover...</td>\n",
       "      <td>Research shows that staying active with age th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 22:16:10.372355-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study looked at the effects of a high...</td>\n",
       "      <td>New study finds a nutritional intervention can...</td>\n",
       "      <td>A new study on nutrition intervention highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 22:16:13.965633-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study showed that a high calcium and ...</td>\n",
       "      <td>Reducing Fracture Risk and Falls in Older Adul...</td>\n",
       "      <td>Did you know that keeping up with a high calci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-12 22:16:18.210671-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent research study conducted in aged care...</td>\n",
       "      <td>New Research Reveals Nutritional Intervention ...</td>\n",
       "      <td>New research shows that elderly people in aged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-12 22:16:22.849429-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short, isolated bouts of v...</td>\n",
       "      <td>Exercise Snacks: Feasible, Time-Efficient, and...</td>\n",
       "      <td>Exercise snacks are bursts of intense exercise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-12 22:16:26.810862-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are brief bouts of vigorous ex...</td>\n",
       "      <td>Improve Your Fitness in Just One Minute! Resea...</td>\n",
       "      <td>Exercise snacks are a quick and convenient way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-12 22:16:30.831341-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks - short bursts of vigorous exe...</td>\n",
       "      <td>Improve Your Health with Quick Exercise Snacks...</td>\n",
       "      <td>Improve your health with short bursts of vigor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-12 22:16:34.350731-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted at Yale University fo...</td>\n",
       "      <td>New Study Shows How Food Cue and Stress Increa...</td>\n",
       "      <td>A recent study conducted at Yale University re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-07-12 22:16:39.776222-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent research compared the effects of food...</td>\n",
       "      <td>Exciting Research on Highly Palatable Food and...</td>\n",
       "      <td>New ground-breaking health research has examin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-07-12 22:16:43.388912-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New research shows how stress and food cues ca...</td>\n",
       "      <td>New research has found that being exposed to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-07-12 22:16:50.099169-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Pain research consistently shows that chronic ...</td>\n",
       "      <td>New Study Shows Dehydration Can Increase Pain ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-07-12 22:16:55.985792-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New Research Shows Mild Dehydration Can Increa...</td>\n",
       "      <td>Did you know that not getting enough water may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-07-12 22:17:00.047966-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>Link Between Hydration and Pain Sensitivity in...</td>\n",
       "      <td>A recent study showed that mild dehydration ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-07-12 22:17:03.908110-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and has negative im...</td>\n",
       "      <td>New research shows weight stigma negatively im...</td>\n",
       "      <td>Weight stigma is harmful, no matter your body ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-07-12 22:17:09.702688-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and has negative co...</td>\n",
       "      <td>Weight Stigma's Impact on Health Behaviors</td>\n",
       "      <td>Stigma for being overweight or obese affects h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-07-12 22:17:13.612467-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and can have a sign...</td>\n",
       "      <td>[Research Update] The Consequences of Weight S...</td>\n",
       "      <td>[Research Update] The Impact of Weight Stigma ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "0   2023-07-12 22:15:58.976371-07:00             1   \n",
       "1   2023-07-12 22:16:03.042046-07:00             1   \n",
       "2   2023-07-12 22:16:06.087321-07:00             1   \n",
       "3   2023-07-12 22:16:10.372355-07:00             2   \n",
       "4   2023-07-12 22:16:13.965633-07:00             2   \n",
       "5   2023-07-12 22:16:18.210671-07:00             2   \n",
       "6   2023-07-12 22:16:22.849429-07:00             3   \n",
       "7   2023-07-12 22:16:26.810862-07:00             3   \n",
       "8   2023-07-12 22:16:30.831341-07:00             3   \n",
       "9   2023-07-12 22:16:34.350731-07:00             4   \n",
       "10  2023-07-12 22:16:39.776222-07:00             4   \n",
       "11  2023-07-12 22:16:43.388912-07:00             4   \n",
       "12  2023-07-12 22:16:50.099169-07:00             5   \n",
       "13  2023-07-12 22:16:55.985792-07:00             5   \n",
       "14  2023-07-12 22:17:00.047966-07:00             5   \n",
       "15  2023-07-12 22:17:03.908110-07:00             6   \n",
       "16  2023-07-12 22:17:09.702688-07:00             6   \n",
       "17  2023-07-12 22:17:13.612467-07:00             6   \n",
       "\n",
       "                                        article_title  choice  \\\n",
       "0   Comparisons in the Recovery Response From Resi...       1   \n",
       "1   Comparisons in the Recovery Response From Resi...       1   \n",
       "2   Comparisons in the Recovery Response From Resi...       1   \n",
       "3   Effect of dietary sources of calcium and prote...       1   \n",
       "4   Effect of dietary sources of calcium and prote...       1   \n",
       "5   Effect of dietary sources of calcium and prote...       1   \n",
       "6   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "7   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "8   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "9   Food craving, cortisol and ghrelin responses i...       1   \n",
       "10  Food craving, cortisol and ghrelin responses i...       1   \n",
       "11  Food craving, cortisol and ghrelin responses i...       1   \n",
       "12  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "13  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "14  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "15  Weight stigma and health behaviors: evidence f...       1   \n",
       "16  Weight stigma and health behaviors: evidence f...       1   \n",
       "17  Weight stigma and health behaviors: evidence f...       1   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Decreases in muscle mass, function, and neurom...   \n",
       "1   Decreases in muscle mass, function, and neurom...   \n",
       "2   Decreases in muscle mass, function, and neurom...   \n",
       "3   Longevity increases the proportion of older ad...   \n",
       "4   Longevity increases the proportion of older ad...   \n",
       "5   Longevity increases the proportion of older ad...   \n",
       "6   We define exercise snacks as isolated ?1-min b...   \n",
       "7   We define exercise snacks as isolated ?1-min b...   \n",
       "8   We define exercise snacks as isolated ?1-min b...   \n",
       "9   The United States is at the forefront of the g...   \n",
       "10  The United States is at the forefront of the g...   \n",
       "11  The United States is at the forefront of the g...   \n",
       "12  Pain is recognized as a public health problem ...   \n",
       "13  Pain is recognized as a public health problem ...   \n",
       "14  Pain is recognized as a public health problem ...   \n",
       "15  Weight stigma is pervasive. Higher weight indi...   \n",
       "16  Weight stigma is pervasive. Higher weight indi...   \n",
       "17  Weight stigma is pervasive. Higher weight indi...   \n",
       "\n",
       "                                          system_role                   model  \\\n",
       "0   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "8   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "9   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "10  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "11  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "12  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "13  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "14  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "15  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "16  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "17  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "    temperature                                          prep_step  \\\n",
       "0           1.5  In the summary, cover the following informatio...   \n",
       "1           1.5  In the summary, cover the following informatio...   \n",
       "2           1.5  In the summary, cover the following informatio...   \n",
       "3           1.5  In the summary, cover the following informatio...   \n",
       "4           1.5  In the summary, cover the following informatio...   \n",
       "5           1.5  In the summary, cover the following informatio...   \n",
       "6           1.5  In the summary, cover the following informatio...   \n",
       "7           1.5  In the summary, cover the following informatio...   \n",
       "8           1.5  In the summary, cover the following informatio...   \n",
       "9           1.5  In the summary, cover the following informatio...   \n",
       "10          1.5  In the summary, cover the following informatio...   \n",
       "11          1.5  In the summary, cover the following informatio...   \n",
       "12          1.5  In the summary, cover the following informatio...   \n",
       "13          1.5  In the summary, cover the following informatio...   \n",
       "14          1.5  In the summary, cover the following informatio...   \n",
       "15          1.5  In the summary, cover the following informatio...   \n",
       "16          1.5  In the summary, cover the following informatio...   \n",
       "17          1.5  In the summary, cover the following informatio...   \n",
       "\n",
       "                                       summarize_task  \\\n",
       "0   1. Describe the interesting points of the rese...   \n",
       "1                 1. Summarize for an instagram post.   \n",
       "2   1. Tell your friend about the research in a te...   \n",
       "3   1. Describe the interesting points of the rese...   \n",
       "4                 1. Summarize for an instagram post.   \n",
       "5   1. Tell your friend about the research in a te...   \n",
       "6   1. Describe the interesting points of the rese...   \n",
       "7                 1. Summarize for an instagram post.   \n",
       "8   1. Tell your friend about the research in a te...   \n",
       "9   1. Describe the interesting points of the rese...   \n",
       "10                1. Summarize for an instagram post.   \n",
       "11  1. Tell your friend about the research in a te...   \n",
       "12  1. Describe the interesting points of the rese...   \n",
       "13                1. Summarize for an instagram post.   \n",
       "14  1. Tell your friend about the research in a te...   \n",
       "15  1. Describe the interesting points of the rese...   \n",
       "16                1. Summarize for an instagram post.   \n",
       "17  1. Tell your friend about the research in a te...   \n",
       "\n",
       "                                            edit_task  \\\n",
       "0   Once you have written your text message:     \\...   \n",
       "1   Once you have written your text message:     \\...   \n",
       "2   Once you have written your text message:     \\...   \n",
       "3   Once you have written your text message:     \\...   \n",
       "4   Once you have written your text message:     \\...   \n",
       "5   Once you have written your text message:     \\...   \n",
       "6   Once you have written your text message:     \\...   \n",
       "7   Once you have written your text message:     \\...   \n",
       "8   Once you have written your text message:     \\...   \n",
       "9   Once you have written your text message:     \\...   \n",
       "10  Once you have written your text message:     \\...   \n",
       "11  Once you have written your text message:     \\...   \n",
       "12  Once you have written your text message:     \\...   \n",
       "13  Once you have written your text message:     \\...   \n",
       "14  Once you have written your text message:     \\...   \n",
       "15  Once you have written your text message:     \\...   \n",
       "16  Once you have written your text message:     \\...   \n",
       "17  Once you have written your text message:     \\...   \n",
       "\n",
       "                                        simplify_task  \\\n",
       "0   3. If needed, rewrite the text using terms app...   \n",
       "1   3. If needed, rewrite the text using terms app...   \n",
       "2   3. If needed, rewrite the text using terms app...   \n",
       "3   3. If needed, rewrite the text using terms app...   \n",
       "4   3. If needed, rewrite the text using terms app...   \n",
       "5   3. If needed, rewrite the text using terms app...   \n",
       "6   3. If needed, rewrite the text using terms app...   \n",
       "7   3. If needed, rewrite the text using terms app...   \n",
       "8   3. If needed, rewrite the text using terms app...   \n",
       "9   3. If needed, rewrite the text using terms app...   \n",
       "10  3. If needed, rewrite the text using terms app...   \n",
       "11  3. If needed, rewrite the text using terms app...   \n",
       "12  3. If needed, rewrite the text using terms app...   \n",
       "13  3. If needed, rewrite the text using terms app...   \n",
       "14  3. If needed, rewrite the text using terms app...   \n",
       "15  3. If needed, rewrite the text using terms app...   \n",
       "16  3. If needed, rewrite the text using terms app...   \n",
       "17  3. If needed, rewrite the text using terms app...   \n",
       "\n",
       "                      simplify_audience  \\\n",
       "0   people without a science background   \n",
       "1   people without a science background   \n",
       "2   people without a science background   \n",
       "3   people without a science background   \n",
       "4   people without a science background   \n",
       "5   people without a science background   \n",
       "6   people without a science background   \n",
       "7   people without a science background   \n",
       "8   people without a science background   \n",
       "9   people without a science background   \n",
       "10  people without a science background   \n",
       "11  people without a science background   \n",
       "12  people without a science background   \n",
       "13  people without a science background   \n",
       "14  people without a science background   \n",
       "15  people without a science background   \n",
       "16  people without a science background   \n",
       "17  people without a science background   \n",
       "\n",
       "                                          format_task  \\\n",
       "0   4. Return your final response in a JSON format...   \n",
       "1   4. Return your final response in a JSON format...   \n",
       "2   4. Return your final response in a JSON format...   \n",
       "3   4. Return your final response in a JSON format...   \n",
       "4   4. Return your final response in a JSON format...   \n",
       "5   4. Return your final response in a JSON format...   \n",
       "6   4. Return your final response in a JSON format...   \n",
       "7   4. Return your final response in a JSON format...   \n",
       "8   4. Return your final response in a JSON format...   \n",
       "9   4. Return your final response in a JSON format...   \n",
       "10  4. Return your final response in a JSON format...   \n",
       "11  4. Return your final response in a JSON format...   \n",
       "12  4. Return your final response in a JSON format...   \n",
       "13  4. Return your final response in a JSON format...   \n",
       "14  4. Return your final response in a JSON format...   \n",
       "15  4. Return your final response in a JSON format...   \n",
       "16  4. Return your final response in a JSON format...   \n",
       "17  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                  full_summarize_task                  folder  \\\n",
       "0   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "1   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "2   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "3   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "4   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "5   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "6   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "7   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "8   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "9   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "10  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "11  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "12  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "13  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "14  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "15  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "16  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "17  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Key points: Changes in muscle mass, function, ...   \n",
       "1   A recent study compared the recovery response ...   \n",
       "2   A recent study investigated the recovery respo...   \n",
       "3   A recent study looked at the effects of a high...   \n",
       "4   A recent study showed that a high calcium and ...   \n",
       "5   A recent research study conducted in aged care...   \n",
       "6   Exercise snacks are short, isolated bouts of v...   \n",
       "7   Exercise snacks are brief bouts of vigorous ex...   \n",
       "8   Exercise snacks - short bursts of vigorous exe...   \n",
       "9   A recent study conducted at Yale University fo...   \n",
       "10  A recent research compared the effects of food...   \n",
       "11  A recent study conducted in a controlled hospi...   \n",
       "12  Pain research consistently shows that chronic ...   \n",
       "13  A recent study found that mild dehydration can...   \n",
       "14  A recent study found that mild dehydration can...   \n",
       "15  Weight stigma is pervasive and has negative im...   \n",
       "16  Weight stigma is pervasive and has negative co...   \n",
       "17  Weight stigma is pervasive and can have a sign...   \n",
       "\n",
       "                                             headline  \\\n",
       "0     New Research: Minimizing Muscle Loss as You Age   \n",
       "1   New Study Shows How Regular Exercise Can Help ...   \n",
       "2   New Research Explores Aging and Muscle Recover...   \n",
       "3   New study finds a nutritional intervention can...   \n",
       "4   Reducing Fracture Risk and Falls in Older Adul...   \n",
       "5   New Research Reveals Nutritional Intervention ...   \n",
       "6   Exercise Snacks: Feasible, Time-Efficient, and...   \n",
       "7   Improve Your Fitness in Just One Minute! Resea...   \n",
       "8   Improve Your Health with Quick Exercise Snacks...   \n",
       "9   New Study Shows How Food Cue and Stress Increa...   \n",
       "10  Exciting Research on Highly Palatable Food and...   \n",
       "11  New research shows how stress and food cues ca...   \n",
       "12  New Study Shows Dehydration Can Increase Pain ...   \n",
       "13  New Research Shows Mild Dehydration Can Increa...   \n",
       "14  Link Between Hydration and Pain Sensitivity in...   \n",
       "15  New research shows weight stigma negatively im...   \n",
       "16         Weight Stigma's Impact on Health Behaviors   \n",
       "17  [Research Update] The Consequences of Weight S...   \n",
       "\n",
       "                                       simple_summary  \n",
       "0   Key points: Changes in muscle mass and functio...  \n",
       "1   Did you know that regular exercise can help co...  \n",
       "2   Research shows that staying active with age th...  \n",
       "3   A new study on nutrition intervention highligh...  \n",
       "4   Did you know that keeping up with a high calci...  \n",
       "5   New research shows that elderly people in aged...  \n",
       "6   Exercise snacks are bursts of intense exercise...  \n",
       "7   Exercise snacks are a quick and convenient way...  \n",
       "8   Improve your health with short bursts of vigor...  \n",
       "9   A recent study conducted at Yale University re...  \n",
       "10  New ground-breaking health research has examin...  \n",
       "11  New research has found that being exposed to f...  \n",
       "12                                               None  \n",
       "13  Did you know that not getting enough water may...  \n",
       "14  A recent study showed that mild dehydration ca...  \n",
       "15  Weight stigma is harmful, no matter your body ...  \n",
       "16  Stigma for being overweight or obese affects h...  \n",
       "17  [Research Update] The Impact of Weight Stigma ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience')).fillna()\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.5\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=article_limit)\n",
    "# # sources_df\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1_prompt00...\n",
      "Processing 1_prompt01...\n",
      "Processing 1_prompt02...\n",
      "Processing 2_prompt00...\n",
      "Processing 2_prompt01...\n",
      "Processing 2_prompt02...\n",
      "Processing 3_prompt00...\n",
      "Processing 3_prompt01...\n",
      "Processing 3_prompt02...\n",
      "Processing 4_prompt00...\n",
      "Processing 4_prompt01...\n",
      "Processing 4_prompt02...\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 5_prompt02...\n",
      "Processing 6_prompt00...\n",
      "Processing 6_prompt01...\n",
      "Processing 6_prompt02...\n",
      "Error converting summary column to JSON: Expecting ',' delimiter: line 5 column 553 (char 1332); will do row by row\n",
      "Error converting summary 11 to JSON: Expecting ',' delimiter: line 5 column 553 (char 1332)\n",
      "Error converting summary 12 to JSON: Expecting property name enclosed in double quotes: line 3 column 396 (char 1498)\n",
      "Error converting summary 15 to JSON: Invalid control character at: line 2 column 451 (char 550)\n",
      "Original summaries DataFrame shape: (18, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-12 22:15:58.976371-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Key points: Changes in muscle mass, function, ...</td>\n",
       "      <td>New Research: Minimizing Muscle Loss as You Age</td>\n",
       "      <td>Key points: Changes in muscle mass and functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-12 22:16:03.042046-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study compared the recovery response ...</td>\n",
       "      <td>New Study Shows How Regular Exercise Can Help ...</td>\n",
       "      <td>Did you know that regular exercise can help co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-12 22:16:06.087321-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study investigated the recovery respo...</td>\n",
       "      <td>New Research Explores Aging and Muscle Recover...</td>\n",
       "      <td>Research shows that staying active with age th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-12 22:16:10.372355-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study looked at the effects of a high...</td>\n",
       "      <td>New study finds a nutritional intervention can...</td>\n",
       "      <td>A new study on nutrition intervention highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-12 22:16:13.965633-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study showed that a high calcium and ...</td>\n",
       "      <td>Reducing Fracture Risk and Falls in Older Adul...</td>\n",
       "      <td>Did you know that keeping up with a high calci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-12 22:16:18.210671-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older ad...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent research study conducted in aged care...</td>\n",
       "      <td>New Research Reveals Nutritional Intervention ...</td>\n",
       "      <td>New research shows that elderly people in aged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-12 22:16:22.849429-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are short, isolated bouts of v...</td>\n",
       "      <td>Exercise Snacks: Feasible, Time-Efficient, and...</td>\n",
       "      <td>Exercise snacks are bursts of intense exercise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-12 22:16:26.810862-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks are brief bouts of vigorous ex...</td>\n",
       "      <td>Improve Your Fitness in Just One Minute! Resea...</td>\n",
       "      <td>Exercise snacks are a quick and convenient way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-12 22:16:30.831341-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min b...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Exercise snacks - short bursts of vigorous exe...</td>\n",
       "      <td>Improve Your Health with Quick Exercise Snacks...</td>\n",
       "      <td>Improve your health with short bursts of vigor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-12 22:16:34.350731-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted at Yale University fo...</td>\n",
       "      <td>New Study Shows How Food Cue and Stress Increa...</td>\n",
       "      <td>A recent study conducted at Yale University re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-07-12 22:16:39.776222-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent research compared the effects of food...</td>\n",
       "      <td>Exciting Research on Highly Palatable Food and...</td>\n",
       "      <td>New ground-breaking health research has examin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-07-12 22:16:43.388912-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses i...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the g...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study conducted in a controlled hospi...</td>\n",
       "      <td>New research shows how stress and food cues ca...</td>\n",
       "      <td>New research has found that being exposed to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-07-12 22:16:50.099169-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Pain research consistently shows that chronic ...</td>\n",
       "      <td>New Study Shows Dehydration Can Increase Pain ...</td>\n",
       "      <td>Pain research consistently shows that chronic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-07-12 22:16:55.985792-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New Research Shows Mild Dehydration Can Increa...</td>\n",
       "      <td>Did you know that not getting enough water may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-07-12 22:17:00.047966-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>Link Between Hydration and Pain Sensitivity in...</td>\n",
       "      <td>A recent study showed that mild dehydration ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-07-12 22:17:03.908110-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Describe the interesting points of the rese...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and has negative im...</td>\n",
       "      <td>New research shows weight stigma negatively im...</td>\n",
       "      <td>Weight stigma is harmful, no matter your body ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-07-12 22:17:09.702688-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Summarize for an instagram post.</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Summarize for an instagram post.\\n\\nIn the ...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and has negative co...</td>\n",
       "      <td>Weight Stigma's Impact on Health Behaviors</td>\n",
       "      <td>Stigma for being overweight or obese affects h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-07-12 22:17:13.612467-07:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma is pervasive. Higher weight indi...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>Weight stigma is pervasive and can have a sign...</td>\n",
       "      <td>[Research Update] The Consequences of Weight S...</td>\n",
       "      <td>[Research Update] The Impact of Weight Stigma ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "0   2023-07-12 22:15:58.976371-07:00             1   \n",
       "1   2023-07-12 22:16:03.042046-07:00             1   \n",
       "2   2023-07-12 22:16:06.087321-07:00             1   \n",
       "3   2023-07-12 22:16:10.372355-07:00             2   \n",
       "4   2023-07-12 22:16:13.965633-07:00             2   \n",
       "5   2023-07-12 22:16:18.210671-07:00             2   \n",
       "6   2023-07-12 22:16:22.849429-07:00             3   \n",
       "7   2023-07-12 22:16:26.810862-07:00             3   \n",
       "8   2023-07-12 22:16:30.831341-07:00             3   \n",
       "9   2023-07-12 22:16:34.350731-07:00             4   \n",
       "10  2023-07-12 22:16:39.776222-07:00             4   \n",
       "11  2023-07-12 22:16:43.388912-07:00             4   \n",
       "12  2023-07-12 22:16:50.099169-07:00             5   \n",
       "13  2023-07-12 22:16:55.985792-07:00             5   \n",
       "14  2023-07-12 22:17:00.047966-07:00             5   \n",
       "15  2023-07-12 22:17:03.908110-07:00             6   \n",
       "16  2023-07-12 22:17:09.702688-07:00             6   \n",
       "17  2023-07-12 22:17:13.612467-07:00             6   \n",
       "\n",
       "                                        article_title  choice  \\\n",
       "0   Comparisons in the Recovery Response From Resi...       1   \n",
       "1   Comparisons in the Recovery Response From Resi...       1   \n",
       "2   Comparisons in the Recovery Response From Resi...       1   \n",
       "3   Effect of dietary sources of calcium and prote...       1   \n",
       "4   Effect of dietary sources of calcium and prote...       1   \n",
       "5   Effect of dietary sources of calcium and prote...       1   \n",
       "6   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "7   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "8   Exercise Snacks A Novel Strategy to Improve Ca...       1   \n",
       "9   Food craving, cortisol and ghrelin responses i...       1   \n",
       "10  Food craving, cortisol and ghrelin responses i...       1   \n",
       "11  Food craving, cortisol and ghrelin responses i...       1   \n",
       "12  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "13  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "14  Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "15  Weight stigma and health behaviors: evidence f...       1   \n",
       "16  Weight stigma and health behaviors: evidence f...       1   \n",
       "17  Weight stigma and health behaviors: evidence f...       1   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Decreases in muscle mass, function, and neurom...   \n",
       "1   Decreases in muscle mass, function, and neurom...   \n",
       "2   Decreases in muscle mass, function, and neurom...   \n",
       "3   Longevity increases the proportion of older ad...   \n",
       "4   Longevity increases the proportion of older ad...   \n",
       "5   Longevity increases the proportion of older ad...   \n",
       "6   We define exercise snacks as isolated ?1-min b...   \n",
       "7   We define exercise snacks as isolated ?1-min b...   \n",
       "8   We define exercise snacks as isolated ?1-min b...   \n",
       "9   The United States is at the forefront of the g...   \n",
       "10  The United States is at the forefront of the g...   \n",
       "11  The United States is at the forefront of the g...   \n",
       "12  Pain is recognized as a public health problem ...   \n",
       "13  Pain is recognized as a public health problem ...   \n",
       "14  Pain is recognized as a public health problem ...   \n",
       "15  Weight stigma is pervasive. Higher weight indi...   \n",
       "16  Weight stigma is pervasive. Higher weight indi...   \n",
       "17  Weight stigma is pervasive. Higher weight indi...   \n",
       "\n",
       "                                          system_role                   model  \\\n",
       "0   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "8   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "9   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "10  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "11  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "12  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "13  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "14  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "15  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "16  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "17  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "    temperature                                          prep_step  \\\n",
       "0           1.5  In the summary, cover the following informatio...   \n",
       "1           1.5  In the summary, cover the following informatio...   \n",
       "2           1.5  In the summary, cover the following informatio...   \n",
       "3           1.5  In the summary, cover the following informatio...   \n",
       "4           1.5  In the summary, cover the following informatio...   \n",
       "5           1.5  In the summary, cover the following informatio...   \n",
       "6           1.5  In the summary, cover the following informatio...   \n",
       "7           1.5  In the summary, cover the following informatio...   \n",
       "8           1.5  In the summary, cover the following informatio...   \n",
       "9           1.5  In the summary, cover the following informatio...   \n",
       "10          1.5  In the summary, cover the following informatio...   \n",
       "11          1.5  In the summary, cover the following informatio...   \n",
       "12          1.5  In the summary, cover the following informatio...   \n",
       "13          1.5  In the summary, cover the following informatio...   \n",
       "14          1.5  In the summary, cover the following informatio...   \n",
       "15          1.5  In the summary, cover the following informatio...   \n",
       "16          1.5  In the summary, cover the following informatio...   \n",
       "17          1.5  In the summary, cover the following informatio...   \n",
       "\n",
       "                                       summarize_task  \\\n",
       "0   1. Describe the interesting points of the rese...   \n",
       "1                 1. Summarize for an instagram post.   \n",
       "2   1. Tell your friend about the research in a te...   \n",
       "3   1. Describe the interesting points of the rese...   \n",
       "4                 1. Summarize for an instagram post.   \n",
       "5   1. Tell your friend about the research in a te...   \n",
       "6   1. Describe the interesting points of the rese...   \n",
       "7                 1. Summarize for an instagram post.   \n",
       "8   1. Tell your friend about the research in a te...   \n",
       "9   1. Describe the interesting points of the rese...   \n",
       "10                1. Summarize for an instagram post.   \n",
       "11  1. Tell your friend about the research in a te...   \n",
       "12  1. Describe the interesting points of the rese...   \n",
       "13                1. Summarize for an instagram post.   \n",
       "14  1. Tell your friend about the research in a te...   \n",
       "15  1. Describe the interesting points of the rese...   \n",
       "16                1. Summarize for an instagram post.   \n",
       "17  1. Tell your friend about the research in a te...   \n",
       "\n",
       "                                            edit_task  \\\n",
       "0   Once you have written your text message:     \\...   \n",
       "1   Once you have written your text message:     \\...   \n",
       "2   Once you have written your text message:     \\...   \n",
       "3   Once you have written your text message:     \\...   \n",
       "4   Once you have written your text message:     \\...   \n",
       "5   Once you have written your text message:     \\...   \n",
       "6   Once you have written your text message:     \\...   \n",
       "7   Once you have written your text message:     \\...   \n",
       "8   Once you have written your text message:     \\...   \n",
       "9   Once you have written your text message:     \\...   \n",
       "10  Once you have written your text message:     \\...   \n",
       "11  Once you have written your text message:     \\...   \n",
       "12  Once you have written your text message:     \\...   \n",
       "13  Once you have written your text message:     \\...   \n",
       "14  Once you have written your text message:     \\...   \n",
       "15  Once you have written your text message:     \\...   \n",
       "16  Once you have written your text message:     \\...   \n",
       "17  Once you have written your text message:     \\...   \n",
       "\n",
       "                                        simplify_task  \\\n",
       "0   3. If needed, rewrite the text using terms app...   \n",
       "1   3. If needed, rewrite the text using terms app...   \n",
       "2   3. If needed, rewrite the text using terms app...   \n",
       "3   3. If needed, rewrite the text using terms app...   \n",
       "4   3. If needed, rewrite the text using terms app...   \n",
       "5   3. If needed, rewrite the text using terms app...   \n",
       "6   3. If needed, rewrite the text using terms app...   \n",
       "7   3. If needed, rewrite the text using terms app...   \n",
       "8   3. If needed, rewrite the text using terms app...   \n",
       "9   3. If needed, rewrite the text using terms app...   \n",
       "10  3. If needed, rewrite the text using terms app...   \n",
       "11  3. If needed, rewrite the text using terms app...   \n",
       "12  3. If needed, rewrite the text using terms app...   \n",
       "13  3. If needed, rewrite the text using terms app...   \n",
       "14  3. If needed, rewrite the text using terms app...   \n",
       "15  3. If needed, rewrite the text using terms app...   \n",
       "16  3. If needed, rewrite the text using terms app...   \n",
       "17  3. If needed, rewrite the text using terms app...   \n",
       "\n",
       "                      simplify_audience  \\\n",
       "0   people without a science background   \n",
       "1   people without a science background   \n",
       "2   people without a science background   \n",
       "3   people without a science background   \n",
       "4   people without a science background   \n",
       "5   people without a science background   \n",
       "6   people without a science background   \n",
       "7   people without a science background   \n",
       "8   people without a science background   \n",
       "9   people without a science background   \n",
       "10  people without a science background   \n",
       "11  people without a science background   \n",
       "12  people without a science background   \n",
       "13  people without a science background   \n",
       "14  people without a science background   \n",
       "15  people without a science background   \n",
       "16  people without a science background   \n",
       "17  people without a science background   \n",
       "\n",
       "                                          format_task  \\\n",
       "0   4. Return your final response in a JSON format...   \n",
       "1   4. Return your final response in a JSON format...   \n",
       "2   4. Return your final response in a JSON format...   \n",
       "3   4. Return your final response in a JSON format...   \n",
       "4   4. Return your final response in a JSON format...   \n",
       "5   4. Return your final response in a JSON format...   \n",
       "6   4. Return your final response in a JSON format...   \n",
       "7   4. Return your final response in a JSON format...   \n",
       "8   4. Return your final response in a JSON format...   \n",
       "9   4. Return your final response in a JSON format...   \n",
       "10  4. Return your final response in a JSON format...   \n",
       "11  4. Return your final response in a JSON format...   \n",
       "12  4. Return your final response in a JSON format...   \n",
       "13  4. Return your final response in a JSON format...   \n",
       "14  4. Return your final response in a JSON format...   \n",
       "15  4. Return your final response in a JSON format...   \n",
       "16  4. Return your final response in a JSON format...   \n",
       "17  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                  full_summarize_task                  folder  \\\n",
       "0   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "1   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "2   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "3   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "4   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "5   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "6   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "7   1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "8   1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "9   1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "10  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "11  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "12  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "13  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "14  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "15  1. Describe the interesting points of the rese...  text/2023-07-11 for db   \n",
       "16  1. Summarize for an instagram post.\\n\\nIn the ...  text/2023-07-11 for db   \n",
       "17  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Key points: Changes in muscle mass, function, ...   \n",
       "1   A recent study compared the recovery response ...   \n",
       "2   A recent study investigated the recovery respo...   \n",
       "3   A recent study looked at the effects of a high...   \n",
       "4   A recent study showed that a high calcium and ...   \n",
       "5   A recent research study conducted in aged care...   \n",
       "6   Exercise snacks are short, isolated bouts of v...   \n",
       "7   Exercise snacks are brief bouts of vigorous ex...   \n",
       "8   Exercise snacks - short bursts of vigorous exe...   \n",
       "9   A recent study conducted at Yale University fo...   \n",
       "10  A recent research compared the effects of food...   \n",
       "11  A recent study conducted in a controlled hospi...   \n",
       "12  Pain research consistently shows that chronic ...   \n",
       "13  A recent study found that mild dehydration can...   \n",
       "14  A recent study found that mild dehydration can...   \n",
       "15  Weight stigma is pervasive and has negative im...   \n",
       "16  Weight stigma is pervasive and has negative co...   \n",
       "17  Weight stigma is pervasive and can have a sign...   \n",
       "\n",
       "                                             headline  \\\n",
       "0     New Research: Minimizing Muscle Loss as You Age   \n",
       "1   New Study Shows How Regular Exercise Can Help ...   \n",
       "2   New Research Explores Aging and Muscle Recover...   \n",
       "3   New study finds a nutritional intervention can...   \n",
       "4   Reducing Fracture Risk and Falls in Older Adul...   \n",
       "5   New Research Reveals Nutritional Intervention ...   \n",
       "6   Exercise Snacks: Feasible, Time-Efficient, and...   \n",
       "7   Improve Your Fitness in Just One Minute! Resea...   \n",
       "8   Improve Your Health with Quick Exercise Snacks...   \n",
       "9   New Study Shows How Food Cue and Stress Increa...   \n",
       "10  Exciting Research on Highly Palatable Food and...   \n",
       "11  New research shows how stress and food cues ca...   \n",
       "12  New Study Shows Dehydration Can Increase Pain ...   \n",
       "13  New Research Shows Mild Dehydration Can Increa...   \n",
       "14  Link Between Hydration and Pain Sensitivity in...   \n",
       "15  New research shows weight stigma negatively im...   \n",
       "16         Weight Stigma's Impact on Health Behaviors   \n",
       "17  [Research Update] The Consequences of Weight S...   \n",
       "\n",
       "                                       simple_summary  \n",
       "0   Key points: Changes in muscle mass and functio...  \n",
       "1   Did you know that regular exercise can help co...  \n",
       "2   Research shows that staying active with age th...  \n",
       "3   A new study on nutrition intervention highligh...  \n",
       "4   Did you know that keeping up with a high calci...  \n",
       "5   New research shows that elderly people in aged...  \n",
       "6   Exercise snacks are bursts of intense exercise...  \n",
       "7   Exercise snacks are a quick and convenient way...  \n",
       "8   Improve your health with short bursts of vigor...  \n",
       "9   A recent study conducted at Yale University re...  \n",
       "10  New ground-breaking health research has examin...  \n",
       "11  New research has found that being exposed to f...  \n",
       "12  Pain research consistently shows that chronic ...  \n",
       "13  Did you know that not getting enough water may...  \n",
       "14  A recent study showed that mild dehydration ca...  \n",
       "15  Weight stigma is harmful, no matter your body ...  \n",
       "16  Stigma for being overweight or obese affects h...  \n",
       "17  [Research Update] The Impact of Weight Stigma ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.5\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=article_limit)\n",
    "# # sources_df\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 18 rows to the database...\n",
      "\tReference #1: New Research: Minimizing Muscle Loss as You Age\n",
      "\tReference #1: New Study Shows How Regular Exercise Can Help Reduce Muscle Ageing\n",
      "\tReference #1: New Research Explores Aging and Muscle Recovery after Exercise\n",
      "\tReference #2: New study finds a nutritional intervention can reduce risk of falls and fractures in older adults\n",
      "\tReference #2: Reducing Fracture Risk and Falls in Older Adults through Nutrition\n",
      "\tReference #2: New Research Reveals Nutritional Intervention Reduces Fracture Risk in Older Adults in Aged Care\n",
      "\tReference #3: Exercise Snacks: Feasible, Time-Efficient, and Effective for Health Improvement\n",
      "\tReference #3: Improve Your Fitness in Just One Minute! Research shows that exercise snacks are a quick and effective way to boost your cardio health\n",
      "\tReference #3: Improve Your Health with Quick Exercise Snacks Throughout the Day\n",
      "\tReference #4: New Study Shows How Food Cue and Stress Increase Cravings for High-Fat Snacks\n",
      "\tReference #4: Exciting Research on Highly Palatable Food and Stress\n",
      "\tReference #4: New research shows how stress and food cues can increase food cravings and intake\n",
      "\tReference #5: New Study Shows Dehydration Can Increase Pain Sensitivity in Women\n",
      "\tReference #5: New Research Shows Mild Dehydration Can Increase Pain Sensitivity in Women\n",
      "\tReference #5: Link Between Hydration and Pain Sensitivity in Women\n",
      "\tReference #6: New research shows weight stigma negatively impacts health behaviors and well-being\n",
      "\tReference #6: Weight Stigma's Impact on Health Behaviors\n",
      "\tReference #6: [Research Update] The Consequences of Weight Stigma on Health Behaviors\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id ASC LIMIT 1\n",
      "**Text #1 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "1_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-07-11 for db//batch_Chaining_attributes_initial_2023-07-13_0206.json\n",
      "Processing 1_prompt00...\n",
      "Original summaries DataFrame shape: (1, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-13 02:06:33.715667-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>According to a recent study, the decline in mu...</td>\n",
       "      <td>New Research Reveals the Benefits of Exercise ...</td>\n",
       "      <td>Discover the benefits of exercise in combating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-13 02:06:33.715667-07:00             1   \n",
       "\n",
       "                                       article_title  choice  \\\n",
       "0  Comparisons in the Recovery Response From Resi...       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Decreases in muscle mass, function, and neurom...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0          1.5  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  1. Tell your friend about the research in a te...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. If needed, rewrite the text using terms app...   \n",
       "\n",
       "                     simplify_audience  \\\n",
       "0  people without a science background   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                  folder  \\\n",
       "0  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "\n",
       "                                             summary  \\\n",
       "0  According to a recent study, the decline in mu...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  New Research Reveals the Benefits of Exercise ...   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Discover the benefits of exercise in combating...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                # if table == 'summaries':\n",
    "\n",
    "                    # Check if prompt already exists in the database\n",
    "                    # prompt = session.query(Prompts).filter_by(\n",
    "                    #     full_template=row['full_summarize_task'], \n",
    "                    #     ).first()\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    )\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.51\n",
    "article_limit = 1\n",
    "temperature = 1.5\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit)\n",
    "# sources_df\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1 rows to the database...\n",
      "Error adding data to the database: 'Query' object has no attribute 'id'\n"
     ]
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id ASC LIMIT 1\n",
      "Adding 1 rows to the database...\n",
      "\tReference #1: New Research Reveals the Benefits of Exercise on Muscle Function and Recovery as We Age\n",
      "Data added successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-13 02:06:33.715667-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neurom...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. If needed, rewrite the text using terms app...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>1. Tell your friend about the research in a te...</td>\n",
       "      <td>text/2023-07-11 for db</td>\n",
       "      <td>According to a recent study, the decline in mu...</td>\n",
       "      <td>New Research Reveals the Benefits of Exercise ...</td>\n",
       "      <td>Discover the benefits of exercise in combating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-13 02:06:33.715667-07:00             1   \n",
       "\n",
       "                                       article_title  choice  \\\n",
       "0  Comparisons in the Recovery Response From Resi...       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Decreases in muscle mass, function, and neurom...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0          1.5  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  1. Tell your friend about the research in a te...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. If needed, rewrite the text using terms app...   \n",
       "\n",
       "                     simplify_audience  \\\n",
       "0  people without a science background   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                  folder  \\\n",
       "0  1. Tell your friend about the research in a te...  text/2023-07-11 for db   \n",
       "\n",
       "                                             summary  \\\n",
       "0  According to a recent study, the decline in mu...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  New Research Reveals the Benefits of Exercise ...   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Discover the benefits of exercise in combating...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.51\n",
    "article_limit = 1\n",
    "temperature = 1.5\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '../text/2023-07-11 for db'\n",
    "\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit)\n",
    "# sources_df\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # # chaining_dict[iteration_id]\n",
    "# qna_dict = create_summaries_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "#     )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
