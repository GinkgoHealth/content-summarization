{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.environ['api_key_openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# set the option to wrap text within cells\n",
    "# pd.reset_option('all')\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue ORDER BY id ASC LIMIT 2\n",
      "Search term: (Recommendations and Nutritional Considerations for Female Athletes: Health and Performance [ti]) AND (Sports Medicine [ta])\n",
      "Number of abstract sections: 1\n",
      "Search term: (Recommendations and Nutritional Considerations for Female Athletes: Health and Performance [ti]) AND (Sports Medicine [ta])\n",
      "Number of abstract sections: 1\n",
      "Adding 2 rows to the database...\n",
      "\tRecommendations and Nutritional Considerations for Female Athletes: Health and Performance\n",
      "\tRecommendations and Nutritional Considerations for Female Athletes: Health and Performance\n",
      "New records added successfully (if applicable)!\n",
      "**Text #276 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #276 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #276 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #277 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #277 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #277 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 276_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 276_prompt00: 'summary'\n",
      "Processing 276_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 276_prompt01: 'summary'\n",
      "Processing 276_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 276_prompt02: 'summary'\n",
      "Processing 277_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 277_prompt00: 'summary'\n",
      "Processing 277_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 277_prompt01: 'summary'\n",
      "Processing 277_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 277_prompt02: 'summary'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m qna_dict[iteration_id]\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 79\u001b[0m     qna_dict \u001b[39m=\u001b[39m generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local\u001b[39m=\u001b[39mlocal, article_limit\u001b[39m=\u001b[39marticle_limit)\n\u001b[0;32m     80\u001b[0m     \u001b[39mprint\u001b[39m(qna_dict[iteration_id])\n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mgenerate_summaries\u001b[1;34m(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit)\u001b[0m\n\u001b[0;32m     58\u001b[0m chatbot_dict \u001b[39m=\u001b[39m batch_summarize( \u001b[39m# orm_summarize.py\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task,  \u001b[39m# parameter values found in prompts.py\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m \u001b[39m#########\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m# Step 5: Create summaries table\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m     69\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39mchatbot_id\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     72\u001b[0m \u001b[39m##########\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m# Step 5: Add results to summaries and prompts table \u001b[39;00m\n\u001b[0;32m     74\u001b[0m bulk_append(table\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummaries\u001b[39m\u001b[39m'\u001b[39m, input_df\u001b[39m=\u001b[39mqna_dict[iteration_id]) \u001b[39m# db_orm.py\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py:206\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mAn error occurred on line \u001b[39m\u001b[39m{\u001b[39;00mlineno\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)    \n\u001b[0;32m    203\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError creating DataFrame from \u001b[39m\u001b[39m{\u001b[39;00mchatbot_key\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    207\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m columns \u001b[39m=\u001b[39m qna_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39mignore_index,\n\u001b[0;32m    376\u001b[0m     join\u001b[39m=\u001b[39mjoin,\n\u001b[0;32m    377\u001b[0m     keys\u001b[39m=\u001b[39mkeys,\n\u001b[0;32m    378\u001b[0m     levels\u001b[39m=\u001b[39mlevels,\n\u001b[0;32m    379\u001b[0m     names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39mverify_integrity,\n\u001b[0;32m    381\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m    382\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    426\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[0;32m    428\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 2\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    print(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue ORDER BY id ASC LIMIT 2\n",
      "Search term: (Recommendations and Nutritional Considerations for Female Athletes: Health and Performance [ti]) AND (Sports Medicine [ta])\n",
      "Number of abstract sections: 1\n",
      "Search term: (Recommendations and Nutritional Considerations for Female Athletes: Health and Performance [ti]) AND (Sports Medicine [ta])\n",
      "Number of abstract sections: 1\n",
      "Adding 2 rows to the database...\n",
      "\t** Already exists in the database: Recommendations and Nutritional Considerations for Female Athletes: Health and Performance.\n",
      "\t** Already exists in the database: Recommendations and Nutritional Considerations for Female Athletes: Health and Performance.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #276 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #276 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #276 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #277 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #277 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #277 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 276_prompt00...\n",
      "Processing 276_prompt01...\n",
      "Processing 276_prompt02...\n",
      "Processing 277_prompt00...\n",
      "Processing 277_prompt01...\n",
      "Processing 277_prompt02...\n",
      "Original summaries DataFrame shape: (6, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 6 rows to the database...\n",
      "\tReference #276: Fascinating Facts about Nutrition and Performance for Female Athletes\n",
      "\tReference #276: New research reveals challenges in studying female athletes and provides recommendations for nutrition and hydration\n",
      "\tReference #276: Optimizing nutrition for female athletes: Key findings\n",
      "\tReference #277: Health Research Hacks for Fun Facts!\n",
      "\tReference #277: Nutrition Gone Wrong: The Impact of Low Energy Availability in Female Athletes\n",
      "\tReference #277: Surprising facts about nutrition in sports\n",
      "New records added successfully (if applicable)!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     79\u001b[0m     qna_dict \u001b[39m=\u001b[39m generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local\u001b[39m=\u001b[39mlocal, article_limit\u001b[39m=\u001b[39marticle_limit)\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mprint\u001b[39m(qna_dict[iteration_id])\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 2\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    print(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue ORDER BY id DESC LIMIT 2\n",
      "Search term: (The effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials [ti]) AND (Ageing Research Reviews [ta])\n",
      "Number of abstract sections: 4\n",
      "Search term: (The effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials [ti]) AND (Ageing Research Reviews [ta])\n",
      "Number of abstract sections: 4\n",
      "Adding 2 rows to the database...\n",
      "\tThe effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials\n",
      "\tThe effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials\n",
      "New records added successfully (if applicable)!\n",
      "**Text #278 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #278 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #278 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #279 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 17321 tokens (16321 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #279 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 17337 tokens (16337 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #279 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 17324 tokens (16324 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 278_prompt00...\n",
      "Processing 278_prompt01...\n",
      "Processing 278_prompt02...\n",
      "Processing 279_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 279_prompt00: 'summary'\n",
      "Processing 279_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 279_prompt01: 'summary'\n",
      "Processing 279_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 279_prompt02: 'summary'\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #278: Texting you a cool health fact!\n",
      "\tReference #278: Exciting new research on Tai Chi for sarcopenia and frailty!\n",
      "\tReference #278: New research on Tai Chi shows it improves physical performance in older adults with sarcopenia and frailty.\n",
      "New records added successfully (if applicable)!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     79\u001b[0m     qna_dict \u001b[39m=\u001b[39m generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local\u001b[39m=\u001b[39mlocal, article_limit\u001b[39m=\u001b[39marticle_limit)\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mprint\u001b[39m(qna_dict[iteration_id])\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 2\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    print(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'reference_id', 'article_title', 'choice', 'text',\n",
       "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
       "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
       "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
       "       'simple_summary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 with new prompt in step 3: \"3. Use the text from step 1 to create a fun tweet.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue ORDER BY id DESC LIMIT 1\n",
      "Search term: (The effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials [ti]) AND (Ageing Research Reviews [ta])\n",
      "Number of abstract sections: 4\n",
      "Adding 1 rows to the database...\n",
      "\tThe effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials\n",
      "New records added successfully (if applicable)!\n",
      "**Text #280 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #280 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #280 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 280_prompt00...\n",
      "Processing 280_prompt01...\n",
      "Processing 280_prompt02...\n",
      "Error converting summary column to JSON: Expecting value: line 1 column 1 (char 0); will do row by row\n",
      "Error converting summary 3 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 4 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Original summaries DataFrame shape: (6, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 6 rows to the database...\n",
      "\tReference #280: Discover the Surprising Benefits of Tai Chi for Sarcopenia and Frailty!\n",
      "\tReference #280: Exciting health research on Tai Chi!\n",
      "\tReference #280: Exciting health research findings on Tai Chi!\n",
      "\tReference #280: Exciting health research on Tai Chi!\n",
      "\tReference #280: Exciting Health Research on Tai Chi for Sarcopenia and Frailty\n",
      "\tReference #280: Exciting new research on the benefits of Tai Chi for health!\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 3 with new prompt in step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue ORDER BY id DESC LIMIT 1\n",
      "Search term: (The effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials [ti]) AND (Ageing Research Reviews [ta])\n",
      "Number of abstract sections: 4\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: The effect of Tai Chi in elderly individuals with sarcopenia and frailty: A systematic review and meta-analysis of randomized controlled trials.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #280 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 280_prompt00...\n",
      "Original summaries DataFrame shape: (2, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 2 rows to the database...\n",
      "\tReference #280: Exciting new research on Tai Chi and its impact on health!\n",
      "\tReference #280: New research shows Tai Chi can improve physical performance and mental well-being in elderly individuals with sarcopenia and frailty\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 4: allow for selection of specific id in `gpt_queue` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue WHERE id IN (401, 407, 408) ORDER BY id ASC\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = None\n",
    "queue_id = (401, 407, 408)\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    elif queue_id:\n",
    "        if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "            print('Converting queue_id list to tuple')\n",
    "            queue_id = tuple(queue_id)\n",
    "        elif (type(queue_id) == list):\n",
    "            print('Converting queue_id list to number')\n",
    "            queue_id = queue_id[0]\n",
    "        if type(queue_id) == tuple:\n",
    "            text_df = get_table(\n",
    "                table='gpt_queue', limit=article_limit, \n",
    "                filter_statement=f'id IN {queue_id}'\n",
    "                )\n",
    "        else:\n",
    "            text_df = get_table(\n",
    "                table='gpt_queue', limit=article_limit, \n",
    "                filter_statement=f'id = {queue_id}'\n",
    "                )\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "    return text_df\n",
    "    # references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    # ###### \n",
    "    # # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    # bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 3: Get the new sources for summarization\n",
    "    # sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>sent_to_sources</th>\n",
       "      <th>section</th>\n",
       "      <th>publication</th>\n",
       "      <th>n_choices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401</td>\n",
       "      <td>Efficacy of Cognitive Behavioral Therapy for A...</td>\n",
       "      <td>Introduction\\nAnxiety disorders are highly dis...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Current Psychiatry Reports</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>407</td>\n",
       "      <td>Time-restricted eating for patients with diabe...</td>\n",
       "      <td>Discussion\\nTo the best of our knowledge, this...</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Frontiers in Nutrition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>1. Introduction\\nAs the number of elderly indi...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Ageing Research Reviews</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "0  401  Efficacy of Cognitive Behavioral Therapy for A...   \n",
       "1  407  Time-restricted eating for patients with diabe...   \n",
       "2  408  The effect of Tai Chi in elderly individuals w...   \n",
       "\n",
       "                                                body sent_to_sources  \\\n",
       "0  Introduction\\nAnxiety disorders are highly dis...            None   \n",
       "1  Discussion\\nTo the best of our knowledge, this...           False   \n",
       "2  1. Introduction\\nAs the number of elderly indi...            None   \n",
       "\n",
       "      section                 publication n_choices  \n",
       "0              Current Psychiatry Reports      None  \n",
       "1  Discussion      Frontiers in Nutrition      None  \n",
       "2                 Ageing Research Reviews      None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 make sure it still works to just grab latest entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue ORDER BY id DESC LIMIT 2\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 2\n",
    "# queue_id = (401, 407, 408)\n",
    "queue_id = None\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    elif queue_id:\n",
    "        if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "            print('Converting queue_id list to tuple')\n",
    "            queue_id = tuple(queue_id)\n",
    "        elif (type(queue_id) == list):\n",
    "            print('Converting queue_id list to number')\n",
    "            queue_id = queue_id[0]\n",
    "        if type(queue_id) == tuple:\n",
    "            text_df = get_table(\n",
    "                table='gpt_queue', limit=article_limit, \n",
    "                filter_statement=f'id IN {queue_id}'\n",
    "                )\n",
    "        else:\n",
    "            text_df = get_table(\n",
    "                table='gpt_queue', limit=article_limit, \n",
    "                filter_statement=f'id = {queue_id}'\n",
    "                )\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "    return text_df\n",
    "    # references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    # ###### \n",
    "    # # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    # bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 3: Get the new sources for summarization\n",
    "    # sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>sent_to_sources</th>\n",
       "      <th>section</th>\n",
       "      <th>publication</th>\n",
       "      <th>n_choices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>2. Methods\\n2.1. Search strategy\\nPublished RC...</td>\n",
       "      <td>False</td>\n",
       "      <td>Methods, Results, Discussion</td>\n",
       "      <td>Ageing Research Reviews</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>409</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>4. Discussion\\n4.1. Sarcopenia and frailty\\nTh...</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Ageing Research Reviews</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "0  410  The effect of Tai Chi in elderly individuals w...   \n",
       "1  409  The effect of Tai Chi in elderly individuals w...   \n",
       "\n",
       "                                                body  sent_to_sources  \\\n",
       "0  2. Methods\\n2.1. Search strategy\\nPublished RC...            False   \n",
       "1  4. Discussion\\n4.1. Sarcopenia and frailty\\nTh...            False   \n",
       "\n",
       "                        section              publication n_choices  \n",
       "0  Methods, Results, Discussion  Ageing Research Reviews      None  \n",
       "1                    Discussion  Ageing Research Reviews      None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 5: Ensure that the corresponding entries in `sources` table are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from gpt_queue WHERE id IN (142, 143) ORDER BY id ASC\n",
      "Search term: (Recommendations and Nutritional Considerations for Female Athletes: Health and Performance [ti]) AND (Sports Medicine [ta])\n",
      "Number of abstract sections: 1\n",
      "Search term: (Recommendations and Nutritional Considerations for Female Athletes: Health and Performance [ti]) AND (Sports Medicine [ta])\n",
      "Number of abstract sections: 1\n",
      "Adding 2 rows to the database...\n",
      "\t** Already exists in the database: Recommendations and Nutritional Considerations for Female Athletes: Health and Performance.\n",
      "\t** Already exists in the database: Recommendations and Nutritional Considerations for Female Athletes: Health and Performance.\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = None\n",
    "queue_id = (142, 143)\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    elif queue_id:\n",
    "        if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "            print('Converting queue_id list to tuple')\n",
    "            queue_id = tuple(queue_id)\n",
    "        elif (type(queue_id) == list):\n",
    "            print('Converting queue_id list to number')\n",
    "            queue_id = queue_id[0]\n",
    "        if type(queue_id) == tuple:\n",
    "            text_df = get_table(\n",
    "                table='gpt_queue', limit=article_limit, \n",
    "                filter_statement=f'id IN {queue_id}'\n",
    "                )\n",
    "        else:\n",
    "            text_df = get_table(\n",
    "                table='gpt_queue', limit=article_limit, \n",
    "                filter_statement=f'id = {queue_id}'\n",
    "                )\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    return sources_df\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "      <th>mesh_headings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276</td>\n",
       "      <td>Recommendations and Nutritional Considerations...</td>\n",
       "      <td>1 Introduction\\nFemale athletes make up nearly...</td>\n",
       "      <td>Optimal nutrition is an important aspect of an...</td>\n",
       "      <td>Sports medicine (Auckland, N.Z.)</td>\n",
       "      <td>Bryan Holtzman, Kathryn E Ackerman</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>Suppl 1</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>10.1007/s40279-021-01508-8</td>\n",
       "      <td></td>\n",
       "      <td>&lt;MeshHeading&gt;&lt;DescriptorName UI=\"D056352\" Majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>277</td>\n",
       "      <td>Recommendations and Nutritional Considerations...</td>\n",
       "      <td>3 Nutrition Gone Wrong: Relative Energy Defici...</td>\n",
       "      <td>Optimal nutrition is an important aspect of an...</td>\n",
       "      <td>Sports medicine (Auckland, N.Z.)</td>\n",
       "      <td>Bryan Holtzman, Kathryn E Ackerman</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>Suppl 1</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>10.1007/s40279-021-01508-8</td>\n",
       "      <td>Nutrition Gone Wrong: Relative Energy Deficien...</td>\n",
       "      <td>&lt;MeshHeading&gt;&lt;DescriptorName UI=\"D056352\" Majo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "0  276  Recommendations and Nutritional Considerations...   \n",
       "1  277  Recommendations and Nutritional Considerations...   \n",
       "\n",
       "                                                text  \\\n",
       "0  1 Introduction\\nFemale athletes make up nearly...   \n",
       "1  3 Nutrition Gone Wrong: Relative Energy Defici...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Optimal nutrition is an important aspect of an...   \n",
       "1  Optimal nutrition is an important aspect of an...   \n",
       "\n",
       "                        publication                             authors  year  \\\n",
       "0  Sports medicine (Auckland, N.Z.)  Bryan Holtzman, Kathryn E Ackerman  2021   \n",
       "1  Sports medicine (Auckland, N.Z.)  Bryan Holtzman, Kathryn E Ackerman  2021   \n",
       "\n",
       "  month pub_volume pub_issue start_page end_page                         doi  \\\n",
       "0               51   Suppl 1         43       57  10.1007/s40279-021-01508-8   \n",
       "1               51   Suppl 1         43       57  10.1007/s40279-021-01508-8   \n",
       "\n",
       "                                             section  \\\n",
       "0                                                      \n",
       "1  Nutrition Gone Wrong: Relative Energy Deficien...   \n",
       "\n",
       "                                       mesh_headings  \n",
       "0  <MeshHeading><DescriptorName UI=\"D056352\" Majo...  \n",
       "1  <MeshHeading><DescriptorName UI=\"D056352\" Majo...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = None\n",
    "queue_id = (142, 143)\n",
    "sources_id = (280, 277)\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(\n",
    "    n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, sources_id=sources_id, article_limit=article_limit\n",
    "    ):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    if sources_id:\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_sources(sources_id, order_by='id', order='ASC')\n",
    "    else:\n",
    "        ####### \n",
    "        # Step 1: Create sources table\n",
    "        if local:\n",
    "            text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "        elif queue_id:\n",
    "            if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "                print('Converting queue_id list to tuple')\n",
    "                queue_id = tuple(queue_id)\n",
    "            elif (type(queue_id) == list):\n",
    "                print('Converting queue_id list to number')\n",
    "                queue_id = queue_id[0]\n",
    "            if type(queue_id) == tuple:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id IN {queue_id}'\n",
    "                    )\n",
    "            else:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id = {queue_id}'\n",
    "                    )\n",
    "        else:\n",
    "            text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "        references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "        ###### \n",
    "        # Step 2:  Add rows from gpt_queue table to sources table \n",
    "        bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    return sources_df\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "      <th>mesh_headings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>277</td>\n",
       "      <td>Recommendations and Nutritional Considerations...</td>\n",
       "      <td>3 Nutrition Gone Wrong: Relative Energy Defici...</td>\n",
       "      <td>Optimal nutrition is an important aspect of an...</td>\n",
       "      <td>Sports medicine (Auckland, N.Z.)</td>\n",
       "      <td>Bryan Holtzman, Kathryn E Ackerman</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>Suppl 1</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>10.1007/s40279-021-01508-8</td>\n",
       "      <td>Nutrition Gone Wrong: Relative Energy Deficien...</td>\n",
       "      <td>&lt;MeshHeading&gt;&lt;DescriptorName UI=\"D056352\" Majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>2. Methods\\n2.1. Search strategy\\nPublished RC...</td>\n",
       "      <td>BACKGROUND: The potential role of Tai Chi in i...</td>\n",
       "      <td>Ageing research reviews</td>\n",
       "      <td>Chia-Yu Huang, Peter Karl Mayer, Mei-Yao Wu, D...</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td></td>\n",
       "      <td>101747</td>\n",
       "      <td></td>\n",
       "      <td>10.1016/j.arr.2022.101747</td>\n",
       "      <td>Methods, Results, Discussion</td>\n",
       "      <td>&lt;MeshHeading&gt;&lt;DescriptorName UI=\"D000368\" Majo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "1  277  Recommendations and Nutritional Considerations...   \n",
       "0  280  The effect of Tai Chi in elderly individuals w...   \n",
       "\n",
       "                                                text  \\\n",
       "1  3 Nutrition Gone Wrong: Relative Energy Defici...   \n",
       "0  2. Methods\\n2.1. Search strategy\\nPublished RC...   \n",
       "\n",
       "                                            abstract  \\\n",
       "1  Optimal nutrition is an important aspect of an...   \n",
       "0  BACKGROUND: The potential role of Tai Chi in i...   \n",
       "\n",
       "                        publication  \\\n",
       "1  Sports medicine (Auckland, N.Z.)   \n",
       "0           Ageing research reviews   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "1                 Bryan Holtzman, Kathryn E Ackerman  2021               51   \n",
       "0  Chia-Yu Huang, Peter Karl Mayer, Mei-Yao Wu, D...  2022               82   \n",
       "\n",
       "  pub_issue start_page end_page                         doi  \\\n",
       "1   Suppl 1         43       57  10.1007/s40279-021-01508-8   \n",
       "0               101747            10.1016/j.arr.2022.101747   \n",
       "\n",
       "                                             section  \\\n",
       "1  Nutrition Gone Wrong: Relative Energy Deficien...   \n",
       "0                       Methods, Results, Discussion   \n",
       "\n",
       "                                       mesh_headings  \n",
       "1  <MeshHeading><DescriptorName UI=\"D056352\" Majo...  \n",
       "0  <MeshHeading><DescriptorName UI=\"D000368\" Majo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.11 Allow sources_id to be a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #280 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #280 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #280 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 280_prompt00...\n",
      "Processing 280_prompt01...\n",
      "Processing 280_prompt02...\n",
      "Error converting summary column to JSON: Expecting value: line 1 column 1 (char 0); will do row by row\n",
      "Error converting summary 2 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #280: Fascinating Health Research: Tai Chi Improves Physical Performance in Elderly\n",
      "\tReference #280: Exciting findings: Tai Chi improves physical performance in elderly with sarcopenia and frailty\n",
      "\tReference #280: None\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = None\n",
    "queue_id = (142, 143)\n",
    "sources_id = 280\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(\n",
    "    n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, sources_id=sources_id, article_limit=article_limit\n",
    "    ):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    if sources_id:\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_sources(sources_id, order_by='id', order='ASC')\n",
    "    else:\n",
    "        ####### \n",
    "        # Step 1: Create sources table\n",
    "        if local:\n",
    "            text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "        elif queue_id:\n",
    "            if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "                print('Converting queue_id list to tuple')\n",
    "                queue_id = tuple(queue_id)\n",
    "            elif (type(queue_id) == list):\n",
    "                print('Converting queue_id list to number')\n",
    "                queue_id = queue_id[0]\n",
    "            if type(queue_id) == tuple:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id IN {queue_id}'\n",
    "                    )\n",
    "            else:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id = {queue_id}'\n",
    "                    )\n",
    "        else:\n",
    "            text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "        references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "        ###### \n",
    "        # Step 2:  Add rows from gpt_queue table to sources table \n",
    "        bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    # return sources_df\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-06 16:13:08.498432-07:00</td>\n",
       "      <td>280</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>1</td>\n",
       "      <td>2. Methods\\n2.1. Search strategy\\nPublished RC...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.\\ \\n    Foll...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! I came across an interesting health resea...</td>\n",
       "      <td>Fascinating Health Research: Tai Chi Improves ...</td>\n",
       "      <td>Hey! I found this super cool study on Tai Chi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-06 16:13:24.587353-07:00</td>\n",
       "      <td>280</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>1</td>\n",
       "      <td>2. Methods\\n2.1. Search strategy\\nPublished RC...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey there! I just read an interesting research...</td>\n",
       "      <td>Exciting findings: Tai Chi improves physical p...</td>\n",
       "      <td>Did you know that practicing Tai Chi can impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-06 16:13:28.832222-07:00</td>\n",
       "      <td>280</td>\n",
       "      <td>The effect of Tai Chi in elderly individuals w...</td>\n",
       "      <td>1</td>\n",
       "      <td>2. Methods\\n2.1. Search strategy\\nPublished RC...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Use the text from step 1 to create a fun tw...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-09-06 16:13:08.498432-07:00           280   \n",
       "1  2023-09-06 16:13:24.587353-07:00           280   \n",
       "2  2023-09-06 16:13:28.832222-07:00           280   \n",
       "\n",
       "                                       article_title  choice  \\\n",
       "0  The effect of Tai Chi in elderly individuals w...       1   \n",
       "1  The effect of Tai Chi in elderly individuals w...       1   \n",
       "2  The effect of Tai Chi in elderly individuals w...       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  2. Methods\\n2.1. Search strategy\\nPublished RC...   \n",
       "1  2. Methods\\n2.1. Search strategy\\nPublished RC...   \n",
       "2  2. Methods\\n2.1. Search strategy\\nPublished RC...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.\\ \\n    Foll...   \n",
       "1  3. Make a more concise and simple version of t...   \n",
       "2  3. Use the text from step 1 to create a fun tw...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hey! I came across an interesting health resea...   \n",
       "1  Hey there! I just read an interesting research...   \n",
       "2                                               None   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Fascinating Health Research: Tai Chi Improves ...   \n",
       "1  Exciting findings: Tai Chi improves physical p...   \n",
       "2                                               None   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Hey! I found this super cool study on Tai Chi ...  \n",
       "1  Did you know that practicing Tai Chi can impro...  \n",
       "2                                               None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.111 repeat w/ updated prompts (removed extra space character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #206 prompt #1 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #206 prompt #2 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #206 prompt #3 of 3**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 206_prompt00...\n",
      "Processing 206_prompt01...\n",
      "Processing 206_prompt02...\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #206: Discover the Surprising Correlates of Physical Activity and Sedentary Behavior in Overweight Adults\n",
      "\tReference #206: Exciting new research on physical activity and sedentary behavior in adults with overweight or obesity\n",
      "\tReference #206: New Research on Physical Activity and Sedentary Behavior in People with Obesity\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = None\n",
    "queue_id = None\n",
    "sources_id = 206\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(\n",
    "    n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, sources_id=sources_id, article_limit=article_limit\n",
    "    ):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    if sources_id:\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_sources(sources_id, order_by='id', order='ASC')\n",
    "    else:\n",
    "        ####### \n",
    "        # Step 1: Create sources table\n",
    "        if local:\n",
    "            text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "        elif queue_id:\n",
    "            if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "                print('Converting queue_id list to tuple')\n",
    "                queue_id = tuple(queue_id)\n",
    "            elif (type(queue_id) == list):\n",
    "                print('Converting queue_id list to number')\n",
    "                queue_id = queue_id[0]\n",
    "            if type(queue_id) == tuple:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id IN {queue_id}'\n",
    "                    )\n",
    "            else:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id = {queue_id}'\n",
    "                    )\n",
    "        else:\n",
    "            text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "        references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "        ###### \n",
    "        # Step 2:  Add rows from gpt_queue table to sources table \n",
    "        bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    # return sources_df\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 6: test new headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #206 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 206_prompt00...\n",
      "Original summaries DataFrame shape: (2, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 2 rows to the database...\n",
      "\tReference #206: Exciting findings on physical activity and sedentary behavior in adults with overweight or obesity!\n",
      "\tReference #206: Surprising Factors that Impact Physical Activity and Sedentary Behavior in Adults with Overweight/Obesity\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = None\n",
    "queue_id = None\n",
    "sources_id = 206\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(\n",
    "    n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, sources_id=sources_id, article_limit=article_limit\n",
    "    ):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    if sources_id:\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_sources(sources_id, order_by='id', order='ASC')\n",
    "    else:\n",
    "        ####### \n",
    "        # Step 1: Create sources table\n",
    "        if local:\n",
    "            text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "        elif queue_id:\n",
    "            if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "                print('Converting queue_id list to tuple')\n",
    "                queue_id = tuple(queue_id)\n",
    "            elif (type(queue_id) == list):\n",
    "                print('Converting queue_id list to number')\n",
    "                queue_id = queue_id[0]\n",
    "            if type(queue_id) == tuple:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id IN {queue_id}'\n",
    "                    )\n",
    "            else:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id = {queue_id}'\n",
    "                    )\n",
    "        else:\n",
    "            text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "        references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "        ###### \n",
    "        # Step 2:  Add rows from gpt_queue table to sources table \n",
    "        bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    # return sources_df\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-07 09:30:20.940656-07:00</td>\n",
       "      <td>206</td>\n",
       "      <td>Correlates of physical activity and sedentary ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4 DISCUSSION\\nThis review provides a summary o...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Use the text from step 1 to create a fun tw...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>A recent review analyzed 45 studies to identif...</td>\n",
       "      <td>New research reveals factors affecting physica...</td>\n",
       "      <td>Did you know that factors like self-efficacy a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-09-07 09:30:20.940656-07:00           206   \n",
       "\n",
       "                                       article_title  choice  \\\n",
       "0  Correlates of physical activity and sedentary ...       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  4 DISCUSSION\\nThis review provides a summary o...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Use the text from step 1 to create a fun tw...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "\n",
       "                                             summary  \\\n",
       "0  A recent review analyzed 45 studies to identif...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  New research reveals factors affecting physica...   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Did you know that factors like self-efficacy a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 7: prompt 42 for new headline prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #268 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 268_prompt00...\n",
      "Original summaries DataFrame shape: (2, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 2 rows to the database...\n",
      "\tReference #268: Personalized interventions may enhance weight loss, according to new research\n",
      "\tReference #268: Tailored lifestyle interventions enhance weight loss for adults with obesity\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "import os\n",
    "api_key = os.environ['api_key_openai']\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = None\n",
    "queue_id = None\n",
    "sources_id = 268\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(\n",
    "    n_choices, temperature, model, pause_per_request, folder_path, section, local, queue_id=queue_id, sources_id=sources_id, article_limit=article_limit\n",
    "    ):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    if sources_id:\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_sources(sources_id, order_by='id', order='ASC')\n",
    "    else:\n",
    "        ####### \n",
    "        # Step 1: Create sources table\n",
    "        if local:\n",
    "            text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "        elif queue_id:\n",
    "            if (type(queue_id) == list) & (len(queue_id) > 1):\n",
    "                print('Converting queue_id list to tuple')\n",
    "                queue_id = tuple(queue_id)\n",
    "            elif (type(queue_id) == list):\n",
    "                print('Converting queue_id list to number')\n",
    "                queue_id = queue_id[0]\n",
    "            if type(queue_id) == tuple:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id IN {queue_id}'\n",
    "                    )\n",
    "            else:\n",
    "                text_df = get_table(\n",
    "                    table='gpt_queue', limit=article_limit, \n",
    "                    filter_statement=f'id = {queue_id}'\n",
    "                    )\n",
    "        else:\n",
    "            text_df = get_table(table='gpt_queue', limit=article_limit, order='DESC') # db_orm.py\n",
    "        references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "        ###### \n",
    "        # Step 2:  Add rows from gpt_queue table to sources table \n",
    "        bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Get the new sources for summarization\n",
    "        sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    # return sources_df\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
