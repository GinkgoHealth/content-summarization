{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "import time\n",
    "import re\n",
    "\n",
    "from response_processing import *\n",
    "from article_processing import create_text_dict_from_folder\n",
    "import traceback\n",
    "from file_functions import *\n",
    "# from summary_chain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web crawler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<p class=\"logo-bmj-journals\"><a href=\"http://journals.bmj.com/\" title=\"BMJ '\n",
      " 'Journals\"><img '\n",
      " 'src=\"/sites/default/themes/bmjj/img/logos/logo-bmj-journals.svg\" title=\"BMJ '\n",
      " 'Journals\" alt=\"BMJ Journals\"></a></p><h3>Log in using your username and '\n",
      " 'password</h3><h2 class=\"pane-title\"><span '\n",
      " 'class=\"icon-search\"></span></h2><h2 class=\"pane-title\"><span '\n",
      " 'class=\"icon-menu\"></span></h2><h2 class=\"pane-title\">Main menu</h2><h3>Log '\n",
      " 'in using your username and password</h3><h2 class=\"element-invisible\">You '\n",
      " 'are here</h2><p><span class=\"icon-article-text\"></span>Article Text</p><p><a '\n",
      " 'class=\"article-pdf-download\" href=\"/content/bmjopen/13/6/e064322.full.pdf\" '\n",
      " 'target=\"new\"><img alt=\"Download PDF\" '\n",
      " 'src=\"/sites/default/themes/bmjj/img/icon-pdf.png\"><strong>PDF</strong></a></p><p><a '\n",
      " 'class=\"article-pdf-download\" '\n",
      " 'href=\"/content/bmjopen/13/6/e064322.full.pdf?with-ds=yes\" target=\"new\"><img '\n",
      " 'alt=\"Download PDF + Supplemental Data\" '\n",
      " 'src=\"/sites/default/themes/bmjj/img/icon-pdf.png\"><strong>PDF +<br>\\n'\n",
      " 'Supplementary<br>\\n'\n",
      " 'Material</strong></a></p><h2>Abstract</h2><p '\n",
      " 'id=\"p-2\"><strong>Introduction</strong> Current published guidelines and '\n",
      " 'meta-analyses comparing endovascular thrombectomy (EVT) alone versus EVT '\n",
      " 'with bridging intravenous thrombolysis (IVT) suggest that EVT alone is '\n",
      " 'non-inferior to EVT with bridging thrombolysis in achieving favourable '\n",
      " 'functional outcome. Because of this controversy, we aimed to systematically '\n",
      " 'update the evidence and meta-analyse data from randomised trials comparing '\n",
      " 'EVT alone versus EVT with bridging thrombolysis, and performed an economic '\n",
      " 'evaluation comparing both strategies.</p><p id=\"p-3\"><strong>Methods and '\n",
      " 'analysis</strong> We will conduct a systematic review of randomised '\n",
      " 'controlled trials comparing EVT with or without bridging thrombolysis in '\n",
      " 'patients presenting with large vessel occlusions. We will identify eligible '\n",
      " 'studies by systematically searching the following databases from inception '\n",
      " 'without any language restrictions: MEDLINE (through Ovid), Embase and the '\n",
      " 'Cochrane Library. The following criteria will be used to assess eligibility '\n",
      " 'for inclusion: (1) adult patients ≥18 years old; (2) randomised patients to '\n",
      " 'EVT alone or to EVT with IVT; and (3) measured outcomes, including '\n",
      " 'functional outcomes, at least 90 days after randomisation. Pairs of '\n",
      " 'reviewers will independently screen the identified articles, extract '\n",
      " 'information and assess the risk of bias of eligible studies. We will use the '\n",
      " 'Cochrane Risk-of-Bias tool to evaluate risk of bias. We will also use the '\n",
      " 'Grading of Recommendations, Assessment, Development and Evaluation approach '\n",
      " 'to assess the certainty in evidence for each outcome. We will then perform '\n",
      " 'an economic evaluation based on the extracted data.</p><p '\n",
      " 'id=\"p-4\"><strong>Ethics and dissemination</strong> This systematic review '\n",
      " 'will not require a research ethics approval because no confidential patient '\n",
      " 'data will be used. We will disseminate our findings by publishing the '\n",
      " 'results in a peer-reviewed journal and via presentation at '\n",
      " 'conferences.</p><p id=\"p-5\"><strong>PROSPERO registration number</strong> '\n",
      " 'CRD42022315608.</p><p id=\"p-1\">This is an open access article distributed in '\n",
      " 'accordance with the Creative Commons Attribution Non Commercial (CC BY-NC '\n",
      " '4.0) license, which permits others to distribute, remix, adapt, build upon '\n",
      " 'this work non-commercially, and license their derivative works on different '\n",
      " 'terms, provided the original work is properly cited, appropriate credit is '\n",
      " 'given, any changes made indicated, and the use is non-commercial. See:\\xa0<a '\n",
      " 'href=\"http://creativecommons.org/licenses/by-nc/4.0/\" '\n",
      " 'rel=\"license\">http://creativecommons.org/licenses/by-nc/4.0/</a>.</p><p><a '\n",
      " 'href=\"http://dx.doi.org/10.1136/bmjopen-2022-064322\" '\n",
      " 'target=\"_new\">http://dx.doi.org/10.1136/bmjopen-2022-064322</a></p><h2 '\n",
      " 'class=\"pane-title\">Statistics from Altmetric.com</h2><h2 '\n",
      " 'class=\"pane-title\">Request Permissions</h2><p>If you wish to reuse any or '\n",
      " 'all of this article please use the link below which will take you to the '\n",
      " 'Copyright Clearance Center’s RightsLink service. You will be able to get a '\n",
      " 'quick price and instant permission to reuse the content in many different '\n",
      " 'ways.</p><h2 class=\"pane-title\"><span class=\"panels-ajax-pane-title\" '\n",
      " 'data-pid=\"new-70fd4c70-563e-4b94-ae3b-2a97f3980c13\"></span></h2><h3>Strengths '\n",
      " 'and limitations of this study</h3><p id=\"p-6\">The broad study eligibility '\n",
      " 'criteria will increase the generalisability of our results.</p><p '\n",
      " 'id=\"p-7\">We will use the Grading of Recommendations, Assessment, Development '\n",
      " 'and Evaluation approach to assess the certainty in evidence for each '\n",
      " 'outcome.</p><p id=\"p-8\">We will perform an economic evaluation based on the '\n",
      " 'meta-analysed data to assess which treatment strategy is more '\n",
      " 'cost-effective, and we will rank the treatment strategies based on efficacy, '\n",
      " 'safety and cost-effectiveness.</p><p id=\"p-9\">Our results will be limited by '\n",
      " 'the primary data, for which careful appraisal of the study quality will be '\n",
      " 'carried out.</p><h2 class=\"\">Introduction</h2><p id=\"p-10\">Intravenous '\n",
      " 'thrombolysis (IVT) has been a long-standing, evidence-based treatment '\n",
      " 'approach for acute ischaemic stroke.<a id=\"xref-ref-1-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-1\">1 2</a> However, IVT must be delivered within 4.5\\u2009hours, '\n",
      " 'has many contraindications, may not provide adequate reperfusion, especially '\n",
      " 'in patients with large vessel occlusions, and may even increase the risk of '\n",
      " 'intracranial haemorrhage.<a id=\"xref-ref-3-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-3\">3</a> As such, trials were conducted to evaluate the use of '\n",
      " 'endovascular therapy in patients with acute ischaemic stroke. The '\n",
      " 'Interventional Management of Stroke (IMS) III was a randomised controlled '\n",
      " 'trial (RCT) comparing endovascular therapy after IVT with IVT alone. '\n",
      " 'Endovascular therapy included a variety of techniques, such as mechanical '\n",
      " 'and aspiration thrombectomy, stent-retriever technology or intra-arterial '\n",
      " 'thrombolysis.<a id=\"xref-ref-4-1\" class=\"xref-bibr\" href=\"#ref-4\">4</a> The '\n",
      " 'Local Versus Systemic Thrombolysis for Acute Ischemic Stroke (SYNTHESIS) '\n",
      " 'trial compared endovascular therapy, including intra-arterial thrombolysis, '\n",
      " 'clot disruption or retrieval or a combination of these approaches, with IVT '\n",
      " 'alone.<a id=\"xref-ref-5-1\" class=\"xref-bibr\" href=\"#ref-5\">5</a> The '\n",
      " 'Mechanical Retrieval and Recanalisation of Stroke Clots Using Embolectomy '\n",
      " '(MR RESCUE) trial compared patients who underwent endovascular therapy alone '\n",
      " 'versus those who received standard care.<a id=\"xref-ref-6-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-6\">6</a> These three RCTs all failed to show '\n",
      " 'any benefit for endovascular therapy in acute ischaemic stroke. There were '\n",
      " 'several limitations in these trials, ranging from inconsistencies with '\n",
      " 'imaging selection, timing variables and device use.</p><p id=\"p-11\">Since '\n",
      " '2015, several RCTs have shown robust evidence supporting the use of '\n",
      " 'endovascular therapy in patients who present with an acute ischaemic stroke '\n",
      " 'secondary to a large vessel occlusion.<a id=\"xref-ref-7-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-7\">7–16</a> Because IVT does not adequately recanalise large or '\n",
      " 'proximal intracranial occlusions, the significant treatment effect of '\n",
      " 'endovascular thrombectomy (EVT) in both IVT-eligible and IVT-ineligible '\n",
      " 'patients with large vessel occlusions, the potential delaying effect of IVT '\n",
      " 'to initiation of EVT and its possible association with increased bleeding '\n",
      " 'events, many RCTs and post hoc analyses of RCTs have evaluated the safety '\n",
      " 'and efficacy of EVT alone versus bridging IVT prior to EVT in patients '\n",
      " 'presenting with acute ischaemic stroke secondary to a large vessel '\n",
      " 'occlusion, and have shown conflicting evidence whether EVT alone would be '\n",
      " 'non-inferior to EVT with pretreatment IVT.<a id=\"xref-ref-17-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-17\">17–22</a> The 2019 European Stroke '\n",
      " 'Organisation (ESO)–European Society for Minimally Invasive Neurological '\n",
      " 'Therapy (ESMINT) guidelines found high quality of evidence recommending the '\n",
      " 'use of EVT and best medical management within 6\\u2009hours after symptom '\n",
      " 'onset, and moderate quality of evidence for use of EVT and best medical '\n",
      " 'management in patients presenting within the window of 6–24 hours.<a '\n",
      " 'id=\"xref-ref-23-1\" class=\"xref-bibr\" href=\"#ref-23\">23</a> The ESO-ESMINT '\n",
      " 'guidelines published an expedited recommendation strongly recommending IVT '\n",
      " 'plus EVT over EVT alone.<a id=\"xref-ref-24-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-24\">24</a> Similarly, the 2019 American Heart Association '\n",
      " 'guidelines provided a class I recommendation for the use of IVT prior to EVT '\n",
      " 'in IVT-eligible patients.<a id=\"xref-ref-25-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-25\">25</a></p><p id=\"p-12\">There are several published systematic '\n",
      " 'reviews exploring the efficacy of bridging IVT prior to EVT compared with '\n",
      " 'EVT alone<a id=\"xref-ref-26-1\" class=\"xref-bibr\" href=\"#ref-26\">26–42</a>; '\n",
      " 'however, they do not adequately assess risk of bias or the certainty of '\n",
      " 'evidence in each outcome, and vary in their study inclusion criteria and '\n",
      " 'methodology. A recently published systematic review and meta-analysis has '\n",
      " 'focused on comparing the two treatment strategies in patients presenting '\n",
      " 'with large vessel occlusions involving only the anterior circulation and has '\n",
      " 'assessed the certainty of evidence using the Grading of Recommendations, '\n",
      " 'Assessment, Development and Evaluation (GRADE) approach.<a '\n",
      " 'id=\"xref-ref-43-1\" class=\"xref-bibr\" href=\"#ref-43\">43</a> This review, '\n",
      " 'however, excludes patients with large vessel occlusions in the posterior '\n",
      " 'circulation. None of these systematic reviews consistently assessed the '\n",
      " 'overall certainty of evidence and conducted a cost-effectiveness analysis '\n",
      " 'comparing bridging IVT prior to EVT versus EVT alone. Thus, we propose to '\n",
      " 'conduct a systematic review and meta-analysis of randomised trials to assess '\n",
      " 'the comparative efficacy and safety of EVT alone versus IVT plus EVT for '\n",
      " 'patients with acute ischaemic stroke secondary to large vessel occlusion and '\n",
      " 'perform a cost-effectiveness analysis using the meta-analysed data.</p><h2 '\n",
      " 'class=\"\">Methods and analysis</h2><h3>Standardised reporting and '\n",
      " 'registration</h3><p id=\"p-13\">We ensured our protocol was prepared in '\n",
      " 'accordance with the Preferred Reporting Items for Systematic Review and '\n",
      " 'Meta-Analyses Protocols checklist.<a id=\"xref-ref-44-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-44\">44</a> This systematic review is registered with '\n",
      " 'International Prospective Register of Systematic Reviews (PROSPERO) '\n",
      " '(registration number CRD42022315608).</p><h3>Eligibility criteria</h3><p '\n",
      " 'id=\"p-14\">We will include randomised trials meeting the following criteria: '\n",
      " '(1) enrolled adult patients ≥18 years old presenting with an acute ischaemic '\n",
      " 'stroke secondary to a large vessel occlusion, regardless of vessel involved, '\n",
      " 'and (2) randomised patients to undergo EVT alone or to receive IVT in '\n",
      " 'addition to EVT. We will include trials that permitted cointerventions (eg, '\n",
      " 'intra-arterial thrombolysis, rescue stenting) only if the same '\n",
      " 'cointerventions were used in patients from all study arms. <a '\n",
      " 'id=\"xref-table-wrap-1-1\" class=\"xref-table\" href=\"#T1\">Table 1</a> provides '\n",
      " 'a more detailed representation of the inclusion and exclusion '\n",
      " 'criteria.</p><p id=\"p-15\" class=\"first-child\">Inclusion and exclusion '\n",
      " 'criteria for study eligibility</p><h3>Data sources and search '\n",
      " 'strategy</h3><p id=\"p-25\">An information specialist (LH) developed the '\n",
      " 'search strategy for the databases (<a id=\"xref-fig-1-1\" class=\"xref-fig\" '\n",
      " 'href=\"#F1\">figure 1</a>, <a id=\"xref-supplementary-material-1-1\" '\n",
      " 'class=\"xref-supplementary-material\" href=\"#DC1\">online supplemental appendix '\n",
      " '1</a>). We will conduct our searches systematically looking for eligible '\n",
      " 'studies in MEDLINE (through Ovid), Embase and the Cochrane Library from '\n",
      " 'inception without language restrictions. We will also review the reference '\n",
      " 'lists of included studies and relevant reviews to identify any additional '\n",
      " 'studies meeting the eligibility criteria.</p><h3 class=\"\">Supplemental '\n",
      " 'material</h3><p id=\"p-27\" class=\"first-child\">Sample search algorithm for '\n",
      " 'MEDLINE(through Ovid).</p><h3>Study selection</h3><p id=\"p-28\">Prior to the '\n",
      " 'screening process, teams of two reviewers will participate in calibration '\n",
      " 'exercises. Following the calibration exercises, teams of two reviewers will '\n",
      " 'subsequently double screen the titles and abstracts of all identified '\n",
      " 'citations. These pairs of two reviewers will then retrieve and double screen '\n",
      " 'the full texts of all citations for eligibility.<a id=\"xref-ref-45-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-45\">45</a> Screening will be done manually '\n",
      " 'without the use of software applications. A third reviewer will resolve '\n",
      " 'disagreements if necessary. We will also contact study authors if reviewers '\n",
      " 'find any uncertainties limiting ability to discern study '\n",
      " 'eligibility.</p><h3>Data extraction</h3><p id=\"p-29\">We designed a '\n",
      " 'standardised extraction form and a comprehensive instruction manual to '\n",
      " 'assist with data extraction. We will conduct calibration exercises prior to '\n",
      " 'the data extraction phase to ensure accuracy and consistency. Pairs of two '\n",
      " 'reviewers will subsequently extract data independently and review in '\n",
      " 'duplicate.</p><p id=\"p-30\">Reviewers will extract the following data for all '\n",
      " 'included studies: study characteristics (eg, author information, country of '\n",
      " 'origin and study design), patient characteristics (eg, sample size, age and '\n",
      " 'sex of patients, medical history, National Institute of Health Stroke Scale '\n",
      " 'score, the proportion for each vessel involved as well as determined stroke '\n",
      " 'aetiology), characteristics of interventions and comparators (eg, '\n",
      " 'intravenous thrombolytic agent used and respective dose and thrombectomy '\n",
      " 'device used) and treatment outcomes, including mortality, functional '\n",
      " 'independence, successful reperfusion, intracranial haemorrhage (including '\n",
      " 'symptomatic intracranial haemorrhage), and procedural complications and '\n",
      " 'other adverse events. Data will be abstracted into an Excel spreadsheeting '\n",
      " 'using Microsoft Office Excel V.2021. If there are any missing details, we '\n",
      " 'will contact the authors of included studies when applicable.</p><p '\n",
      " 'id=\"p-31\">We conducted a preliminary literature search of the databases, and '\n",
      " 'conclusion of the search suggests that there will be an estimate of six '\n",
      " 'studies eligible for this review.</p><h3>Risk of bias assessment</h3><p '\n",
      " 'id=\"p-32\">Pairs of reviewers will assess the risk of bias of included '\n",
      " 'studies independently and in duplicate using the revised Cochrane '\n",
      " 'Risk-of-Bias V.2 (RoB 2) tool. We will address concerns for low interrater '\n",
      " 'reliability and other expected challenges, such as difficult terminology, by '\n",
      " 'training the reviewers to improve the reliability of RoB 2.<a '\n",
      " 'id=\"xref-ref-46-1\" class=\"xref-bibr\" href=\"#ref-46\">46</a> We will use the '\n",
      " 'following criteria to assess risk of bias: randomisation process, deviations '\n",
      " 'from intended interventions, missing outcome data, measurement of the '\n",
      " 'outcome and selection of the reported result.<a id=\"xref-ref-47-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-47\">47</a> We will resolve any disagreements '\n",
      " 'between reviewers through consensus and/or with the assistance of an '\n",
      " 'adjudicator. Risk of bias for included studies will be illustrated in '\n",
      " 'figures produced by Risk-of-bias Visualization.<a id=\"xref-ref-48-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-48\">48</a></p><h3>Data synthesis</h3><p '\n",
      " 'id=\"p-33\">We will group all outcomes reported by at least two studies for '\n",
      " 'direct comparison. We will standardise the definitions and measurements of '\n",
      " 'each outcome via consensus. We will conduct a meta-analysis of the outcomes '\n",
      " 'of interest when possible using the generic inverse variance method and '\n",
      " 'random effects analysis model via Review Manager V.5.4. We will use '\n",
      " 'Harbord’s test to assess small study effects for binary outcomes and Egger’s '\n",
      " 'test for continuous outcomes when there are at least 10 studies eligible for '\n",
      " 'quantitative assessment.<a id=\"xref-ref-49-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-49\">49</a> When no meta-analysis could be performed due to '\n",
      " 'heterogeneity of the data, we will narratively synthesise the findings. For '\n",
      " 'dichotomous outcomes reported by at least one RCT, we will calculate the '\n",
      " 'relative risk (RR) using the crude event rate and the associated 95% CIs to '\n",
      " 'inform relative effectiveness. We will calculate risk difference based on '\n",
      " 'the RRs from our study and the baseline risks from a well-designed, '\n",
      " 'high-quality multicentre observational study of 6350 patients who had '\n",
      " 'ischaemic stroke.<a id=\"xref-ref-50-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-50\">50</a> For continuous outcomes reported by at least one RCT, '\n",
      " 'we will calculate the weighted mean difference and associated 95%\\u2009CI. '\n",
      " 'When only median and range values are reported or when SD are not reported, '\n",
      " 'we will use methods outlined in <em>Cochrane Handbook for Systematic Reviews '\n",
      " 'of Interventions</em> and by Wan <em>et al</em> to estimate means and SD.<a '\n",
      " 'id=\"xref-ref-51-1\" class=\"xref-bibr\" href=\"#ref-51\">51 52</a> We will report '\n",
      " 'our synthesised findings as funnel plots to assess for asymmetry per outcome '\n",
      " 'of interest and will also estimate Egger’ test of the intercept to assess '\n",
      " 'for publication bias.<a id=\"xref-ref-53-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-53\">53</a></p><h3>Subgroup analysis</h3><p id=\"p-34\">We will '\n",
      " 'evaluate statistical heterogeneity using inconsistency measures, Cochran’s Q '\n",
      " 'test and I<sup>2</sup>. We will use the following a priori hypotheses to '\n",
      " 'explain heterogeneity between studies: (1) location of vessel involved (eg, '\n",
      " 'anterior circulation or posterior circulation) will show different treatment '\n",
      " 'effects<a id=\"xref-ref-54-1\" class=\"xref-bibr\" href=\"#ref-54\">54</a>; (2) '\n",
      " 'high risk of bias studies will show larger treatment effects; and (3) type '\n",
      " 'of thrombectomy devices used (eg, stent retriever, aspiration, etc). We will '\n",
      " 'perform subgroup analyses irrespective of the heterogeneity estimates as '\n",
      " 'long as there are at least two studies representing each '\n",
      " 'subgroup.</p><h3>Assessing certainty of the evidence</h3><p id=\"p-35\">For '\n",
      " 'each outcome, we will assess the certainty of the evidence (as high, '\n",
      " 'moderate, low or very low) using the GRADE approach and developed GRADE '\n",
      " 'evidence profiles.<a id=\"xref-ref-55-1\" class=\"xref-bibr\" href=\"#ref-55\">55 '\n",
      " '56</a> We will use previously derived thresholds for the minimally important '\n",
      " 'difference for favourable functional outcome, mortality and symptomatic '\n",
      " 'intracranial hemorrhage (sICH), adapted from Wang and colleagues.<a '\n",
      " 'id=\"xref-ref-57-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-57\">57</a></p><h3>Cost–utility analysis</h3><p id=\"p-36\">We will '\n",
      " 'conduct a model-based cost–utility analysis to determine the '\n",
      " 'cost-effectiveness of EVT alone compared with IVT and EVT for patients with '\n",
      " 'an acute ischaemic stroke secondary to a large vessel occlusion. A Markov '\n",
      " 'decision analytical model with a lifetime horizon will be developed to '\n",
      " 'predict the long-term costs and health outcomes. We will conduct the '\n",
      " 'analysis from a healthcare perspective. We will base the clinical outcome '\n",
      " 'inputs from this systematic review. We will search literature for the '\n",
      " 'long-term clinical outcome inputs. From the healthcare perspective, we will '\n",
      " 'consider both medical costs (ie, costs related to patient care) and '\n",
      " 'non-medical costs (ie, overhead costs such as finance, human resources and '\n",
      " 'administration) that are incurred during treatment. The treatment costs come '\n",
      " 'from the administrative data of the University of Chicago Medical Center. '\n",
      " 'Other cost estimates (ie, health state-related costs) and utility inputs '\n",
      " 'will be based on literature.</p><h3>Patient and public involvement</h3><p '\n",
      " 'id=\"p-37\">Neither patients nor the public was involved in the '\n",
      " 'study.</p><h3>Ethics and dissemination</h3><p id=\"p-38\">This systematic '\n",
      " 'review will not require a research ethics approval because no confidential '\n",
      " 'patient data will be used. We will disseminate our findings by publishing '\n",
      " 'the results in a peer-reviewed journal and via presentation at '\n",
      " 'conferences.</p><h2 class=\"\">Discussion</h2><p id=\"p-39\">EVT has emerged to '\n",
      " 'become a superior treatment modality compared with medical management alone '\n",
      " 'for the treatment of strokes secondary to large vessel occlusions, '\n",
      " 'particularly in the anterior circulation.<a id=\"xref-ref-58-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-58\">58</a> However, controversies in the safety '\n",
      " 'and efficacy of bridging IVT prior to thrombectomy remain to be the subject '\n",
      " 'of debate. A recent subgroup analysis showed that the effect of intravenous '\n",
      " 'alteplase prior to thrombectomy is not significantly associated with the '\n",
      " 'occlusion site<a id=\"xref-ref-59-1\" class=\"xref-bibr\" href=\"#ref-59\">59</a>; '\n",
      " 'however, the trial for which this analysis was based included only '\n",
      " 'occlusions in the internal carotid and M1 or M2 branches of the middle '\n",
      " 'cerebral artery.<a id=\"xref-ref-21-1\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-21\">21</a> An editorial by Podlasek and colleagues briefly '\n",
      " 'reviewed the combined the trial data from six RCTs and showed that EVT alone '\n",
      " 'is non-inferior to bridging therapy in achieving good functional outcomes at '\n",
      " '3 months with a 6% margin of confidence.<a id=\"xref-ref-60-1\" '\n",
      " 'class=\"xref-bibr\" href=\"#ref-60\">60</a> While most guidelines currently '\n",
      " 'recommend IVT prior to thrombectomy,<a id=\"xref-ref-23-2\" class=\"xref-bibr\" '\n",
      " 'href=\"#ref-23\">23–25</a> there is a need for a high-quality review to '\n",
      " 'provide a clinical summary of the efficacy and safety of mechanical '\n",
      " 'thrombectomy alone versus IVT prior to mechanical thrombectomy and to '\n",
      " 'balance those outcomes with cost.</p><p id=\"p-40\">Our study will have many '\n",
      " 'strengths compared with existing reviews in the literature. First, we will '\n",
      " 'compare the efficacy and safety of mechanical thrombectomy alone versus '\n",
      " 'mechanical thrombectomy and bridging thrombolysis in studies that only '\n",
      " 'directly compare the two interventions strategies. Second, we will '\n",
      " 'investigate the effects of treatment across certain conditions. Third, we '\n",
      " 'will apply the RoB 2 tool and GRADE approach to evaluate the risk of bias '\n",
      " 'and certainty of evidence, respectively, for each outcome. Lastly, this '\n",
      " 'study will be the first to use meta-analysed data to robustly perform an '\n",
      " 'economic evaluation comparing the two treatment strategies, integrate '\n",
      " 'clinical outcome inputs from study-level data and treatment cost inputs from '\n",
      " 'administrative data. Some potential limitations will include the following: '\n",
      " 'heterogeneity of outcome definitions and measurement, such as in the case of '\n",
      " 'symptomatic intracranial haemorrhage; cost estimation cannot assess for '\n",
      " 'lifetime cost as there are limited longitudinal data with respect to the '\n",
      " 'treatment strategies. The findings of our study will help inform providers '\n",
      " 'about the role of IVT in mechanical thrombectomy and identify key areas for '\n",
      " 'future research.</p><h2 class=\"\">Ethics statements</h2><h3>Patient consent '\n",
      " 'for publication</h3><p id=\"p-48\" class=\"ethics-consent-to-publish\">Not '\n",
      " 'applicable.</p><h2 class=\"\">References</h2><h2 '\n",
      " 'class=\"pane-title\">Supplementary materials</h2><h2>Supplementary '\n",
      " 'Data</h2><p>This web only file has been produced by the BMJ Publishing Group '\n",
      " 'from an electronic\\n'\n",
      " '               file supplied by the author(s) and has not been edited for '\n",
      " 'content.\\n'\n",
      " '            </p><h2>Footnotes</h2><p id=\"p-41\"><span '\n",
      " 'class=\"fn-label\">Twitter</span> @LHneiny</p><p id=\"p-42\"><span '\n",
      " 'class=\"fn-label\">Contributors</span> RZM and TK: conception and design of '\n",
      " 'the work, analysis, drafting of the manuscript and final approval. YZ, AMK '\n",
      " 'and AJD: analysis, design of the work and drafting of the manuscript and '\n",
      " 'final approval. JC-P, HD, ET, SK, AT and RB: data collection. LH: design of '\n",
      " 'the work and final approval. ST, EC, JRB, SM, AM and SP: analysis, drafting '\n",
      " 'of the work and final approval. All authors reviewed and contributed to the '\n",
      " 'final version of this article.</p><p id=\"p-43\"><span '\n",
      " 'class=\"fn-label\">Funding</span> The authors have not declared a specific '\n",
      " 'grant for this research from any funding agency in the public, commercial or '\n",
      " 'not-for-profit sectors.</p><p id=\"p-44\"><span class=\"fn-label\">Competing '\n",
      " 'interests</span> None declared.</p><p id=\"p-45\"><span '\n",
      " 'class=\"fn-label\">Patient and public involvement</span> Patients and/or the '\n",
      " 'public were not involved in the design, conduct, reporting or dissemination '\n",
      " 'plans of this research.</p><p id=\"p-46\"><span class=\"fn-label\">Provenance '\n",
      " 'and peer review</span> Not commissioned; externally peer reviewed.</p><p '\n",
      " 'id=\"p-47\"><span class=\"fn-label\">Supplemental material</span> This content '\n",
      " 'has been supplied by the author(s). It has not been vetted by BMJ Publishing '\n",
      " 'Group Limited (BMJ) and may not have been peer-reviewed. Any opinions or '\n",
      " 'recommendations discussed are solely those of the author(s) and are not '\n",
      " 'endorsed by BMJ. BMJ disclaims all liability and responsibility arising from '\n",
      " 'any reliance placed on the content. Where the content includes any '\n",
      " 'translated material, BMJ does not warrant the accuracy and reliability of '\n",
      " 'the translations (including but not limited to local regulations, clinical '\n",
      " 'guidelines, terminology, drug names and drug dosages), and is not '\n",
      " 'responsible for any error and/or omissions arising from translation and '\n",
      " 'adaptation or otherwise.</p><h2 class=\"pane-title\">Read the full text or '\n",
      " 'download the PDF:</h2><h3>Log in using your username and '\n",
      " 'password</h3><p><small><span class=\"online-issn issn\">Online ISSN: '\n",
      " '2044-6055</span><span class=\"print-issn issn\">Print ISSN: '\n",
      " '2044-6055</span></small><br>\\n'\n",
      " '        <small>Copyright © 2023 BMJ Publishing Group Ltd. All rights '\n",
      " 'reserved.</small></p>')\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "setup()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class myspider(scrapy.Spider):\n",
    "    name = \"myspider\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = ['https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv']\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse_front)\n",
    "    \n",
    "    def parse_front(self, response):\n",
    "        # self.article_title = response.css('a.art-title > font::text').extract()\n",
    "        # article_url = response.xpath('//a[@class=\"art-title\"]/@href').extract()\n",
    "        self.article_title = [response.css('a.art-title > font::text').extract_first()]\n",
    "        article_url = [response.xpath('//a[@class=\"art-title\"]/@href').extract_first()]\n",
    "        for index, url in enumerate(article_url):\n",
    "            article_dict[index] = dict()\n",
    "            article_dict[index]['title'] = self.article_title[index]\n",
    "            article_dict[index]['url'] = url\n",
    "            yield response.follow(url=url, callback=self.parse_pages, cb_kwargs={'index': index})\n",
    "    \n",
    "    def parse_pages(self, response, index):\n",
    "        text = response.xpath('//h2|//p|//h3|//h4').extract()\n",
    "        article_dict[index]['text'] = ''.join([line for line in text])\n",
    "        \n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(myspider)\n",
    "    return d\n",
    "\n",
    "\n",
    "iteration_id = 2.1\n",
    "# main_dict = dict()\n",
    "article_dict = dict()\n",
    "\n",
    "run_spider()\n",
    "main_dict[iteration_id] = article_dict\n",
    "\n",
    "pprint(next(iter(article_dict.values()))['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 allow URL to be passed as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The crawler_or_spidercls argument cannot be a spider object, it must be a spider class (or a Crawler object)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m# url = 'https://journals.plos.org/plosone/feed/atom' # PLOS One\u001b[39;00m\n\u001b[0;32m     44\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 46\u001b[0m run_spider(url)\n\u001b[0;32m     47\u001b[0m main_dict[iteration_id] \u001b[39m=\u001b[39m article_dict\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[39m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[39mreturn\u001b[39;00m eventual_result\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    462\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\crochet\\_eventloop.py:198\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    196\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result(timeout)\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Failure):\n\u001b[1;32m--> 198\u001b[0m     result\u001b[39m.\u001b[39;49mraiseException()\n\u001b[0;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\twisted\\python\\failure.py:504\u001b[0m, in \u001b[0;36mFailure.raiseException\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraiseException\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m    500\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[39m    raise the original exception, preserving traceback\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[39m    information if available.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb)\n",
      "\u001b[1;31mValueError\u001b[0m: The crawler_or_spidercls argument cannot be a spider object, it must be a spider class (or a Crawler object)"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "import sys\n",
    "\n",
    "setup()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class myspider(scrapy.Spider):\n",
    "    name = \"myspider\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        url = getattr(self, 'url', 'https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv')\n",
    "        yield scrapy.Request(url=url, callback=self.parse_front)\n",
    "    \n",
    "    def parse_front(self, response):\n",
    "        self.article_title = [response.css('a.art-title > font::text').extract_first()]\n",
    "        article_url = [response.xpath('//a[@class=\"art-title\"]/@href').extract_first()]\n",
    "        # self.article_title = [response.css('entry > title::text').extract_first()]\n",
    "        # article_url = [response.xpath('//entry/link[@rel=\"alternate\"]/@href').extract_first()]\n",
    "        for index, url in enumerate(article_url):\n",
    "            article_dict[index] = dict()\n",
    "            article_dict[index]['title'] = self.article_title[index]\n",
    "            article_dict[index]['url'] = url\n",
    "    #         yield response.follow(url=url, callback=self.parse_pages, cb_kwargs={'index': index})\n",
    "    \n",
    "    # def parse_pages(self, response, index):\n",
    "    #     text = response.xpath('//h2|//p|//h3|//h4').extract()\n",
    "    #     article_dict[index]['text'] = ''.join([line for line in text])\n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider(url):\n",
    "    crawler = CrawlerRunner()\n",
    "    spider = myspider(url=url)\n",
    "    d = crawler.crawl(spider)\n",
    "    pprint(f\"Sample result: {next(iter(article_dict.values()))['text']}\")\n",
    "    return d\n",
    "\n",
    "iteration_id = 1.1\n",
    "main_dict = dict()\n",
    "article_dict = dict()\n",
    "# url = 'https://journals.plos.org/plosone/feed/atom' # PLOS One\n",
    "url = 'https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv'\n",
    "\n",
    "run_spider(url)\n",
    "main_dict[iteration_id] = article_dict\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reactor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m article_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m     37\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 39\u001b[0m run_spider(url)\n\u001b[0;32m     40\u001b[0m main_dict[iteration_id] \u001b[39m=\u001b[39m article_dict\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[39m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[39mreturn\u001b[39;00m eventual_result\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    462\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\crochet\\_eventloop.py:198\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    196\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result(timeout)\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Failure):\n\u001b[1;32m--> 198\u001b[0m     result\u001b[39m.\u001b[39;49mraiseException()\n\u001b[0;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\twisted\\python\\failure.py:504\u001b[0m, in \u001b[0;36mFailure.raiseException\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraiseException\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m    500\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[39m    raise the original exception, preserving traceback\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[39m    information if available.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reactor' is not defined"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "import sys\n",
    "\n",
    "setup()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class myspider(scrapy.Spider):\n",
    "    name = \"myspider\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        url = getattr(self, 'url', 'https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv')\n",
    "        yield scrapy.Request(url=url, callback=self.parse_front)\n",
    "    \n",
    "    def parse_front(self, response):\n",
    "        self.article_title = [response.css('a.art-title > font::text').extract_first()]\n",
    "        article_url = [response.xpath('//a[@class=\"art-title\"]/@href').extract_first()]\n",
    "        for index, url in enumerate(article_url):\n",
    "            article_dict[index] = dict()\n",
    "            article_dict[index]['title'] = self.article_title[index]\n",
    "            article_dict[index]['url'] = url\n",
    "    \n",
    "@wait_for(10)\n",
    "def run_spider(url):\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(myspider, url=url)  # Pass the spider class and URL as arguments\n",
    "    d.addBoth(lambda _: reactor.stop())  # Stop the reactor when the crawl is finished\n",
    "    reactor.run()  # Run the reactor\n",
    "    pprint(f\"Sample result: {next(iter(article_dict.values()))['text']}\")\n",
    "    return d\n",
    "\n",
    "iteration_id = 1.2\n",
    "main_dict = dict()\n",
    "article_dict = dict()\n",
    "url = 'https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv'\n",
    "\n",
    "run_spider(url)\n",
    "main_dict[iteration_id] = article_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m run_spider()\n\u001b[0;32m     49\u001b[0m main_dict[iteration_id] \u001b[39m=\u001b[39m article_dict\n\u001b[1;32m---> 50\u001b[0m pprint(\u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(article_dict\u001b[39m.\u001b[39;49mvalues())))\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "setup()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class myspider(scrapy.Spider):\n",
    "    name = \"myspider\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        # urls = ['https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv']\n",
    "        urls = ['https://journals.plos.org/plosone/feed/atom']\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse_front)\n",
    "    \n",
    "    def parse_front(self, response):\n",
    "        # self.article_title = response.css('a.art-title > font::text').extract()\n",
    "        # article_url = response.xpath('//a[@class=\"art-title\"]/@href').extract()\n",
    "        # self.article_title = [response.css('a.art-title > font::text').extract_first()]\n",
    "        # article_url = [response.xpath('//a[@class=\"art-title\"]/@href').extract_first()]\n",
    "        self.article_title = [response.css('entry > title').extract_first()]\n",
    "        # article_url = [response.xpath('//entry/link[@rel=\"alternate\"]/@href').extract_first()]\n",
    "        for index, url in enumerate(article_url):\n",
    "            article_dict[index] = dict()\n",
    "            article_dict[index]['title'] = self.article_title[index]\n",
    "            # article_dict[index]['url'] = url\n",
    "    #         yield response.follow(url=url, callback=self.parse_pages, cb_kwargs={'index': index})\n",
    "    \n",
    "    # def parse_pages(self, response, index):\n",
    "    #     text = response.xpath('//h2|//p|//h3|//h4').extract()\n",
    "    #     article_dict[index]['text'] = ''.join([line for line in text])\n",
    "        \n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(myspider)\n",
    "    # pprint(next(iter(article_dict.values()))['text'])\n",
    "    return d\n",
    "\n",
    "\n",
    "iteration_id = 1.3\n",
    "main_dict = dict()\n",
    "article_dict = dict()\n",
    "url = 'https://journals.plos.org/plosone/feed/atom'\n",
    "# 'https://emails.bmj.com/q/1fnLH65XUsNn7Iiph6kELOM/wv'\n",
    "\n",
    "run_spider()\n",
    "main_dict[iteration_id] = article_dict\n",
    "pprint(next(iter(article_dict.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex pattern: .*<h2>Abstract</h2>.*(?:Introduction)?.*(<h2.*?>Introduction</h2>.*References)<.*\n",
      "text_dict keys: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 class=\"\">Introduction</h2><p id=\"p-10\">Intravenous thrombolysis (IVT) has been a long-standing, evidence-based treatment approach for acute ischaemic stroke.<a id=\"xref-ref-1-1\" class=\"xref-bibr\" href=\"#ref-1\">1 2</a> However, IVT must be delivered within 4.5 hours, has many contraindications, may not provide adequate reperfusion, especially in patients with large vessel occlusions, and may even increase the risk of intracranial haemorrhage.<a id=\"xref-ref-3-1\" class=\"xref-bibr\" href=\"#ref-3\">3</a> As such, trials were conducted to evaluate the use of endovascular therapy in patients with acute ischaemic stroke. The Interventional Management of Stroke (IMS) III was a randomised controlled trial (RCT) comparing endovascular therapy after IVT with IVT alone. Endovascular therapy included a variety of techniques, such as mechanical and aspiration thrombectomy, stent-retriever technology or intra-arterial thrombolysis.<a id=\"xref-ref-4-1\" class=\"xref-bibr\" href=\"#ref-4\">4</a> The Local Versus Systemic Thrombolysis for Acute Ischemic Stroke (SYNTHESIS) trial compared endovascular therapy, including intra-arterial thrombolysis, clot disruption or retrieval or a combination of these approaches, with IVT alone.<a id=\"xref-ref-5-1\" class=\"xref-bibr\" href=\"#ref-5\">5</a> The Mechanical Retrieval and Recanalisation of Stroke Clots Using Embolectomy (MR RESCUE) trial compared patients who underwent endovascular therapy alone versus those who received standard care.<a id=\"xref-ref-6-1\" class=\"xref-bibr\" href=\"#ref-6\">6</a> These three RCTs all failed to show any benefit for endovascular therapy in acute ischaemic stroke. There were several limitations in these trials, ranging from inconsistencies with imaging selection, timing variables and device use.</p><p id=\"p-11\">Since 2015, several RCTs have shown robust evidence supporting the use of endovascular therapy in patients who present with an acute ischaemic stroke secondary to a large vessel occlusion.<a id=\"xref-ref-7-1\" class=\"xref-bibr\" href=\"#ref-7\">7–16</a> Because IVT does not adequately recanalise large or proximal intracranial occlusions, the significant treatment effect of endovascular thrombectomy (EVT) in both IVT-eligible and IVT-ineligible patients with large vessel occlusions, the potential delaying effect of IVT to initiation of EVT and its possible association with increased bleeding events, many RCTs and post hoc analyses of RCTs have evaluated the safety and efficacy of EVT alone versus bridging IVT prior to EVT in patients presenting with acute ischaemic stroke secondary to a large vessel occlusion, and have shown conflicting evidence whether EVT alone would be non-inferior to EVT with pretreatment IVT.<a id=\"xref-ref-17-1\" class=\"xref-bibr\" href=\"#ref-17\">17–22</a> The 2019 European Stroke Organisation (ESO)–European Society for Minimally Invasive Neurological Therapy (ESMINT) guidelines found high quality of evidence recommending the use of EVT and best medical management within 6 hours after symptom onset, and moderate quality of evidence for use of EVT and best medical management in patients presenting within the window of 6–24 hours.<a id=\"xref-ref-23-1\" class=\"xref-bibr\" href=\"#ref-23\">23</a> The ESO-ESMINT guidelines published an expedited recommendation strongly recommending IVT plus EVT over EVT alone.<a id=\"xref-ref-24-1\" class=\"xref-bibr\" href=\"#ref-24\">24</a> Similarly, the 2019 American Heart Association guidelines provided a class I recommendation for the use of IVT prior to EVT in IVT-eligible patients.<a id=\"xref-ref-25-1\" class=\"xref-bibr\" href=\"#ref-25\">25</a></p><p id=\"p-12\">There are several published systematic reviews exploring the efficacy of bridging IVT prior to EVT compared with EVT alone<a id=\"xref-ref-26-1\" class=\"xref-bibr\" href=\"#ref-26\">26–42</a>; however, they do not adequately assess risk of bias or the certainty of evidence in each outcome, and vary in their study inclusion criteria and methodology. A recently published systematic review and meta-analysis has focused on comparing the two treatment strategies in patients presenting with large vessel occlusions involving only the anterior circulation and has assessed the certainty of evidence using the Grading of Recommendations, Assessment, Development and Evaluation (GRADE) approach.<a id=\"xref-ref-43-1\" class=\"xref-bibr\" href=\"#ref-43\">43</a> This review, however, excludes patients with large vessel occlusions in the posterior circulation. None of these systematic reviews consistently assessed the overall certainty of evidence and conducted a cost-effectiveness analysis comparing bridging IVT prior to EVT versus EVT alone. Thus, we propose to conduct a systematic review and meta-analysis of randomised trials to assess the comparative efficacy and safety of EVT alone versus IVT plus EVT for patients with acute ischaemic stroke secondary to large vessel occlusion and perform a cost-effectiveness analysis using the meta-analysed data.</p><h2 class=\"\">Methods and analysis</h2><h3>Standardised reporting and registration</h3><p id=\"p-13\">We ensured our protocol was prepared in accordance with the Preferred Reporting Items for Systematic Review and Meta-Analyses Protocols checklist.<a id=\"xref-ref-44-1\" class=\"xref-bibr\" href=\"#ref-44\">44</a> This systematic review is registered with International Prospective Register of Systematic Reviews (PROSPERO) (registration number CRD42022315608).</p><h3>Eligibility criteria</h3><p id=\"p-14\">We will include randomised trials meeting the following criteria: (1) enrolled adult patients ≥18 years old presenting with an acute ischaemic stroke secondary to a large vessel occlusion, regardless of vessel involved, and (2) randomised patients to undergo EVT alone or to receive IVT in addition to EVT. We will include trials that permitted cointerventions (eg, intra-arterial thrombolysis, rescue stenting) only if the same cointerventions were used in patients from all study arms. <a id=\"xref-table-wrap-1-1\" class=\"xref-table\" href=\"#T1\">Table 1</a> provides a more detailed representation of the inclusion and exclusion criteria.</p><p id=\"p-15\" class=\"first-child\">Inclusion and exclusion criteria for study eligibility</p><h3>Data sources and search strategy</h3><p id=\"p-25\">An information specialist (LH) developed the search strategy for the databases (<a id=\"xref-fig-1-1\" class=\"xref-fig\" href=\"#F1\">figure 1</a>, <a id=\"xref-supplementary-material-1-1\" class=\"xref-supplementary-material\" href=\"#DC1\">online supplemental appendix 1</a>). We will conduct our searches systematically looking for eligible studies in MEDLINE (through Ovid), Embase and the Cochrane Library from inception without language restrictions. We will also review the reference lists of included studies and relevant reviews to identify any additional studies meeting the eligibility criteria.</p><h3 class=\"\">Supplemental material</h3><p id=\"p-27\" class=\"first-child\">Sample search algorithm for MEDLINE(through Ovid).</p><h3>Study selection</h3><p id=\"p-28\">Prior to the screening process, teams of two reviewers will participate in calibration exercises. Following the calibration exercises, teams of two reviewers will subsequently double screen the titles and abstracts of all identified citations. These pairs of two reviewers will then retrieve and double screen the full texts of all citations for eligibility.<a id=\"xref-ref-45-1\" class=\"xref-bibr\" href=\"#ref-45\">45</a> Screening will be done manually without the use of software applications. A third reviewer will resolve disagreements if necessary. We will also contact study authors if reviewers find any uncertainties limiting ability to discern study eligibility.</p><h3>Data extraction</h3><p id=\"p-29\">We designed a standardised extraction form and a comprehensive instruction manual to assist with data extraction. We will conduct calibration exercises prior to the data extraction phase to ensure accuracy and consistency. Pairs of two reviewers will subsequently extract data independently and review in duplicate.</p><p id=\"p-30\">Reviewers will extract the following data for all included studies: study characteristics (eg, author information, country of origin and study design), patient characteristics (eg, sample size, age and sex of patients, medical history, National Institute of Health Stroke Scale score, the proportion for each vessel involved as well as determined stroke aetiology), characteristics of interventions and comparators (eg, intravenous thrombolytic agent used and respective dose and thrombectomy device used) and treatment outcomes, including mortality, functional independence, successful reperfusion, intracranial haemorrhage (including symptomatic intracranial haemorrhage), and procedural complications and other adverse events. Data will be abstracted into an Excel spreadsheeting using Microsoft Office Excel V.2021. If there are any missing details, we will contact the authors of included studies when applicable.</p><p id=\"p-31\">We conducted a preliminary literature search of the databases, and conclusion of the search suggests that there will be an estimate of six studies eligible for this review.</p><h3>Risk of bias assessment</h3><p id=\"p-32\">Pairs of reviewers will assess the risk of bias of included studies independently and in duplicate using the revised Cochrane Risk-of-Bias V.2 (RoB 2) tool. We will address concerns for low interrater reliability and other expected challenges, such as difficult terminology, by training the reviewers to improve the reliability of RoB 2.<a id=\"xref-ref-46-1\" class=\"xref-bibr\" href=\"#ref-46\">46</a> We will use the following criteria to assess risk of bias: randomisation process, deviations from intended interventions, missing outcome data, measurement of the outcome and selection of the reported result.<a id=\"xref-ref-47-1\" class=\"xref-bibr\" href=\"#ref-47\">47</a> We will resolve any disagreements between reviewers through consensus and/or with the assistance of an adjudicator. Risk of bias for included studies will be illustrated in figures produced by Risk-of-bias Visualization.<a id=\"xref-ref-48-1\" class=\"xref-bibr\" href=\"#ref-48\">48</a></p><h3>Data synthesis</h3><p id=\"p-33\">We will group all outcomes reported by at least two studies for direct comparison. We will standardise the definitions and measurements of each outcome via consensus. We will conduct a meta-analysis of the outcomes of interest when possible using the generic inverse variance method and random effects analysis model via Review Manager V.5.4. We will use Harbord’s test to assess small study effects for binary outcomes and Egger’s test for continuous outcomes when there are at least 10 studies eligible for quantitative assessment.<a id=\"xref-ref-49-1\" class=\"xref-bibr\" href=\"#ref-49\">49</a> When no meta-analysis could be performed due to heterogeneity of the data, we will narratively synthesise the findings. For dichotomous outcomes reported by at least one RCT, we will calculate the relative risk (RR) using the crude event rate and the associated 95% CIs to inform relative effectiveness. We will calculate risk difference based on the RRs from our study and the baseline risks from a well-designed, high-quality multicentre observational study of 6350 patients who had ischaemic stroke.<a id=\"xref-ref-50-1\" class=\"xref-bibr\" href=\"#ref-50\">50</a> For continuous outcomes reported by at least one RCT, we will calculate the weighted mean difference and associated 95% CI. When only median and range values are reported or when SD are not reported, we will use methods outlined in <em>Cochrane Handbook for Systematic Reviews of Interventions</em> and by Wan <em>et al</em> to estimate means and SD.<a id=\"xref-ref-51-1\" class=\"xref-bibr\" href=\"#ref-51\">51 52</a> We will report our synthesised findings as funnel plots to assess for asymmetry per outcome of interest and will also estimate Egger’ test of the intercept to assess for publication bias.<a id=\"xref-ref-53-1\" class=\"xref-bibr\" href=\"#ref-53\">53</a></p><h3>Subgroup analysis</h3><p id=\"p-34\">We will evaluate statistical heterogeneity using inconsistency measures, Cochran’s Q test and I<sup>2</sup>. We will use the following a priori hypotheses to explain heterogeneity between studies: (1) location of vessel involved (eg, anterior circulation or posterior circulation) will show different treatment effects<a id=\"xref-ref-54-1\" class=\"xref-bibr\" href=\"#ref-54\">54</a>; (2) high risk of bias studies will show larger treatment effects; and (3) type of thrombectomy devices used (eg, stent retriever, aspiration, etc). We will perform subgroup analyses irrespective of the heterogeneity estimates as long as there are at least two studies representing each subgroup.</p><h3>Assessing certainty of the evidence</h3><p id=\"p-35\">For each outcome, we will assess the certainty of the evidence (as high, moderate, low or very low) using the GRADE approach and developed GRADE evidence profiles.<a id=\"xref-ref-55-1\" class=\"xref-bibr\" href=\"#ref-55\">55 56</a> We will use previously derived thresholds for the minimally important difference for favourable functional outcome, mortality and symptomatic intracranial hemorrhage (sICH), adapted from Wang and colleagues.<a id=\"xref-ref-57-1\" class=\"xref-bibr\" href=\"#ref-57\">57</a></p><h3>Cost–utility analysis</h3><p id=\"p-36\">We will conduct a model-based cost–utility analysis to determine the cost-effectiveness of EVT alone compared with IVT and EVT for patients with an acute ischaemic stroke secondary to a large vessel occlusion. A Markov decision analytical model with a lifetime horizon will be developed to predict the long-term costs and health outcomes. We will conduct the analysis from a healthcare perspective. We will base the clinical outcome inputs from this systematic review. We will search literature for the long-term clinical outcome inputs. From the healthcare perspective, we will consider both medical costs (ie, costs related to patient care) and non-medical costs (ie, overhead costs such as finance, human resources and administration) that are incurred during treatment. The treatment costs come from the administrative data of the University of Chicago Medical Center. Other cost estimates (ie, health state-related costs) and utility inputs will be based on literature.</p><h3>Patient and public involvement</h3><p id=\"p-37\">Neither patients nor the public was involved in the study.</p><h3>Ethics and dissemination</h3><p id=\"p-38\">This systematic review will not require a research ethics approval because no confidential patient data will be used. We will disseminate our findings by publishing the results in a peer-reviewed journal and via presentation at conferences.</p><h2 class=\"\">Discussion</h2><p id=\"p-39\">EVT has emerged to become a superior treatment modality compared with medical management alone for the treatment of strokes secondary to large vessel occlusions, particularly in the anterior circulation.<a id=\"xref-ref-58-1\" class=\"xref-bibr\" href=\"#ref-58\">58</a> However, controversies in the safety and efficacy of bridging IVT prior to thrombectomy remain to be the subject of debate. A recent subgroup analysis showed that the effect of intravenous alteplase prior to thrombectomy is not significantly associated with the occlusion site<a id=\"xref-ref-59-1\" class=\"xref-bibr\" href=\"#ref-59\">59</a>; however, the trial for which this analysis was based included only occlusions in the internal carotid and M1 or M2 branches of the middle cerebral artery.<a id=\"xref-ref-21-1\" class=\"xref-bibr\" href=\"#ref-21\">21</a> An editorial by Podlasek and colleagues briefly reviewed the combined the trial data from six RCTs and showed that EVT alone is non-inferior to bridging therapy in achieving good functional outcomes at 3 months with a 6% margin of confidence.<a id=\"xref-ref-60-1\" class=\"xref-bibr\" href=\"#ref-60\">60</a> While most guidelines currently recommend IVT prior to thrombectomy,<a id=\"xref-ref-23-2\" class=\"xref-bibr\" href=\"#ref-23\">23–25</a> there is a need for a high-quality review to provide a clinical summary of the efficacy and safety of mechanical thrombectomy alone versus IVT prior to mechanical thrombectomy and to balance those outcomes with cost.</p><p id=\"p-40\">Our study will have many strengths compared with existing reviews in the literature. First, we will compare the efficacy and safety of mechanical thrombectomy alone versus mechanical thrombectomy and bridging thrombolysis in studies that only directly compare the two interventions strategies. Second, we will investigate the effects of treatment across certain conditions. Third, we will apply the RoB 2 tool and GRADE approach to evaluate the risk of bias and certainty of evidence, respectively, for each outcome. Lastly, this study will be the first to use meta-analysed data to robustly perform an economic evaluation comparing the two treatment strategies, integrate clinical outcome inputs from study-level data and treatment cost inputs from administrative data. Some potential limitations will include the following: heterogeneity of outcome definitions and measurement, such as in the case of symptomatic intracranial haemorrhage; cost estimation cannot assess for lifetime cost as there are limited longitudinal data with respect to the treatment strategies. The findings of our study will help inform providers about the role of IVT in mechanical thrombectomy and identify key areas for future research.</p><h2 class=\"\">Ethics statements</h2><h3>Patient consent for publication</h3><p id=\"p-48\" class=\"ethics-consent-to-publish\">Not applicable.</p><h2 class=\"\">References"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython import display\n",
    "def trim_text(text, regex=r'(.*)'):\n",
    "    try:\n",
    "        processed = re.search(regex, text, re.DOTALL).group(1)\n",
    "        html_display = display.HTML(processed)\n",
    "    except: \n",
    "        print('Unable to parse article text')\n",
    "        processed = '<Error parsing article text>' \n",
    "        html_display = processed\n",
    "    return processed, html_display\n",
    "\n",
    "def text_dict_from_web(article_dict, header=2, to_display=0,\n",
    "        regex_str='.*<h\\d>Abstract</h\\d>.*(?:Introduction)?.*(<h\\d.*?>Introduction</h\\d>.*References)<.*'\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Create a text dictionary from a dictionary containing web-scraped articles.\n",
    "\n",
    "    Parameters:\n",
    "        article_dict (dict): Values of each dictionary item are a dictionary representing the data from a \n",
    "            single article: 'url', 'text', and 'title'.\n",
    "\n",
    "    Returns:\n",
    "        text_dict: Dictionary where each item is a string of the text of an article, starting with the title.\n",
    "    \"\"\"\n",
    "    regex_str = regex_str.replace('\\d', f'{header}')\n",
    "    regex = rf'{regex_str}'\n",
    "    print(f'Regex pattern: {regex}')\n",
    "    text_dict = dict()\n",
    "    display_dict = dict()\n",
    "    if type(to_display) != list:\n",
    "        to_display = [to_display] \n",
    "    for article_key in article_dict:\n",
    "        trimmed_text, display = trim_text(article_dict[article_key]['text'], regex)\n",
    "        text_dict[article_key] = f\"{article_dict[article_key]['title']}\\n\\n{trimmed_text}\"\n",
    "        if article_key in to_display:\n",
    "            display_dict[article_key] = display\n",
    "    print(f'text_dict keys: {[key for key in text_dict.keys()]}')\n",
    "    return text_dict, display_dict\n",
    "    \n",
    "\n",
    "text_id = 2\n",
    "header = 2\n",
    "texts[text_id], display_dict = text_dict_from_web(article_dict, to_display=0, header=header)\n",
    "display_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for running summary_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "chain_results_dict = dict()\n",
    "qna_dict = dict()\n",
    "texts = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and result statistics to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, \\\n",
    "    such as age and sex, within the body of the summary. \\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing or redundant. \\\n",
    "    \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same. \\\n",
    "    \\nCreate an intriguing headline to hook the audience.\\\n",
    "    \\nReturn your response in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\nwhere the summary is a publication-ready format.\\\n",
    "    \\nDo not label the headline and summary.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "user_simplify_task = [\n",
    "    \"\"\"If needed, rewrite the headline and text using terms appropriate for the audience. If not keep it the same.\\\n",
    "    Follow these steps to accomplish this: \\\n",
    "    \\n1. Check if the content and language are appropriate for the audience. \\\n",
    "    \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "    \\n3. Return the final version of the headline and text to be shown to the audience. \\\n",
    "    \\nIt should be in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\n\\nwhere the summary is in paragraph form.\\\n",
    "    \\n4. Remove the backticks. Do not label the headline and summary. \",\n",
    "    \\n\\nYour audience is\"\"\",\n",
    "]\n",
    "\n",
    "simplify_audience = [\n",
    "    # \"a lay audience\",\n",
    "    \"people who are not science experts\",\n",
    "]\n",
    "\n",
    "user_relevance_task = [\n",
    "    \"\"\"Rewrite the headline and text to include a statement of how it is relevant for the audience. \\\n",
    "    Follow these steps to accomplish this: \\\n",
    "    \\n1. Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things, \\\n",
    "    add a sentence to inform the audience. Otherwise, keep it the same. \\\n",
    "    Avoid making claims that are not supported by science.\\\n",
    "    \\n3. Modify the content if needed to reduce redundancy. \\\n",
    "    \\n4. Check if the content and language are appropriate for the audience. \\\n",
    "    If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "    \\n5. Return the final version of the headline and text to be shown to the audience. \\\n",
    "    \\nIt should be in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\n\\nwhere the summary is in paragraph form.\\\n",
    "    \\n6. Remove the backticks. Do not label the headline and summary. \",\n",
    "    \\n\\nYour audience consists of\"\"\",\n",
    "]\n",
    "\n",
    "relevance_audience = [\n",
    "    \"seniors\",\n",
    "    # \"people who enjoy sports\",\n",
    "    # \"people new to resistance training\",\n",
    "    \"people starting an exercise program\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #0 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 145 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\summary_chain.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 55181 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #1 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 145 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\summary_chain.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 53495 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing text0_prompt00...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m\n",
      "\u001b[0;32m     14\u001b[0m \u001b[39m# Create initial summaries\u001b[39;00m\n",
      "\u001b[0;32m     15\u001b[0m chaining_dict \u001b[39m=\u001b[39m batch_summarize_chain(\n",
      "\u001b[0;32m     16\u001b[0m     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
      "\u001b[0;32m     17\u001b[0m     system_role\u001b[39m=\u001b[39msystem_role, model\u001b[39m=\u001b[39mmodel, max_tokens\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n",
      "\u001b[0;32m     18\u001b[0m     n_choices\u001b[39m=\u001b[39mn_choices, pause_per_request\u001b[39m=\u001b[39mpause_per_request,\n",
      "\u001b[0;32m     19\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n",
      "\u001b[0;32m     20\u001b[0m     )\n",
      "\u001b[1;32m---> 21\u001b[0m qna_dict \u001b[39m=\u001b[39m spreadsheet_columns(\n",
      "\u001b[0;32m     22\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id, save\u001b[39m=\u001b[39;49msave\n",
      "\u001b[0;32m     23\u001b[0m     )\n",
      "\u001b[0;32m     25\u001b[0m \u001b[39m# # Create simple summaries\u001b[39;00m\n",
      "\u001b[0;32m     26\u001b[0m \u001b[39m# audience = simplify_audience\u001b[39;00m\n",
      "\u001b[0;32m     27\u001b[0m \u001b[39m# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m \u001b[39m# )\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[39m# print(f'\\nCompleted merge_all_chaining_results!:)')\u001b[39;00m\n",
      "\u001b[0;32m     65\u001b[0m qna_dict[iteration_id]\n",
      "\n",
      "File \u001b[1;32m~\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\response_processing.py:165\u001b[0m, in \u001b[0;36mspreadsheet_columns\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id, save, filename, path)\u001b[0m\n",
      "\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspreadsheet_columns\u001b[39m(qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n",
      "\u001b[0;32m    160\u001b[0m     save\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;32m    161\u001b[0m     ):\n",
      "\u001b[0;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    163\u001b[0m \u001b[39m    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\u001b[39;00m\n",
      "\u001b[0;32m    164\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 165\u001b[0m     qna_dict \u001b[39m=\u001b[39m create_qna_df(\n",
      "\u001b[0;32m    166\u001b[0m         qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id, \n",
      "\u001b[0;32m    167\u001b[0m         )\n",
      "\u001b[0;32m    168\u001b[0m     qna_dict[iteration_id][\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m qna_dict[iteration_id][\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;32m    169\u001b[0m     spreadsheet_columns \u001b[39m=\u001b[39m [letter \u001b[39mfor\u001b[39;00m letter \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mascii_uppercase]\u001b[39m+\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mletter \u001b[39mfor\u001b[39;00m letter \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mascii_uppercase]\n",
      "\n",
      "File \u001b[1;32m~\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\response_processing.py:143\u001b[0m, in \u001b[0;36mcreate_qna_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n",
      "\u001b[0;32m    139\u001b[0m \u001b[39mfor\u001b[39;00m chatbot_key \u001b[39min\u001b[39;00m chatbot_dict[chatbot_id]\u001b[39m.\u001b[39mkeys():\n",
      "\u001b[0;32m    140\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mchatbot_key\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;32m    141\u001b[0m     dfs_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mDataFrame(\n",
      "\u001b[0;32m    142\u001b[0m         chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna, \n",
      "\u001b[1;32m--> 143\u001b[0m         index\u001b[39m=\u001b[39m[choice \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39;49mqna[\u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n",
      "\u001b[0;32m    144\u001b[0m         )\n",
      "\u001b[0;32m    146\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;32m    147\u001b[0m columns \u001b[39m=\u001b[39m qna_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "\n",
      "\u001b[1;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "# chatbot_id = 0\n",
    "save_outputs = False\n",
    "save = True\n",
    "# save = False\n",
    "empty_columns = True\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "text_dict = main_text[text_id]\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Merge the results\n",
    "# try:\n",
    "#     qna_dict = merge_all_chaining_results(\n",
    "#         chatbot_dict, qna_dict, iteration_id=iteration_id, relevance_audiences=2, pivot=True,\n",
    "#         empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         save_df=save, save_chatbot=save, \n",
    "#             csv_path=folder_path,\n",
    "#     )\n",
    "#     print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "# except Exception as error:\n",
    "#     exc_type, exc_obj, tb = sys.exc_info()\n",
    "#     f = tb.tb_frame\n",
    "#     lineno = tb.tb_lineno\n",
    "#     file = f.f_code.co_filename\n",
    "#     print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "#     print('Unable to merge results')\n",
    "#     if save:\n",
    "#         save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "#         print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "\n",
    "# qna_dict = merge_all_chaining_results2(\n",
    "#     chatbot_dict, qna_dict, iteration_id=iteration_id, relevance_audiences=2, pivot=True,\n",
    "#     empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         csv_path=folder_path,\n",
    "# )\n",
    "# print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
