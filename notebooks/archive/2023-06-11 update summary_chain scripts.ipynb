{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "import time\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "\n",
    "from response_processing import *\n",
    "from article_processing import create_text_dict_from_folder\n",
    "import traceback\n",
    "from file_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wrangling import filter_df_all_conditions, filter_df_any_condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        system_role=\"You are an expert at science communication.\"):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            self.summaries_dict['prep_step'] = prep_step\n",
    "            self.summaries_dict['task'] = task\n",
    "            self.summaries_dict['prompt'] = full_task\n",
    "            return self.qna\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "            return self.qna\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, qna_dict, chaining_bot_dict, iteration_id, \n",
    "    temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna_dict: dict\n",
    "            A dictionary containing the results of the summarization process. The keys of the dictionary are the iteration IDs and the values are pandas dataframes containing the summaries for each text ID\n",
    "\n",
    "    \"\"\"\n",
    "    temp_qna_dict = dict()\n",
    "    qna_dfs_list = []\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task), \n",
    "        columns=['prep_step', 'summarize_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        temp_qna_dict[key] = dict()\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                temp_qna_dict[key][index] = chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            updated_qna_dict = (temp_qna_dict[key])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('Error concatenating prompts DataFrame')\n",
    "            return temp_qna_dict, chaining_bot_dict\n",
    "        qna_dfs_list.append(updated_qna_dict)\n",
    "    try:\n",
    "        qna_dict[iteration_id] = pd.concat([\n",
    "            pd.DataFrame(\n",
    "                data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "            ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "        ])\n",
    "        qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "        print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "        if save_outputs:\n",
    "            try:\n",
    "                save_output(\n",
    "                    qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "                    csv_path=csv_path, pickle_path=pickle_path)\n",
    "                save_instance_to_dict(\n",
    "                    chaining_bot_dict[iteration_id], \n",
    "                    description=f'batch_Chaining_attributes',\n",
    "                    pickle_path=pickle_path, json_path=json_path\n",
    "                    )\n",
    "            except:\n",
    "                print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        qna_dict[iteration_id] = qna_dfs_list\n",
    "        print('Error creating DataFrame; dictionary returned instead')\n",
    "    return qna_dict, chaining_bot_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a headline to hook the audience.\\\n",
    "    \\nReturn your response as the headline followed by the final version of the summary, \\\n",
    "    separated by a blank line.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create text dictionary\n",
    "folder_path = '../text/2023-06-11' # ** UPDATE REQUIRED**\n",
    "\n",
    "encoding='ISO-8859-1'\n",
    "subset=None\n",
    "\n",
    "text_dict = create_text_dict_from_folder(folder_path, encoding=encoding, subset=subset)\n",
    "\n",
    "\n",
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "chain_results_dict = dict()\n",
    "qna_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 2: 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-focused health promotion policies. These policies assume that individuals can improve their health by losing weight, employing weight stigma as one strategy for motivating behavior change [5]. However, our findings indicate that weight stigma is associated with poorer health behaviors, independent of BMI. Given that physical health and weight are largely shaped by factors outside of an individual\\x92s control (i.e., genetics and social determinants like socioeconomic status) [5], it is concerning that multiple behaviors, for which individuals have some control over, may be undermined by weight stigma.\\nFurthermore, a lower BMI may not necessarily be protective against weight stigma. In our sample, individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. In fact, moderation analyses indicated that individuals with\\xa0lower\\xa0BMIs showed greater disordered eating and alcohol use in the face of weight stigma. These results emerged despite individuals with higher weight reporting greater daily weight stigma. One explanation for the observed differences in health behavioral outcomes across the weight spectrum is that infrequent health behaviors may be less likely to be enacted as coping strategies. For instance, previous research has shown that alcohol use decreases as BMI increases among females with higher weight [44]. Thus, using food, instead of alcohol, may be the more common coping strategy among individuals with higher BMIs, as previous research suggests [45]. Nonetheless, the sizes of the moderation effects were very small, with some confidence intervals functionally at zero, and thus further interpretation of the present findings should only be done with caution.\\nPrior research has found conflicting evidence for the relationship between weight stigma and physical activity. Some studies have found that greater weight stigma is associated with short-term increases in reported exercise behavior [16,\\xa046]. Others have shown that weight stigma is positively correlated with increased exercise avoidance, but has no direct link to self-reported exercise [14,\\xa047]. The current study adds to the latter base of evidence showing no relationship between weight stigma and physical activity. One possible explanation is that participants were asked about their daily experiences with weight stigma, which may not correspond to their level of physical activity over the past month. Ecological momentary assessment methodology may provide better insight into this relationship, as demonstrated by Vartanian et al. who examined health motivations following stigmatizing events in daily life [48].\\nDespite emerging evidence that weight stigma is prevalent among men [28], there is a lack of research on men\\x92s health outcomes related to weight stigma. In this study, moderation by gender was not observed for any outcome. These results are consistent with previous research reporting no gender differences in poor health outcomes such as mortality and obesity due to weight stigma [3,\\xa049]. Men may also feel pressured to meet societal body standards and thus may display the same magnitude of associations between weight stigma and health behaviors. It is recommended that the null gender findings are interpreted with caution, as more research is needed.\\nHow might weight stigma influence an individual\\x92s health behaviors? One potential mechanism is stress. Previous work suggests that weight stigma is stressful [6,\\xa050] and experimental lab studies manipulating weight stigma have shown that individuals with higher weight, as well as those who perceive themselves as overweight, show elevated levels of the stress hormone cortisol following exposure to a weight-stigmatizing event [51,\\xa052]. Additionally, some research has found that individuals who experience more weight-based discrimination have higher hair cortisol levels\\x97a finding most pronounced in those at the highest BMI [53]. Individuals who experience greater stress may engage in more unhealthy coping behaviors. Indeed, stress can drive changes in behaviors such as eating, physical activity, and sleep [54]. For example, Tataranni et al. administered synthetic cortisol vs. placebo and found greater food consumption in the cortisol group [55]. This early work is supported by accumulating evidence that cortisol is associated with increased caloric intake and greater abdominal fat storage [56]. The health behavior pathway may not be independent from that of stress but rather reflect a serial mediation model, wherein weight stigma increases stress that in turn causes decrements in health behaviors.\\nThe present study contributes to the weight stigma literature in several ways. As noted, a key strength of this study is the assessment of several health behaviors within a large, national census-matched sample. Previous studies that have examined weight stigma in relation to different health behaviors have often had small sample sizes or were limited to female subjects. Thus, the present study may provide more generalizable information about health behaviors in the U.S. A related strength of the study is that higher BMI scores were well-represented in the sample, with 31.4% meeting BMI criteria for obesity. This is a closer estimate of the proportion of the American population that is classified with obesity (42%) compared to previous studies [57]. Therefore, there is greater confidence that these findings reflect the experiences of individuals with obesity in the population, aiding generalizability. Lastly, we enhance reproducibility by presenting a two-stage research program of exploratory and confirmatory analyses based on recommended open science practices.\\nThere are some limitations to consider. First, a composite weight stigma score was used due to survey constraints. While early tests indicate good construct validity, additional psychometric testing is warranted (see Online Supplementary Materials\\xa04). Another limitation is the use of self-reported weight, which is subject to inaccuracies. Additionally, the data collection period overlapped with winter holidays. Individuals may have made new year\\x92s health resolutions, and therefore the self-reported health behaviors may be more indicative of newly established goals rather than typical health habits. However, such resolutions would likely dampen, rather than magnify, the relationship between weight stigma and poor health behaviors. Lastly, the study is cross-sectional and therefore causal direction cannot be determined. Weight stigma may operate as a feedback loop that leads to weight gain through certain behaviors such as comfort eating [6], but further investigation is required. Given survey constraints, weight bias internalization was not assessed. Future research should build on these findings to determine the potential role of weight bias internalization in these health behaviors.\\nDespite these limitations, these study\\x92s findings show that weight stigma is significantly associated with several health behaviors. If future research confirms that this is indeed a causal relationship, weight stigma could cumulatively undermine physical health over time. Taken together, these findings highlight weight stigma as a potential barrier to healthy behaviors, and suggest that one strategy to improve population health may be to reduce weight stigma. Though more research is needed, it may be important to employ more weight-inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].\\n\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(text_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Update messages and class attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        # try:\n",
    "        #     response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        # except Exception as error:\n",
    "        #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "        #     f = tb.tb_frame\n",
    "        #     lineno = tb.tb_lineno\n",
    "        #     filename = f.f_code.co_filename\n",
    "        #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        #     print('\\t**API request failed for `.summarize()`**')\n",
    "        #     return self.qna\n",
    "        # try:\n",
    "        #     for index, choice in enumerate(response.choices):\n",
    "        #         self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "        #     self.qna.setdefault('summary', [])\n",
    "        #     self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        #     self.summaries_dict['prep_step'] = prep_step\n",
    "        #     self.summaries_dict['task'] = task\n",
    "        #     self.summaries_dict['prompt'] = full_task\n",
    "        #     return self.qna\n",
    "        # except Exception as error:\n",
    "        #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "        #     f = tb.tb_frame\n",
    "        #     lineno = tb.tb_lineno\n",
    "        #     filename = f.f_code.co_filename\n",
    "        #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        #     print('\\t**Error with response parsing**')\n",
    "        #     return self.qna\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna_dict: dict\n",
    "            A dictionary containing the results of the summarization process. The keys of the dictionary are the iteration IDs and the values are pandas dataframes containing the summaries for each text ID\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "    #     try:\n",
    "    #         updated_qna_dict = (temp_qna_dict[key])\n",
    "    #     except Exception as error:\n",
    "    #         exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #         f = tb.tb_frame\n",
    "    #         lineno = tb.tb_lineno\n",
    "    #         filename = f.f_code.co_filename\n",
    "    #         print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #         print('Error concatenating prompts DataFrame')\n",
    "    #         return temp_qna_dict, chaining_bot_dict\n",
    "    #     qna_dfs_list.append(updated_qna_dict)\n",
    "    # try:\n",
    "    #     qna_dict[iteration_id] = pd.concat([\n",
    "    #         pd.DataFrame(\n",
    "    #             data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "    #         ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "    #     ])\n",
    "    #     qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "    #     print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "    #     if save_outputs:\n",
    "    #         try:\n",
    "    #             save_output(\n",
    "    #                 qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "    #                 csv_path=csv_path, pickle_path=pickle_path)\n",
    "    #             save_instance_to_dict(\n",
    "    #                 chaining_bot_dict[iteration_id], \n",
    "    #                 description=f'batch_Chaining_attributes',\n",
    "    #                 pickle_path=pickle_path, json_path=json_path\n",
    "    #                 )\n",
    "    #         except:\n",
    "    #             print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    # except Exception as error:\n",
    "    #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #     f = tb.tb_frame\n",
    "    #     lineno = tb.tb_lineno\n",
    "    #     filename = f.f_code.co_filename\n",
    "    #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #     qna_dict[iteration_id] = qna_dfs_list\n",
    "    #     print('Error creating DataFrame; dictionary returned instead')\n",
    "    # return qna_dict, chaining_bot_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <__main__.Chaining at 0x198fa2e0d90>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x198fa2e1450>}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       " 'summarization task': 'summarize for a LinkedIn post.',\n",
       " 'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       " 'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict[1]['text1_prompt00'].qna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "Identify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \n",
      "Based on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \n",
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     separated by a blank line.\n"
     ]
    }
   ],
   "source": [
    "print(chaining_dict[1]['text1_prompt00'].qna['full summarization task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a helpful assistant.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.'},\n",
       " 'summaries_dict': {},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {},\n",
       " 'relevance_dict': {},\n",
       " 'n_previous_prompts': {}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(chaining_dict[1]['text1_prompt00'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Send to ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna_dict: dict\n",
    "            A dictionary containing the results of the summarization process. The keys of the dictionary are the iteration IDs and the values are pandas dataframes containing the summaries for each text ID\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "    #     try:\n",
    "    #         updated_qna_dict = (temp_qna_dict[key])\n",
    "    #     except Exception as error:\n",
    "    #         exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #         f = tb.tb_frame\n",
    "    #         lineno = tb.tb_lineno\n",
    "    #         filename = f.f_code.co_filename\n",
    "    #         print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #         print('Error concatenating prompts DataFrame')\n",
    "    #         return temp_qna_dict, chaining_bot_dict\n",
    "    #     qna_dfs_list.append(updated_qna_dict)\n",
    "    # try:\n",
    "    #     qna_dict[iteration_id] = pd.concat([\n",
    "    #         pd.DataFrame(\n",
    "    #             data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "    #         ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "    #     ])\n",
    "    #     qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "    #     print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "    #     if save_outputs:\n",
    "    #         try:\n",
    "    #             save_output(\n",
    "    #                 qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "    #                 csv_path=csv_path, pickle_path=pickle_path)\n",
    "    #             save_instance_to_dict(\n",
    "    #                 chaining_bot_dict[iteration_id], \n",
    "    #                 description=f'batch_Chaining_attributes',\n",
    "    #                 pickle_path=pickle_path, json_path=json_path\n",
    "    #                 )\n",
    "    #         except:\n",
    "    #             print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    # except Exception as error:\n",
    "    #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #     f = tb.tb_frame\n",
    "    #     lineno = tb.tb_lineno\n",
    "    #     filename = f.f_code.co_filename\n",
    "    #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #     qna_dict[iteration_id] = qna_dfs_list\n",
    "    #     print('Error creating DataFrame; dictionary returned instead')\n",
    "    # return qna_dict, chaining_bot_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <__main__.Chaining at 0x22979a07b90>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x229799d4250>}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text1_prompt00'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(chaining_dict[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Chaining at 0x22979a07b90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict[1][next(iter(chaining_dict[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a helpful assistant.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       "  'summary': ['High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       "   'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.']},\n",
       " 'summaries_dict': {'response_01': 'High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       "  'response_02': 'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {},\n",
       " 'relevance_dict': {},\n",
       " 'n_previous_prompts': {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(chaining_dict[1][next(iter(chaining_dict[1]))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sample_Chaining_attr` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def sample_Chaining_attr(chaining_dict=chaining_dict, iteration_id=iteration_id):\n",
    "    return (vars(chaining_dict[iteration_id][next(iter(chaining_dict[iteration_id]))]))\n",
    "\n",
    "# sample_Chaining_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_01': 'High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       " 'response_02': 'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr()['summaries_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       " 'summarization task': 'summarize for a LinkedIn post.',\n",
       " 'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       " 'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       " 'summary': ['High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       "  'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr()['qna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "Identify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \n",
      "Based on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \n",
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     separated by a blank line.\n"
     ]
    }
   ],
   "source": [
    "print(sample_Chaining_attr()['qna']['full summarization task'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Create summaries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    iteration_id = chatbot_id if chatbot_id != None else iteration_id\n",
    "    for chatbot_key in chatbot_dict[iteration_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(chatbot_dict[iteration_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "    \n",
    "    return dfs_list\n",
    "    qna_df = pd.concat(dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df\n",
    "    return qna_dict\n",
    "\n",
    "    #     try:\n",
    "    #         updated_qna_dict = (temp_qna_dict[key])\n",
    "    #     except Exception as error:\n",
    "    #         exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #         f = tb.tb_frame\n",
    "    #         lineno = tb.tb_lineno\n",
    "    #         filename = f.f_code.co_filename\n",
    "    #         print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #         print('Error concatenating prompts DataFrame')\n",
    "    #         return temp_qna_dict, chaining_bot_dict\n",
    "    #     qna_dfs_list.append(updated_qna_dict)\n",
    "    # try:\n",
    "    #     qna_dict[iteration_id] = pd.concat([\n",
    "    #         pd.DataFrame(\n",
    "    #             data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "    #         ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "    #     ])\n",
    "    #     qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "    #     print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "    #     if save_outputs:\n",
    "    #         try:\n",
    "    #             save_output(\n",
    "    #                 qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "    #                 csv_path=csv_path, pickle_path=pickle_path)\n",
    "    #             save_instance_to_dict(\n",
    "    #                 chaining_bot_dict[iteration_id], \n",
    "    #                 description=f'batch_Chaining_attributes',\n",
    "    #                 pickle_path=pickle_path, json_path=json_path\n",
    "    #                 )\n",
    "    #         except:\n",
    "    #             print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    # except Exception as error:\n",
    "    #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #     f = tb.tb_frame\n",
    "    #     lineno = tb.tb_lineno\n",
    "    #     filename = f.f_code.co_filename\n",
    "    #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #     qna_dict[iteration_id] = qna_dfs_list\n",
    "    #     print('Error creating DataFrame; dictionary returned instead')\n",
    "    # return qna_dict, chaining_bot_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id\n",
    "#     )\n",
    "\n",
    "qna_dict = dict()\n",
    "qna_dict = create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <__main__.Chaining at 0x22979a07b90>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x229799d4250>}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   choice  \\\n",
       " 0       0   \n",
       " 1       1   \n",
       " \n",
       "                                                                                          article_title  \\\n",
       " 0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " 1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " \n",
       "                     system_role          model  \\\n",
       " 0  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " 1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " \n",
       "                                                                                                   text  \\\n",
       " 0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " 1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " \n",
       "                                                                                              prep step  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                summarization task  \\\n",
       " 0  summarize for a LinkedIn post.   \n",
       " 1  summarize for a LinkedIn post.   \n",
       " \n",
       "                                                                                              edit task  \\\n",
       " 0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " 1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " \n",
       "                                                                                full summarization task  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                                                                                                summary  \n",
       " 0  High calcium and high protein dairy foods may reduce risk of fractures and falls in institutiona...  \n",
       " 1  High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA...  ,\n",
       "    choice  \\\n",
       " 0       0   \n",
       " 1       1   \n",
       " \n",
       "                                                                                          article_title  \\\n",
       " 0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " 1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " \n",
       "                     system_role          model  \\\n",
       " 0  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " 1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " \n",
       "                                                                                                   text  \\\n",
       " 0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " 1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " \n",
       "                                                                                              prep step  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                summarization task  \\\n",
       " 0  summarize for a LinkedIn post.   \n",
       " 1  summarize for a LinkedIn post.   \n",
       " \n",
       "                                                                                              edit task  \\\n",
       " 0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " 1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " \n",
       "                                                                                full summarization task  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                                                                                                summary  \n",
       " 0  Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...  \n",
       " 1  Weight stigma may undermine healthy behaviors, according to a study in the International Journal...  ]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>article_title</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>edit task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight stigma may undermine healthy behaviors, according to a study in the International Journal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   choice  \\\n",
       "0       0   \n",
       "1       1   \n",
       "\n",
       "                                                                                         article_title  \\\n",
       "0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                    system_role          model  \\\n",
       "0  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                                                                                             prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "               summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit task  \\\n",
       "0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "\n",
       "                                                                               full summarization task  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                               summary  \n",
       "0  Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...  \n",
       "1  Weight stigma may undermine healthy behaviors, according to a study in the International Journal...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 9)\n",
      "Original summaries Dataframe columns: Index(['article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>edit task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>High calcium and high protein dairy foods may reduce risk of fractures and falls in institutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight stigma may undermine healthy behaviors, according to a study in the International Journal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         article_title  \\\n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                    system_role          model  \\\n",
       "1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                                                                                             prep step  \\\n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "               summarization task  \\\n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit task  \\\n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "2  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "2  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "\n",
       "                                                                               full summarization task  \\\n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                               summary  \n",
       "1  High calcium and high protein dairy foods may reduce risk of fractures and falls in institutiona...  \n",
       "2  High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA...  \n",
       "1  Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...  \n",
       "2  Weight stigma may undermine healthy behaviors, according to a study in the International Journal...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.13\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id\n",
    "#     )\n",
    "\n",
    "chatbot_id = 1\n",
    "qna_dict = dict()\n",
    "qna_dict = create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 save the API response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 9)\n",
      "Original summaries Dataframe columns: Index(['article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>edit task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Nutritional approach reduces fractures and fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poor H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  \\\n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Effect of dietary sources of calcium and prote...   \n",
       "1  Weight stigma and health behaviors: evidence f...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                         system_role          model  \\\n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                                text  \\\n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Effect of dietary sources of calcium and prote...   \n",
       "1  Weight stigma and health behaviors: evidence f...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                           prep step  \\\n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "\n",
       "               summarization task  \\\n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit task  \\\n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "\n",
       "                             full summarization task  \\\n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "\n",
       "                                             summary  \n",
       "1  Nutritional approach reduces fractures and fal...  \n",
       "2  High calcium and high protein dairy foods may ...  \n",
       "1  Headline: Weight Stigma Linked to Poor Health ...  \n",
       "2  Headline: Weight Stigma Associated with Poor H...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description='batch_Chaining_responses',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.14\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1\n",
    "qna_dict = create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.14: {'text1_prompt00': <__main__.Chaining at 0x17bd1300590>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x17bce185ad0>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_responses_2023-06-12_1100.sav\n",
      "Time completed: 2023-06-12 11:00:13.074088\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_responses_2023-06-12_1100.json\n"
     ]
    }
   ],
   "source": [
    "save_outputs = True\n",
    "pickle_path=folder_path\n",
    "json_path=folder_path\n",
    "if save_outputs:\n",
    "    try:\n",
    "        save_instance_to_dict(\n",
    "            chaining_dict[iteration_id], \n",
    "            description=f'batch_Chaining_responses',\n",
    "            pickle_path=pickle_path, json_path=json_path\n",
    "            )\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        file = f.f_code.co_filename\n",
    "        print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "        print('[prompt_chaining_dict()] Unable to save outputs')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 10)\n",
      "Original summaries Dataframe columns: Index(['choice', 'article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.sav\n",
      "Time completed: 2023-06-12 11:39:43.138043\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.csv\n",
      "Time completed: 2023-06-12 11:39:43.176313\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B: article_title</th>\n",
       "      <th>C: choice</th>\n",
       "      <th>D: system_role</th>\n",
       "      <th>E: model</th>\n",
       "      <th>F: text</th>\n",
       "      <th>G: prep step</th>\n",
       "      <th>H: summarization task</th>\n",
       "      <th>I: edit task</th>\n",
       "      <th>J: full summarization task</th>\n",
       "      <th>K: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Nutritional approach reduces fractures and fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poor H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    B: article_title  C: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      D: system_role       E: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             F: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        G: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            H: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        I: edit task  \\\n",
       "0  \\nIf applicable, include a brief description o...   \n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "3  \\nIf applicable, include a brief description o...   \n",
       "\n",
       "                          J: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          K: summary  \n",
       "0  Nutritional approach reduces fractures and fal...  \n",
       "1  High calcium and high protein dairy foods may ...  \n",
       "2  Headline: Weight Stigma Linked to Poor Health ...  \n",
       "3  Headline: Weight Stigma Associated with Poor H...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.15\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=True\n",
    "#     )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "chatbot_id = 1.14\n",
    "save = True\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    If applicable, include a brief description of ...\n",
      "1    If applicable, include a brief description of ...\n",
      "2    If applicable, include a brief description of ...\n",
      "3    If applicable, include a brief description of ...\n",
      "Name: I: edit task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(qna_dict[iteration_id]['I: edit task'].str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     separated by a blank line.\n"
     ]
    }
   ],
   "source": [
    "print(qna_dict[iteration_id].loc[0, 'I: edit task'].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 10)\n",
      "Original summaries Dataframe columns: Index(['choice', 'article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.sav\n",
      "Time completed: 2023-06-12 11:39:43.138043\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.csv\n",
      "Time completed: 2023-06-12 11:39:43.176313\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B: article_title</th>\n",
       "      <th>C: choice</th>\n",
       "      <th>D: system_role</th>\n",
       "      <th>E: model</th>\n",
       "      <th>F: text</th>\n",
       "      <th>G: prep step</th>\n",
       "      <th>H: summarization task</th>\n",
       "      <th>I: edit task</th>\n",
       "      <th>J: full summarization task</th>\n",
       "      <th>K: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Nutritional approach reduces fractures and fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poor H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    B: article_title  C: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      D: system_role       E: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             F: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        G: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            H: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        I: edit task  \\\n",
       "0  \\nIf applicable, include a brief description o...   \n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "3  \\nIf applicable, include a brief description o...   \n",
       "\n",
       "                          J: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          K: summary  \n",
       "0  Nutritional approach reduces fractures and fal...  \n",
       "1  High calcium and high protein dairy foods may ...  \n",
       "2  Headline: Weight Stigma Linked to Poor Health ...  \n",
       "3  Headline: Weight Stigma Associated with Poor H...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.15\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=True\n",
    "#     )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "chatbot_id = 1.14\n",
    "save = True\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response as the headline followed by the final version of the summary, \\\n",
    "    where the summary is in paragraph form.\\\n",
    "    \\nDo not label the headline and summary, but separate them by a blank line.\\\n",
    "    \\nDo not include a list of the key concepts as they should already be in the summary.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 new prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_attributes_initial_2023-06-12_1308.sav\n",
      "Time completed: 2023-06-12 13:08:58.970939\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1308.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.2\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save = True\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=True\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "# chatbot_id = 1.14\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1_prompt00': <__main__.Chaining at 0x17bd1aeb590>,\n",
       " 'text2_prompt00': <__main__.Chaining at 0x17bce736f50>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a journalist writing content based on science research articles.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form.    \\nDo not label the headline and summary, but separate them by a blank line.    \\nDo not include a list of the key concepts as they should already be in the summary.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form.    \\nDo not label the headline and summary, but separate them by a blank line.    \\nDo not include a list of the key concepts as they should already be in the summary.',\n",
       "  'summary': ['High calcium and protein dairy foods reduce risk of hip fractures and falls in older adults, according to a recent study. The study found that this nutritional approach resulted in a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The study targeted institutionalized older adults replete in vitamin D, in whom low calcium and protein intakes were common and were likely to contribute to the already high fracture burden in this community. The study used high calcium and protein dairy foods to increase calcium and protein intakes. The study found no group difference in all-cause mortality.',\n",
       "   'High calcium and high protein dairy foods may reduce the risk of fractures and falls in institutionalized older adults, according to a cluster randomized controlled trial. The study found a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls. This nutritional approach may benefit the community by reducing the burden of fractures among those with a small attributable risk to the individual. Compliance was optimized by supervised provision and consumption of the foods, and the cohort was intentionally targeted at high risk for fracture. Participants consumed 1-1.5 g/kg/day of protein to prevent protein catabolism and preserve or increase muscle mass. The study used fermented and non-fermented dairy foods, and milk consumption did not differ between the intervention and control groups.']},\n",
       " 'summaries_dict': {'response_01': 'High calcium and protein dairy foods reduce risk of hip fractures and falls in older adults, according to a recent study. The study found that this nutritional approach resulted in a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The study targeted institutionalized older adults replete in vitamin D, in whom low calcium and protein intakes were common and were likely to contribute to the already high fracture burden in this community. The study used high calcium and protein dairy foods to increase calcium and protein intakes. The study found no group difference in all-cause mortality.',\n",
       "  'response_02': 'High calcium and high protein dairy foods may reduce the risk of fractures and falls in institutionalized older adults, according to a cluster randomized controlled trial. The study found a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls. This nutritional approach may benefit the community by reducing the burden of fractures among those with a small attributable risk to the individual. Compliance was optimized by supervised provision and consumption of the foods, and the cohort was intentionally targeted at high risk for fracture. Participants consumed 1-1.5 g/kg/day of protein to prevent protein catabolism and preserve or increase muscle mass. The study used fermented and non-fermented dairy foods, and milk consumption did not differ between the intervention and control groups.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {},\n",
       " 'relevance_dict': {},\n",
       " 'n_previous_prompts': {}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time completed: 2023-06-12 15:03:56.926896\n",
      "Dictionary keys: ['text1_prompt00', 'text2_prompt00']\n",
      "Article title: Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 0\n",
      "\t\t\tAdded relevance: 0\n",
      "Article title: Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 0\n",
      "\t\t\tAdded relevance: 0\n",
      "\n",
      "\n",
      "New chatbot dict keys: ['text1_prompt00', 'text2_prompt00']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'batch_Chaining_attributes_initial_2023-06-12_1308.sav'\n",
    "\n",
    "loaded_pickle = loadpickle(filename, folder_path)\n",
    "chatbot_dict[1.2] = revive_chatbot_dict(loaded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text1_prompt00', 'text2_prompt00'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict[1.2].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.21 strip white space; format CSV for easier copy/paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 11)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task', 'summary',\n",
      "       'date'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1504.sav\n",
      "Time completed: 2023-06-12 15:04:05.725110\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1504.csv\n",
      "Time completed: 2023-06-12 15:04:05.735947\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: article_title</th>\n",
       "      <th>C: choice</th>\n",
       "      <th>D: system_role</th>\n",
       "      <th>E: model</th>\n",
       "      <th>F: text</th>\n",
       "      <th>G: prep step</th>\n",
       "      <th>H: summarization task</th>\n",
       "      <th>I: edit task</th>\n",
       "      <th>J: full summarization task</th>\n",
       "      <th>K: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and protein dairy foods reduce ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight stigma is associated with disordered ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight stigma is associated with poorer health...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A: date                                   B: article_title  C: choice  \\\n",
       "0  2023-06-12  Effect of dietary sources of calcium and prote...          1   \n",
       "1  2023-06-12  Effect of dietary sources of calcium and prote...          2   \n",
       "2  2023-06-12  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  2023-06-12  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      D: system_role       E: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             F: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        G: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            H: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        I: edit task  \\\n",
       "0  If applicable, include a brief description of ...   \n",
       "1  If applicable, include a brief description of ...   \n",
       "2  If applicable, include a brief description of ...   \n",
       "3  If applicable, include a brief description of ...   \n",
       "\n",
       "                          J: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          K: summary  \n",
       "0  High calcium and protein dairy foods reduce ri...  \n",
       "1  High calcium and high protein dairy foods may ...  \n",
       "2  Weight stigma is associated with disordered ea...  \n",
       "3  Weight stigma is associated with poorer health...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.2\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=True\n",
    "#     )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B: article_title              object\n",
       "D: system_role                object\n",
       "E: model                      object\n",
       "F: text                       object\n",
       "G: prep step                  object\n",
       "H: summarization task         object\n",
       "I: edit task                  object\n",
       "J: full summarization task    object\n",
       "K: summary                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New prompts 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response as the headline followed by the final version of the summary, \\\n",
    "    where the summary is in paragraph form, i.e.\\\n",
    "    \\<headline>\\n\\n<summary>\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-12_1529'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H%M\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 add date as an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../text/2023-06-11'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-12 1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r'(?:.*\\/)?(.*)$'\n",
    "re.sub(regex, r'\\1', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-11'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "re.sub(regex, r'\\1', '2023-06-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "**Text #3 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "**Text #4 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "**Text #5 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "**Text #6 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "**Text #7 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "An error occurred on line 322 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\478215318.py : Chaining.__init__() missing 1 required positional argument: 'folder_path'\n",
      "\t...Error making chatbot request\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_attributes_initial_2023-06-12_1551.sav\n",
      "Time completed: 2023-06-12 15:51:50.946690\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys([])\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1551.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.3\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 7935 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 8137 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #3 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 4586 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #4 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 7572 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #5 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 4932 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #6 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #7 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.3\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\155391363.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 7935 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\155391363.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 8137 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #3 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\155391363.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 4586 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #4 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\155391363.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 7572 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #5 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\155391363.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 4932 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #6 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #7 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text3_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text4_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text5_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text6_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text7_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_attributes_initial_2023-06-12_1602.sav\n",
      "Time completed: 2023-06-12 16:02:33.291022\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00', 'text3_prompt00', 'text4_prompt00', 'text5_prompt00', 'text6_prompt00', 'text7_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1602.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.32\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "folder_path = '../text/2023-06-12 1'\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 7935 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 8137 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #3 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 4586 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #4 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 7572 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #5 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 131 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14948\\4130344250.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 4932 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Success!\n",
      "**Text #6 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #7 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.3\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create text dictionary\n",
    "folder_path = '../text/2023-06-12 1' # ** UPDATE REQUIRED**\n",
    "\n",
    "encoding='ISO-8859-1'\n",
    "subset=None\n",
    "\n",
    "text_dict = create_text_dict_from_folder(folder_path, encoding=encoding, subset=subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.33 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.33\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Unable to save pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_summaries_initial_2023-06-12_1626.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text1_prompt00': {'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'temperature': 0.7,\n",
       "  'max_tokens': 1000,\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'qna': {'date': '2023-06-12_1607',\n",
       "   'folder': '2023-06-12 1',\n",
       "   'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "   'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "   'model': 'gpt-3.5-turbo',\n",
       "   'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "   'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "   'summarization task': 'summarize for a LinkedIn post.',\n",
       "   'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form, i.e.    \\\\<headline>\\n\\n<summary>',\n",
       "   'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form, i.e.    \\\\<headline>\\n\\n<summary>',\n",
       "   'summary': ['High calcium and protein intake from dairy foods can reduce the risk of fractures and falls in institutionalized older adults. This approach may have a greater impact on reducing the burden of fractures in the community as a whole compared to drug therapy, which only targets those at high risk of fracture. This nutritional intervention was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study found no group difference in all-cause mortality. The nutritional approach produced two novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.',\n",
       "    'High calcium and high protein dairy foods can help reduce the risk of fractures and falls in institutionalised older adults, according to a recent study. The trial found that this nutritional approach was associated with a 33% reduction in the risk of fractures, a 46% reduction in the risk of hip fractures, and an 11% reduction in the risk of falls. The study intentionally targeted a cohort at high risk for fracture, in whom low calcium and protein intakes were common. Compliance was optimised by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The nutritional intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively; and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day are needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.']},\n",
       "  'summaries_dict': {'response_01': 'High calcium and protein intake from dairy foods can reduce the risk of fractures and falls in institutionalized older adults. This approach may have a greater impact on reducing the burden of fractures in the community as a whole compared to drug therapy, which only targets those at high risk of fracture. This nutritional intervention was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study found no group difference in all-cause mortality. The nutritional approach produced two novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.',\n",
       "   'response_02': 'High calcium and high protein dairy foods can help reduce the risk of fractures and falls in institutionalised older adults, according to a recent study. The trial found that this nutritional approach was associated with a 33% reduction in the risk of fractures, a 46% reduction in the risk of hip fractures, and an 11% reduction in the risk of falls. The study intentionally targeted a cohort at high risk for fracture, in whom low calcium and protein intakes were common. Compliance was optimised by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The nutritional intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively; and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day are needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.'},\n",
       "  'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'response_regex': 'response_(.*)',\n",
       "  'simple_summary_dict': {},\n",
       "  'relevance_dict': {},\n",
       "  'n_previous_prompts': {},\n",
       "  'date_created': '2023-06-12_1626'},\n",
       " 'text2_prompt00': {'text': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-focused health promotion policies. These policies assume that individuals can improve their health by losing weight, employing weight stigma as one strategy for motivating behavior change [5]. However, our findings indicate that weight stigma is associated with poorer health behaviors, independent of BMI. Given that physical health and weight are largely shaped by factors outside of an individual\\x92s control (i.e., genetics and social determinants like socioeconomic status) [5], it is concerning that multiple behaviors, for which individuals have some control over, may be undermined by weight stigma.\\nFurthermore, a lower BMI may not necessarily be protective against weight stigma. In our sample, individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. In fact, moderation analyses indicated that individuals with\\xa0lower\\xa0BMIs showed greater disordered eating and alcohol use in the face of weight stigma. These results emerged despite individuals with higher weight reporting greater daily weight stigma. One explanation for the observed differences in health behavioral outcomes across the weight spectrum is that infrequent health behaviors may be less likely to be enacted as coping strategies. For instance, previous research has shown that alcohol use decreases as BMI increases among females with higher weight [44]. Thus, using food, instead of alcohol, may be the more common coping strategy among individuals with higher BMIs, as previous research suggests [45]. Nonetheless, the sizes of the moderation effects were very small, with some confidence intervals functionally at zero, and thus further interpretation of the present findings should only be done with caution.\\nPrior research has found conflicting evidence for the relationship between weight stigma and physical activity. Some studies have found that greater weight stigma is associated with short-term increases in reported exercise behavior [16,\\xa046]. Others have shown that weight stigma is positively correlated with increased exercise avoidance, but has no direct link to self-reported exercise [14,\\xa047]. The current study adds to the latter base of evidence showing no relationship between weight stigma and physical activity. One possible explanation is that participants were asked about their daily experiences with weight stigma, which may not correspond to their level of physical activity over the past month. Ecological momentary assessment methodology may provide better insight into this relationship, as demonstrated by Vartanian et al. who examined health motivations following stigmatizing events in daily life [48].\\nDespite emerging evidence that weight stigma is prevalent among men [28], there is a lack of research on men\\x92s health outcomes related to weight stigma. In this study, moderation by gender was not observed for any outcome. These results are consistent with previous research reporting no gender differences in poor health outcomes such as mortality and obesity due to weight stigma [3,\\xa049]. Men may also feel pressured to meet societal body standards and thus may display the same magnitude of associations between weight stigma and health behaviors. It is recommended that the null gender findings are interpreted with caution, as more research is needed.\\nHow might weight stigma influence an individual\\x92s health behaviors? One potential mechanism is stress. Previous work suggests that weight stigma is stressful [6,\\xa050] and experimental lab studies manipulating weight stigma have shown that individuals with higher weight, as well as those who perceive themselves as overweight, show elevated levels of the stress hormone cortisol following exposure to a weight-stigmatizing event [51,\\xa052]. Additionally, some research has found that individuals who experience more weight-based discrimination have higher hair cortisol levels\\x97a finding most pronounced in those at the highest BMI [53]. Individuals who experience greater stress may engage in more unhealthy coping behaviors. Indeed, stress can drive changes in behaviors such as eating, physical activity, and sleep [54]. For example, Tataranni et al. administered synthetic cortisol vs. placebo and found greater food consumption in the cortisol group [55]. This early work is supported by accumulating evidence that cortisol is associated with increased caloric intake and greater abdominal fat storage [56]. The health behavior pathway may not be independent from that of stress but rather reflect a serial mediation model, wherein weight stigma increases stress that in turn causes decrements in health behaviors.\\nThe present study contributes to the weight stigma literature in several ways. As noted, a key strength of this study is the assessment of several health behaviors within a large, national census-matched sample. Previous studies that have examined weight stigma in relation to different health behaviors have often had small sample sizes or were limited to female subjects. Thus, the present study may provide more generalizable information about health behaviors in the U.S. A related strength of the study is that higher BMI scores were well-represented in the sample, with 31.4% meeting BMI criteria for obesity. This is a closer estimate of the proportion of the American population that is classified with obesity (42%) compared to previous studies [57]. Therefore, there is greater confidence that these findings reflect the experiences of individuals with obesity in the population, aiding generalizability. Lastly, we enhance reproducibility by presenting a two-stage research program of exploratory and confirmatory analyses based on recommended open science practices.\\nThere are some limitations to consider. First, a composite weight stigma score was used due to survey constraints. While early tests indicate good construct validity, additional psychometric testing is warranted (see Online Supplementary Materials\\xa04). Another limitation is the use of self-reported weight, which is subject to inaccuracies. Additionally, the data collection period overlapped with winter holidays. Individuals may have made new year\\x92s health resolutions, and therefore the self-reported health behaviors may be more indicative of newly established goals rather than typical health habits. However, such resolutions would likely dampen, rather than magnify, the relationship between weight stigma and poor health behaviors. Lastly, the study is cross-sectional and therefore causal direction cannot be determined. Weight stigma may operate as a feedback loop that leads to weight gain through certain behaviors such as comfort eating [6], but further investigation is required. Given survey constraints, weight bias internalization was not assessed. Future research should build on these findings to determine the potential role of weight bias internalization in these health behaviors.\\nDespite these limitations, these study\\x92s findings show that weight stigma is significantly associated with several health behaviors. If future research confirms that this is indeed a causal relationship, weight stigma could cumulatively undermine physical health over time. Taken together, these findings highlight weight stigma as a potential barrier to healthy behaviors, and suggest that one strategy to improve population health may be to reduce weight stigma. Though more research is needed, it may be important to employ more weight-inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].\\n\\n',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'temperature': 0.7,\n",
       "  'max_tokens': 1000,\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'qna': {'date': '2023-06-12_1607',\n",
       "   'folder': '2023-06-12 1',\n",
       "   'article_title': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity',\n",
       "   'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "   'model': 'gpt-3.5-turbo',\n",
       "   'text': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-focused health promotion policies. These policies assume that individuals can improve their health by losing weight, employing weight stigma as one strategy for motivating behavior change [5]. However, our findings indicate that weight stigma is associated with poorer health behaviors, independent of BMI. Given that physical health and weight are largely shaped by factors outside of an individual\\x92s control (i.e., genetics and social determinants like socioeconomic status) [5], it is concerning that multiple behaviors, for which individuals have some control over, may be undermined by weight stigma.\\nFurthermore, a lower BMI may not necessarily be protective against weight stigma. In our sample, individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. In fact, moderation analyses indicated that individuals with\\xa0lower\\xa0BMIs showed greater disordered eating and alcohol use in the face of weight stigma. These results emerged despite individuals with higher weight reporting greater daily weight stigma. One explanation for the observed differences in health behavioral outcomes across the weight spectrum is that infrequent health behaviors may be less likely to be enacted as coping strategies. For instance, previous research has shown that alcohol use decreases as BMI increases among females with higher weight [44]. Thus, using food, instead of alcohol, may be the more common coping strategy among individuals with higher BMIs, as previous research suggests [45]. Nonetheless, the sizes of the moderation effects were very small, with some confidence intervals functionally at zero, and thus further interpretation of the present findings should only be done with caution.\\nPrior research has found conflicting evidence for the relationship between weight stigma and physical activity. Some studies have found that greater weight stigma is associated with short-term increases in reported exercise behavior [16,\\xa046]. Others have shown that weight stigma is positively correlated with increased exercise avoidance, but has no direct link to self-reported exercise [14,\\xa047]. The current study adds to the latter base of evidence showing no relationship between weight stigma and physical activity. One possible explanation is that participants were asked about their daily experiences with weight stigma, which may not correspond to their level of physical activity over the past month. Ecological momentary assessment methodology may provide better insight into this relationship, as demonstrated by Vartanian et al. who examined health motivations following stigmatizing events in daily life [48].\\nDespite emerging evidence that weight stigma is prevalent among men [28], there is a lack of research on men\\x92s health outcomes related to weight stigma. In this study, moderation by gender was not observed for any outcome. These results are consistent with previous research reporting no gender differences in poor health outcomes such as mortality and obesity due to weight stigma [3,\\xa049]. Men may also feel pressured to meet societal body standards and thus may display the same magnitude of associations between weight stigma and health behaviors. It is recommended that the null gender findings are interpreted with caution, as more research is needed.\\nHow might weight stigma influence an individual\\x92s health behaviors? One potential mechanism is stress. Previous work suggests that weight stigma is stressful [6,\\xa050] and experimental lab studies manipulating weight stigma have shown that individuals with higher weight, as well as those who perceive themselves as overweight, show elevated levels of the stress hormone cortisol following exposure to a weight-stigmatizing event [51,\\xa052]. Additionally, some research has found that individuals who experience more weight-based discrimination have higher hair cortisol levels\\x97a finding most pronounced in those at the highest BMI [53]. Individuals who experience greater stress may engage in more unhealthy coping behaviors. Indeed, stress can drive changes in behaviors such as eating, physical activity, and sleep [54]. For example, Tataranni et al. administered synthetic cortisol vs. placebo and found greater food consumption in the cortisol group [55]. This early work is supported by accumulating evidence that cortisol is associated with increased caloric intake and greater abdominal fat storage [56]. The health behavior pathway may not be independent from that of stress but rather reflect a serial mediation model, wherein weight stigma increases stress that in turn causes decrements in health behaviors.\\nThe present study contributes to the weight stigma literature in several ways. As noted, a key strength of this study is the assessment of several health behaviors within a large, national census-matched sample. Previous studies that have examined weight stigma in relation to different health behaviors have often had small sample sizes or were limited to female subjects. Thus, the present study may provide more generalizable information about health behaviors in the U.S. A related strength of the study is that higher BMI scores were well-represented in the sample, with 31.4% meeting BMI criteria for obesity. This is a closer estimate of the proportion of the American population that is classified with obesity (42%) compared to previous studies [57]. Therefore, there is greater confidence that these findings reflect the experiences of individuals with obesity in the population, aiding generalizability. Lastly, we enhance reproducibility by presenting a two-stage research program of exploratory and confirmatory analyses based on recommended open science practices.\\nThere are some limitations to consider. First, a composite weight stigma score was used due to survey constraints. While early tests indicate good construct validity, additional psychometric testing is warranted (see Online Supplementary Materials\\xa04). Another limitation is the use of self-reported weight, which is subject to inaccuracies. Additionally, the data collection period overlapped with winter holidays. Individuals may have made new year\\x92s health resolutions, and therefore the self-reported health behaviors may be more indicative of newly established goals rather than typical health habits. However, such resolutions would likely dampen, rather than magnify, the relationship between weight stigma and poor health behaviors. Lastly, the study is cross-sectional and therefore causal direction cannot be determined. Weight stigma may operate as a feedback loop that leads to weight gain through certain behaviors such as comfort eating [6], but further investigation is required. Given survey constraints, weight bias internalization was not assessed. Future research should build on these findings to determine the potential role of weight bias internalization in these health behaviors.\\nDespite these limitations, these study\\x92s findings show that weight stigma is significantly associated with several health behaviors. If future research confirms that this is indeed a causal relationship, weight stigma could cumulatively undermine physical health over time. Taken together, these findings highlight weight stigma as a potential barrier to healthy behaviors, and suggest that one strategy to improve population health may be to reduce weight stigma. Though more research is needed, it may be important to employ more weight-inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].\\n\\n',\n",
       "   'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "   'summarization task': 'summarize for a LinkedIn post.',\n",
       "   'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form, i.e.    \\\\<headline>\\n\\n<summary>',\n",
       "   'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form, i.e.    \\\\<headline>\\n\\n<summary>',\n",
       "   'summary': ['Weight stigma is associated with poorer health behaviors, independent of BMI, according to a study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance in a large sample of U.S. adults. However, no such relationship was observed for physical activity. The study suggests that weight stigma is a potential barrier to healthy behaviors and that reducing weight stigma may be a strategy to improve population health. These findings highlight the need for more weight-inclusive approaches to health promotion.',\n",
       "    \"Weight stigma is associated with poor health behaviors, such as disordered eating, comfort eating, alcohol use, and sleep disturbance, according to a recent study published in the International Journal of Obesity. The study found that weight stigma may undermine an individual's ability to improve their health, regardless of their BMI. While weight stigma has been known to have a negative impact on physical health, this study sheds light on the impact it can have on health behaviors, which could accumulate over time. The findings suggest that reducing weight stigma may be an important strategy for improving population health.\"]},\n",
       "  'summaries_dict': {'response_01': 'Weight stigma is associated with poorer health behaviors, independent of BMI, according to a study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance in a large sample of U.S. adults. However, no such relationship was observed for physical activity. The study suggests that weight stigma is a potential barrier to healthy behaviors and that reducing weight stigma may be a strategy to improve population health. These findings highlight the need for more weight-inclusive approaches to health promotion.',\n",
       "   'response_02': \"Weight stigma is associated with poor health behaviors, such as disordered eating, comfort eating, alcohol use, and sleep disturbance, according to a recent study published in the International Journal of Obesity. The study found that weight stigma may undermine an individual's ability to improve their health, regardless of their BMI. While weight stigma has been known to have a negative impact on physical health, this study sheds light on the impact it can have on health behaviors, which could accumulate over time. The findings suggest that reducing weight stigma may be an important strategy for improving population health.\"},\n",
       "  'article_title': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity',\n",
       "  'response_regex': 'response_(.*)',\n",
       "  'simple_summary_dict': {},\n",
       "  'relevance_dict': {},\n",
       "  'n_previous_prompts': {},\n",
       "  'date_created': '2023-06-12_1626'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = 'batch_Chaining_summaries_initial'\n",
    "save_instance_to_dict(chaining_dict[1.33], description=description, json_path=folder_path, pickle_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice') # Move 'choice' to second column\n",
    "\n",
    "    qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.33\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a journalistic headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     where the summary is in paragraph form, i.e.    \\<headline>\n",
      "\n",
      "<summary>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sample_Chaining_attr(iteration_id=1.33)['qna']['edit task'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1621.sav\n",
      "Time completed: 2023-06-12 16:21:23.477736\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1621.csv\n",
      "Time completed: 2023-06-12 16:21:23.482911\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: folder</th>\n",
       "      <th>C: article_title</th>\n",
       "      <th>D: choice</th>\n",
       "      <th>E: system_role</th>\n",
       "      <th>F: model</th>\n",
       "      <th>G: text</th>\n",
       "      <th>H: prep step</th>\n",
       "      <th>I: summarization task</th>\n",
       "      <th>J: edit task</th>\n",
       "      <th>K: full summarization task</th>\n",
       "      <th>L: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and protein intake from dairy foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight stigma is associated with poorer health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight stigma is associated with poor health b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A: date     B: folder  \\\n",
       "0  2023-06-12  2023-06-12 1   \n",
       "1  2023-06-12  2023-06-12 1   \n",
       "2  2023-06-12  2023-06-12 1   \n",
       "3  2023-06-12  2023-06-12 1   \n",
       "\n",
       "                                    C: article_title  D: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      E: system_role       F: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             G: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        H: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            I: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        J: edit task  \\\n",
       "0  If applicable, include a brief description of ...   \n",
       "1  If applicable, include a brief description of ...   \n",
       "2  If applicable, include a brief description of ...   \n",
       "3  If applicable, include a brief description of ...   \n",
       "\n",
       "                          K: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          L: summary  \n",
       "0  High calcium and protein intake from dairy foo...  \n",
       "1  High calcium and high protein dairy foods can ...  \n",
       "2  Weight stigma is associated with poorer health...  \n",
       "3  Weight stigma is associated with poor health b...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.34\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "\n",
    "chatbot_id = 1.33\n",
    "\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1621.sav\n",
      "Time completed: 2023-06-12 16:21:23.477736\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1621.csv\n",
      "Time completed: 2023-06-12 16:21:23.482911\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: folder</th>\n",
       "      <th>C: article_title</th>\n",
       "      <th>D: choice</th>\n",
       "      <th>E: system_role</th>\n",
       "      <th>F: model</th>\n",
       "      <th>G: text</th>\n",
       "      <th>H: prep step</th>\n",
       "      <th>I: summarization task</th>\n",
       "      <th>J: edit task</th>\n",
       "      <th>K: full summarization task</th>\n",
       "      <th>L: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and protein intake from dairy foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight stigma is associated with poorer health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight stigma is associated with poor health b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A: date     B: folder  \\\n",
       "0  2023-06-12  2023-06-12 1   \n",
       "1  2023-06-12  2023-06-12 1   \n",
       "2  2023-06-12  2023-06-12 1   \n",
       "3  2023-06-12  2023-06-12 1   \n",
       "\n",
       "                                    C: article_title  D: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      E: system_role       F: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             G: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        H: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            I: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        J: edit task  \\\n",
       "0  If applicable, include a brief description of ...   \n",
       "1  If applicable, include a brief description of ...   \n",
       "2  If applicable, include a brief description of ...   \n",
       "3  If applicable, include a brief description of ...   \n",
       "\n",
       "                          K: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          L: summary  \n",
       "0  High calcium and protein intake from dairy foo...  \n",
       "1  High calcium and high protein dairy foods can ...  \n",
       "2  Weight stigma is associated with poorer health...  \n",
       "3  Weight stigma is associated with poor health b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(regex, r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.4\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.33\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New prompts 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\nwhere the summary is in paragraph form\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1701.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.41\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.33\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1703.sav\n",
      "Time completed: 2023-06-12 17:03:08.709869\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1703.csv\n",
      "Time completed: 2023-06-12 17:03:08.728449\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: folder</th>\n",
       "      <th>C: article_title</th>\n",
       "      <th>D: choice</th>\n",
       "      <th>E: system_role</th>\n",
       "      <th>F: model</th>\n",
       "      <th>G: text</th>\n",
       "      <th>H: prep step</th>\n",
       "      <th>I: summarization task</th>\n",
       "      <th>J: edit task</th>\n",
       "      <th>K: full summarization task</th>\n",
       "      <th>L: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12 1701</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: High Calcium and Protein Dairy Foods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12 1701</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: High Calcium and High Protein Dairy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12 1701</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight stigma linked to poorer healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12 1701</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A: date     B: folder  \\\n",
       "0  2023-06-12 1701  2023-06-12 1   \n",
       "1  2023-06-12 1701  2023-06-12 1   \n",
       "2  2023-06-12 1701  2023-06-12 1   \n",
       "3  2023-06-12 1701  2023-06-12 1   \n",
       "\n",
       "                                    C: article_title  D: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      E: system_role       F: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             G: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        H: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            I: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        J: edit task  \\\n",
       "0  If applicable, include a brief description of ...   \n",
       "1  If applicable, include a brief description of ...   \n",
       "2  If applicable, include a brief description of ...   \n",
       "3  If applicable, include a brief description of ...   \n",
       "\n",
       "                          K: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          L: summary  \n",
       "0  Headline: High Calcium and Protein Dairy Foods...  \n",
       "1  Headline: High Calcium and High Protein Dairy ...  \n",
       "2  Headline: Weight stigma linked to poorer healt...  \n",
       "3  Headline: Weight Stigma Linked to Poor Health ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New prompts 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\nwhere the summary is in paragraph form.\\\n",
    "    \\nRemove any 'headline' and 'summary' labels\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1721.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.42\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.33\n",
    "\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1721.sav\n",
      "Time completed: 2023-06-12 17:21:28.259863\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial_2023-06-12_1721.csv\n",
      "Time completed: 2023-06-12 17:21:28.268092\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: folder</th>\n",
       "      <th>C: article_title</th>\n",
       "      <th>D: choice</th>\n",
       "      <th>E: system_role</th>\n",
       "      <th>F: model</th>\n",
       "      <th>G: text</th>\n",
       "      <th>H: prep step</th>\n",
       "      <th>I: summarization task</th>\n",
       "      <th>J: edit task</th>\n",
       "      <th>K: full summarization task</th>\n",
       "      <th>L: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12 1720</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High Calcium and High Protein Diet Reduces Ris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12 1720</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and protein dairy foods associate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12 1721</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Study finds weight stigma associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12 1721</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poorer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A: date     B: folder  \\\n",
       "0  2023-06-12 1720  2023-06-12 1   \n",
       "1  2023-06-12 1720  2023-06-12 1   \n",
       "2  2023-06-12 1721  2023-06-12 1   \n",
       "3  2023-06-12 1721  2023-06-12 1   \n",
       "\n",
       "                                    C: article_title  D: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      E: system_role       F: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             G: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        H: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            I: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        J: edit task  \\\n",
       "0  If applicable, include a brief description of ...   \n",
       "1  If applicable, include a brief description of ...   \n",
       "2  If applicable, include a brief description of ...   \n",
       "3  If applicable, include a brief description of ...   \n",
       "\n",
       "                          K: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          L: summary  \n",
       "0  High Calcium and High Protein Diet Reduces Ris...  \n",
       "1  High calcium and protein dairy foods associate...  \n",
       "2  Headline: Study finds weight stigma associated...  \n",
       "3  Headline: Weight Stigma Associated with Poorer...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update prompts 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing or redundant. \\\n",
    "    \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\nwhere the summary is in paragraph form.\\\n",
    "    \\nDo not label the headline and summary.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.43 avoid pickling DataFrame since dict of Chaining instances are already pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1916.json\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_initial2023-06-12_1916.csv\n",
      "Time completed: 2023-06-12 19:16:58.336923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A: date</th>\n",
       "      <th>B: folder</th>\n",
       "      <th>C: article_title</th>\n",
       "      <th>D: choice</th>\n",
       "      <th>E: system_role</th>\n",
       "      <th>F: model</th>\n",
       "      <th>G: text</th>\n",
       "      <th>H: prep step</th>\n",
       "      <th>I: summarization task</th>\n",
       "      <th>J: edit task</th>\n",
       "      <th>K: full summarization task</th>\n",
       "      <th>L: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12 1916</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and protein diet may reduce fract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12 1916</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Calcium and protein-rich diet reduces risk of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12 1916</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12 1916</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>If applicable, include a brief description of ...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A: date     B: folder  \\\n",
       "0  2023-06-12 1916  2023-06-12 1   \n",
       "1  2023-06-12 1916  2023-06-12 1   \n",
       "2  2023-06-12 1916  2023-06-12 1   \n",
       "3  2023-06-12 1916  2023-06-12 1   \n",
       "\n",
       "                                    C: article_title  D: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      E: system_role       F: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             G: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        H: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            I: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        J: edit task  \\\n",
       "0  If applicable, include a brief description of ...   \n",
       "1  If applicable, include a brief description of ...   \n",
       "2  If applicable, include a brief description of ...   \n",
       "3  If applicable, include a brief description of ...   \n",
       "\n",
       "                          K: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          L: summary  \n",
       "0  High calcium and protein diet may reduce fract...  \n",
       "1  Calcium and protein-rich diet reduces risk of ...  \n",
       "2  Weight Stigma Linked to Poor Health Behaviors,...  \n",
       "3  Weight Stigma Linked to Poor Health Behaviors\\...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.43\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.33\n",
    "\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Simple and relevance summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_simplify_task = [\n",
    "    \"\"\"If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.\\\n",
    "    Follow these steps to accomplish this: \\\n",
    "    \\n1. Check if the content and language are appropriate for the audience. \\\n",
    "    \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "    \\n3. Return the final version of the summary to be shown to the audience. \\\n",
    "    \\n\\nYour audience is\"\"\",\n",
    "]\n",
    "\n",
    "simplify_audience = [\n",
    "    # \"a lay audience\",\n",
    "    \"people who are not science experts\",\n",
    "]\n",
    "\n",
    "user_relevance_task = [\n",
    "    \"\"\"Rewrite this summary to include a statement of how it is relevant for the audience. \\\n",
    "        Follow these steps to accomplish this: \\\n",
    "        \\n1. Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things, \\\n",
    "        add a sentence to inform the audience. Otherwise, keep it the same. \\\n",
    "        \\n3. Modify the summary if needed to reduce redundancy. \\\n",
    "        \\n4. Check if the content and language are appropriate for the audience. \\\n",
    "        If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "        \\n5. Return the final version of the summary to be shown to the audience. \\\n",
    "        \\n6. Remove the backticks.\n",
    "        \\n\\nYour audience consists of\"\"\",\n",
    "]\n",
    "\n",
    "relevance_audience = [\n",
    "    \"seniors\",\n",
    "    \"people who enjoy sports\",\n",
    "    # \"people new to resistance training\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_iteration_id: 1.43\n",
      "n_choices: 1\n",
      "**text1_prompt00\n",
      "simplify_iteration:  1\n",
      "Task: If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \n",
      "1. Check if the content and language are appropriate for the audience.     \n",
      "2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "3. Return the final version of the summary to be shown to the audience.     \n",
      "\n",
      "Your audience is people who are not science experts\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to summarize response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "\t\t...Preparing to summarize response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "**text2_prompt00\n",
      "simplify_iteration:  1\n",
      "Task: If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \n",
      "1. Check if the content and language are appropriate for the audience.     \n",
      "2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "    \n",
      "3. Return the final version of the summary to be shown to the audience.     \n",
      "\n",
      "Your audience is people who are not science experts\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to summarize response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n",
      "\t\t...Preparing to summarize response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Summary given\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2.10\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# chatbot_id = iteration_id\n",
    "summary_iteration_id = 1.43\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "\n",
    "audience = simplify_audience\n",
    "simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "    chatbot_dict[chatbot_id], iteration_id,\n",
    "    n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simple_summaries[2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'response_01': {0: {'simple summary choice': 1,\n",
       "    'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "    'audience': 'people who are not science experts',\n",
       "    'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "    'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "    'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "  'response_02': {0: {'simple summary choice': 1,\n",
       "    'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "    'audience': 'people who are not science experts',\n",
       "    'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "    'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "    'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_summaries[2.1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simple_summaries[2.10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update `sample_Chaining_attr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_01': {0: {'simple summary choice': 1,\n",
       "   'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "   'audience': 'people who are not science experts',\n",
       "   'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "   'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "   'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       " 'response_02': {0: {'simple summary choice': 1,\n",
       "   'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "   'audience': 'people who are not science experts',\n",
       "   'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "   'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "   'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_Chaining_attr(chaining_dict=chaining_dict, iteration_id=iteration_id):\n",
    "    if type(chaining_dict[iteration_id]) == dict:\n",
    "        return (vars(chaining_dict[iteration_id][next(iter(chaining_dict[iteration_id]))]))\n",
    "    elif type(chaining_dict[iteration_id]) == list:\n",
    "        return (chaining_dict[iteration_id][0][next(iter(chaining_dict[iteration_id][0]))])\n",
    "\n",
    "sample_Chaining_attr(simple_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.1: [{1: {'response_01': {0: {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "      'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "    'response_02': {0: {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "      'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       "  {1: {'response_01': {0: {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': \"Weight stigma can negatively impact health behaviors, regardless of a person's weight, according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep problems, but not physical activity. The researchers also discovered that people of all weights reported experiencing weight stigma. This suggests that weight stigma can be a barrier to healthy behaviors and reducing it could improve overall health.\",\n",
       "      'original summary': 'Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.'}},\n",
       "    'response_02': {0: {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': \"Weight discrimination, or being treated unfairly because of one's weight, is a common problem that can lead to unhealthy behaviors, according to a recent study published in the International Journal of Obesity. The study found that weight discrimination was linked to disordered eating, comfort eating, alcohol use, and sleep problems, regardless of a person's body mass index (BMI). Interestingly, the study found no connection between weight discrimination and physical activity. These findings suggest that weight discrimination can make it harder for people to adopt healthy habits, and that promoting a more inclusive approach to health may be more effective. More research is needed to understand how weight bias affects people's health behaviors. The study was conducted with a large group of adults from across the United States.\",\n",
       "      'original summary': \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"}}}}]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_summaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_iteration_id: 1.43\n",
      "n_choices: 1\n",
      "**text1_prompt00\n",
      "relevance_iteration:  1\n",
      "Task: Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.        \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \n",
      "3. Modify the summary if needed to reduce redundancy.         \n",
      "4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "        \n",
      "5. Return the final version of the summary to be shown to the audience.         \n",
      "6. Remove the backticks.\n",
      "        \n",
      "\n",
      "Your audience consists of seniors\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "relevance_iteration:  2\n",
      "Task: Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.        \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \n",
      "3. Modify the summary if needed to reduce redundancy.         \n",
      "4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "        \n",
      "5. Return the final version of the summary to be shown to the audience.         \n",
      "6. Remove the backticks.\n",
      "        \n",
      "\n",
      "Your audience consists of people who enjoy sports\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "**text2_prompt00\n",
      "relevance_iteration:  1\n",
      "Task: Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.        \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \n",
      "3. Modify the summary if needed to reduce redundancy.         \n",
      "4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "        \n",
      "5. Return the final version of the summary to be shown to the audience.         \n",
      "6. Remove the backticks.\n",
      "        \n",
      "\n",
      "Your audience consists of seniors\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "relevance_iteration:  2\n",
      "Task: Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \n",
      "1. Think about why this might be relevant for the audience in the grand scheme of things.        \n",
      "2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \n",
      "3. Modify the summary if needed to reduce redundancy.         \n",
      "4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
      "        \n",
      "5. Return the final version of the summary to be shown to the audience.         \n",
      "6. Remove the backticks.\n",
      "        \n",
      "\n",
      "Your audience consists of people who enjoy sports\n",
      "summaries_keys: \n",
      "\t ['response_01', 'response_02']\n",
      "\t\t...Preparing to add relevance to response_01\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n",
      "\t\t...Preparing to add relevance to response_02\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Relevance statement given\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2.10\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# chatbot_id = iteration_id\n",
    "summary_iteration_id = 1.43\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# Add relevance\n",
    "relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "    chatbot_dict[summary_iteration_id], iteration_id, prompt_column='relevance', \n",
    "    n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'folder': '2023-06-12 1',\n",
       " 'system_role': 'You are a journalist writing content based on science research articles.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'date': '2023-06-12 1916',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "  'summary': [\"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "   'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.']},\n",
       " 'summaries_dict': {'response_01': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "  'response_02': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {1: {'response_01': {0: {'simple summary choice': 1,\n",
       "     'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "     'audience': 'people who are not science experts',\n",
       "     'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "     'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "     'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {0: {'simple summary choice': 1,\n",
       "     'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "     'audience': 'people who are not science experts',\n",
       "     'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "     'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "     'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       " 'relevance_dict': {1: {'response_01': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'seniors',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "     'relevance statement': 'A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. The findings suggest that inadequate intake of calcium and protein may contribute to the high incidence of fractures in the elderly population. This study is relevant for seniors as it highlights the importance of a balanced diet to maintain bone health and prevent falls.',\n",
       "     'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'seniors',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "     'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially important because many seniors have inadequate calcium and protein intake, which contributes to a large portion of the fracture burden in the community. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the health and well-being of seniors.',\n",
       "     'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}},\n",
       "  2: {'response_01': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'people who enjoy sports',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "     'relevance statement': 'A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. This is important for sports enthusiasts who are aging and want to maintain their physical activity levels. The study suggests that inadequate intake of calcium and protein may contribute to fractures and falls in older adults, and a diet rich in these nutrients may help prevent these injuries.',\n",
       "     'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'people who enjoy sports',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "     'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially relevant for sports enthusiasts who want to maintain their physical health and avoid injuries. The study showed that many people have inadequate calcium and protein intake, which increases their risk of fractures. By incorporating high calcium and protein foods into their diet, sports enthusiasts can reduce their risk of fractures and falls, and maintain their active lifestyle.',\n",
       "     'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       " 'n_previous_prompts': {'simply_summary': 0, 'relevance': 1}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr(iteration_id=1.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'response_01': {0: {'simple summary choice': 1,\n",
       "    'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "    'audience': 'people who are not science experts',\n",
       "    'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "    'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "    'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "  'response_02': {0: {'simple summary choice': 1,\n",
       "    'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "    'audience': 'people who are not science experts',\n",
       "    'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "    'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "    'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr(iteration_id=1.43)['simple_summary_dict']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error occurred in line 738: merge_all_chaining_results() missing 1 required positional argument: 'chatbot_dict'\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: batch_Chaining_attributes_2023-06-12_2058.json\n",
      "\n",
      "Could not merge; saved Chaining instances as JSON.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_14692\\1216722102.py\", line 738, in <module>\n",
      "    chatbot_dict = merge_all_chaining_results(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: merge_all_chaining_results() missing 1 required positional argument: 'chatbot_dict'\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[iteration_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = pd.concat(qna_dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_columns = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_columns = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results['full relevance task'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results['add relevance task (seniors)'] = new_results[\"relevance task\"]\n",
    "        new_results['full add relevance task (seniors)'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_columns.append(relevance_audience_list[0])\n",
    "        spreadsheet_columns.append('add relevance task (seniors)')\n",
    "        spreadsheet_columns.append('full add relevance task (seniors)')\n",
    "        spreadsheet_columns.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_columns]\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_columns)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    chatbot_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        pickle_path = csv_path if pickle_path is None else pickle_path\n",
    "        try:\n",
    "            save_output(\n",
    "                chatbot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return chatbot_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2.10\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# chatbot_id = iteration_id\n",
    "summary_iteration_id = 1.43\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[summary_iteration_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# Merge the results\n",
    "try:\n",
    "    chatbot_dict = merge_all_chaining_results(\n",
    "        chatbot_dict, iteration_id=iteration_id, pivot=True,\n",
    "        empty_columns=True, chatbot_id=summary_iteration_id,\n",
    "        save_df=save, save_chatbot=True, \n",
    "            csv_path=folder_path,\n",
    "    )\n",
    "    print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(f'\\nError occurred in line {traceback.extract_tb(sys.exc_info()[2])[-1][1]}: {e}')\n",
    "    save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "    print(f'\\nCould not merge; saved Chaining instances as JSON.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "Original summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "Merged DataFrame shape: (4, 20)\n",
      "\n",
      "Columns before adding empty columns: ['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'relevance task', 'full relevance task', 'people who enjoy sports', 'add relevance task (seniors)', 'full add relevance task (seniors)', 'seniors']\n",
      "Inserting empty columns...\n",
      "\tK (9): original summary content rating, L (10): original summary language rating, M (11): top summary, S (17): simple summary content rating, T (18): simple summary language rating, U (19): top simple summary, Y (23): added relevance content rating, Z (24): added relevance language rating, AA (25): top added relevance, \n",
      "** Merged dataframe shape: (4, 29)\n",
      "['B: article_title', 'C: choice', 'D: system_role', 'E: model', 'F: text', 'G: prep step', 'H: summarization task', 'I: full summarization task', 'J: summary', 'K: original summary content rating', 'L: original summary language rating', 'M: top summary', 'N: simple summary choice', 'O: audience', 'P: simplify task', 'Q: full simplify task', 'R: simple summary', 'S: simple summary content rating', 'T: simple summary language rating', 'U: top simple summary', 'V: relevance task', 'W: full relevance task', 'X: people who enjoy sports', 'Y: added relevance content rating', 'Z: added relevance language rating', 'AA: top added relevance', 'AB: add relevance task (seniors)', 'AC: full add relevance task (seniors)', 'AD: seniors']\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_2023-06-12_2100.sav\n",
      "Time completed: 2023-06-12 21:00:44.587043\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_2023-06-12_2100.csv\n",
      "Time completed: 2023-06-12 21:00:44.610133\n",
      "\tDataFrame saved as CSV\n",
      "\n",
      "Saving Chaining object (chatbot)...\n",
      "B: article_title\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "C: choice\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "D: system_role\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "E: model\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "F: text\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "G: prep step\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "H: summarization task\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "I: full summarization task\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "J: summary\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "K: original summary content rating\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "L: original summary language rating\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "M: top summary\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "N: simple summary choice\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "O: audience\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "P: simplify task\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "Q: full simplify task\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "R: simple summary\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "S: simple summary content rating\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "T: simple summary language rating\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "U: top simple summary\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "V: relevance task\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "W: full relevance task\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "X: people who enjoy sports\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "Y: added relevance content rating\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "Z: added relevance language rating\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "AA: top added relevance\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "AB: add relevance task (seniors)\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "AC: full add relevance task (seniors)\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "AD: seniors\n",
      "\t_is_copy\n",
      "\t_mgr\n",
      "\t_item_cache\n",
      "\t_attrs\n",
      "\t_flags\n",
      "\t_name\n",
      "\t_cacher\n",
      "Unable to save pickle\n",
      "Dictionary keys: dict_keys(['B: article_title', 'C: choice', 'D: system_role', 'E: model', 'F: text', 'G: prep step', 'H: summarization task', 'I: full summarization task', 'J: summary', 'K: original summary content rating', 'L: original summary language rating', 'M: top summary', 'N: simple summary choice', 'O: audience', 'P: simplify task', 'Q: full simplify task', 'R: simple summary', 'S: simple summary content rating', 'T: simple summary language rating', 'U: top simple summary', 'V: relevance task', 'W: full relevance task', 'X: people who enjoy sports', 'Y: added relevance content rating', 'Z: added relevance language rating', 'AA: top added relevance', 'AB: add relevance task (seniors)', 'AC: full add relevance task (seniors)', 'AD: seniors'])\n",
      "An error occurred on line 173 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\response_processing.py : Object of type ReferenceType is not JSON serializable\n",
      "Unable to save chatbot dictionary to JSON\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = pd.concat(qna_dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_columns = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_columns = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results['full relevance task'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results['add relevance task (seniors)'] = new_results[\"relevance task\"]\n",
    "        new_results['full add relevance task (seniors)'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_columns.append(relevance_audience_list[0])\n",
    "        spreadsheet_columns.append('add relevance task (seniors)')\n",
    "        spreadsheet_columns.append('full add relevance task (seniors)')\n",
    "        spreadsheet_columns.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_columns]\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_columns)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    chatbot_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        pickle_path = csv_path if pickle_path is None else pickle_path\n",
    "        try:\n",
    "            save_output(\n",
    "                chatbot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return chatbot_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2.10\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# chatbot_id = iteration_id\n",
    "summary_iteration_id = 1.43\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[summary_iteration_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# Merge the results\n",
    "try:\n",
    "    chatbot_dict = merge_all_chaining_results2(\n",
    "        chatbot_dict, iteration_id=iteration_id, pivot=True,\n",
    "        empty_columns=True, chatbot_id=summary_iteration_id,\n",
    "        save_df=save, save_chatbot=save, \n",
    "            csv_path=folder_path,\n",
    "    )\n",
    "    print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(f'\\nError occurred in line {traceback.extract_tb(sys.exc_info()[2])[-1][1]}: {e}')\n",
    "    save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "    print(f'\\nCould not merge; saved Chaining instances as JSON.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "Original summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "Merged DataFrame shape: (4, 20)\n",
      "\n",
      "Columns before adding empty columns: ['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'relevance task', 'full relevance task', 'people who enjoy sports', 'add relevance task (seniors)', 'full add relevance task (seniors)', 'seniors']\n",
      "Inserting empty columns...\n",
      "\tK (9): original summary content rating, L (10): original summary language rating, M (11): top summary, S (17): simple summary content rating, T (18): simple summary language rating, U (19): top simple summary, Y (23): added relevance content rating, Z (24): added relevance language rating, AA (25): top added relevance, \n",
      "** Merged dataframe shape: (4, 29)\n",
      "['B: article_title', 'C: choice', 'D: system_role', 'E: model', 'F: text', 'G: prep step', 'H: summarization task', 'I: full summarization task', 'J: summary', 'K: original summary content rating', 'L: original summary language rating', 'M: top summary', 'N: simple summary choice', 'O: audience', 'P: simplify task', 'Q: full simplify task', 'R: simple summary', 'S: simple summary content rating', 'T: simple summary language rating', 'U: top simple summary', 'V: relevance task', 'W: full relevance task', 'X: people who enjoy sports', 'Y: added relevance content rating', 'Z: added relevance language rating', 'AA: top added relevance', 'AB: add relevance task (seniors)', 'AC: full add relevance task (seniors)', 'AD: seniors']\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_2023-06-12_2110.sav\n",
      "Time completed: 2023-06-12 21:10:07.884938\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_summaries_2023-06-12_2110.csv\n",
      "Time completed: 2023-06-12 21:10:07.892908\n",
      "\tDataFrame saved as CSV\n",
      "\n",
      "Saving Chaining object (chatbot)...\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-12 1/batch_Chaining_attributes_2023-06-12_2110.sav\n",
      "Time completed: 2023-06-12 21:10:07.893904\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_attributes_2023-06-12_2110.json\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, df_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = pd.concat(qna_dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_columns = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_columns = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results['full relevance task'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results['add relevance task (seniors)'] = new_results[\"relevance task\"]\n",
    "        new_results['full add relevance task (seniors)'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_columns.append(relevance_audience_list[0])\n",
    "        spreadsheet_columns.append('add relevance task (seniors)')\n",
    "        spreadsheet_columns.append('full add relevance task (seniors)')\n",
    "        spreadsheet_columns.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_columns]\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_columns)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    df_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        pickle_path = csv_path if pickle_path is None else pickle_path\n",
    "        try:\n",
    "            save_output(\n",
    "                df_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return df_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2.10\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# chatbot_id = iteration_id\n",
    "summary_iteration_id = 1.43\n",
    "save_outputs = True\n",
    "save = True\n",
    "# save = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[summary_iteration_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# Merge the results\n",
    "try:\n",
    "    df_dict = merge_all_chaining_results2(\n",
    "        chatbot_dict, dict(), iteration_id=iteration_id, pivot=True,\n",
    "        empty_columns=True, chatbot_id=summary_iteration_id,\n",
    "        save_df=save, save_chatbot=save, \n",
    "            csv_path=folder_path,\n",
    "    )\n",
    "    print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(f'\\nError occurred in line {traceback.extract_tb(sys.exc_info()[2])[-1][1]}: {e}')\n",
    "    save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "    print(f'\\nCould not merge; saved Chaining instances as JSON.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "\n",
      "original summaries df columns: Index(['date', 'folder', 'article_title', 'choice', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "** Merged dataframe shape: (4, 20)\n",
      "['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'relevance task', 'full relevance task', 'people who enjoy sports', 'add relevance task (seniors)', 'full add relevance task (seniors)', 'seniors']\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = create_qna_df(qna_dict, chatbot_dict, iteration_id, chatbot_id)[iteration_id]\n",
    "    # qna_df.rename(columns={'summary': 'original summary'}, inplace=True)\n",
    "    # print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    # print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "    print(f'\\noriginal summaries df columns: {qna_df.columns}\\n')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results['full relevance task'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results['add relevance task (seniors)'] = new_results[\"relevance task\"]\n",
    "        new_results['full add relevance task (seniors)'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[0])\n",
    "        spreadsheet_column_names.append('add relevance task (seniors)')\n",
    "        spreadsheet_column_names.append('full add relevance task (seniors)')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_column_names]\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_column_names = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_column_names)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_column_names[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    df_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        try:\n",
    "            save_output(\n",
    "                df_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return df_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 2.10\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "# chatbot_id = iteration_id\n",
    "summary_iteration_id = 1.43\n",
    "save_outputs = False\n",
    "# save = True\n",
    "save = False\n",
    "empty_columns = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[summary_iteration_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, summary_iteration_id=summary_iteration_id\n",
    "#     )\n",
    "\n",
    "# Merge the results\n",
    "# try:\n",
    "#     df_dict = merge_all_chaining_results2(\n",
    "#         chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "#         empty_columns=empty_columns, chatbot_id=summary_iteration_id,\n",
    "#         save_df=save, save_chatbot=save, \n",
    "#             csv_path=folder_path,\n",
    "#     )\n",
    "#     print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "# except Exception as error:\n",
    "#     exc_type, exc_obj, tb = sys.exc_info()\n",
    "#     f = tb.tb_frame\n",
    "#     lineno = tb.tb_lineno\n",
    "#     file = f.f_code.co_filename\n",
    "#     print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "#     print('Unable to merge results')\n",
    "#     if save:\n",
    "#         save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "#         print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "df_dict = merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "    empty_columns=empty_columns, chatbot_id=summary_iteration_id,\n",
    "    save_df=save, save_chatbot=save, \n",
    "        csv_path=folder_path,\n",
    ")\n",
    "print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "# df_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "      <th>simple summary choice</th>\n",
       "      <th>audience</th>\n",
       "      <th>simplify task</th>\n",
       "      <th>full simplify task</th>\n",
       "      <th>simple summary</th>\n",
       "      <th>relevance task</th>\n",
       "      <th>full relevance task</th>\n",
       "      <th>people who enjoy sports</th>\n",
       "      <th>add relevance task (seniors)</th>\n",
       "      <th>full add relevance task (seniors)</th>\n",
       "      <th>seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and protein diet may reduce fract...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>A recent study has found that a diet high in c...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>A recent study has found that a diet high in c...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>A recent study has found that a diet high in c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Calcium and protein-rich diet reduces risk of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>A recent study found that older adults who con...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>A recent study found that a diet rich in calci...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>A recent study found that a diet rich in calci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors,...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>Weight stigma can negatively impact health beh...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Weight stigma can negatively impact health beh...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Weight stigma can negatively impact health beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>If needed, rewrite the text using terms approp...</td>\n",
       "      <td>Weight discrimination, or being treated unfair...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Weight stigma, or discrimination based on a pe...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Rewrite this summary to include a statement of...</td>\n",
       "      <td>Weight stigma, or discrimination based on a pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...       1   \n",
       "1  Effect of dietary sources of calcium and prote...       2   \n",
       "2  Weight stigma and health behaviors: evidence f...       1   \n",
       "3  Weight stigma and health behaviors: evidence f...       2   \n",
       "\n",
       "                                         system_role          model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                                text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                           prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "               summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                             full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                             summary simple summary choice  \\\n",
       "0  High calcium and protein diet may reduce fract...                     1   \n",
       "1  Calcium and protein-rich diet reduces risk of ...                     1   \n",
       "2  Weight Stigma Linked to Poor Health Behaviors,...                     1   \n",
       "3  Weight Stigma Linked to Poor Health Behaviors\\...                     1   \n",
       "\n",
       "                             audience  \\\n",
       "0  people who are not science experts   \n",
       "1  people who are not science experts   \n",
       "2  people who are not science experts   \n",
       "3  people who are not science experts   \n",
       "\n",
       "                                       simplify task  \\\n",
       "0  If needed, rewrite the text using terms approp...   \n",
       "1  If needed, rewrite the text using terms approp...   \n",
       "2  If needed, rewrite the text using terms approp...   \n",
       "3  If needed, rewrite the text using terms approp...   \n",
       "\n",
       "                                  full simplify task  \\\n",
       "0  If needed, rewrite the text using terms approp...   \n",
       "1  If needed, rewrite the text using terms approp...   \n",
       "2  If needed, rewrite the text using terms approp...   \n",
       "3  If needed, rewrite the text using terms approp...   \n",
       "\n",
       "                                      simple summary  \\\n",
       "0  A recent study has found that a diet high in c...   \n",
       "1  A recent study found that older adults who con...   \n",
       "2  Weight stigma can negatively impact health beh...   \n",
       "3  Weight discrimination, or being treated unfair...   \n",
       "\n",
       "                                      relevance task  \\\n",
       "0  Rewrite this summary to include a statement of...   \n",
       "1  Rewrite this summary to include a statement of...   \n",
       "2  Rewrite this summary to include a statement of...   \n",
       "3  Rewrite this summary to include a statement of...   \n",
       "\n",
       "                                 full relevance task  \\\n",
       "0  Rewrite this summary to include a statement of...   \n",
       "1  Rewrite this summary to include a statement of...   \n",
       "2  Rewrite this summary to include a statement of...   \n",
       "3  Rewrite this summary to include a statement of...   \n",
       "\n",
       "                             people who enjoy sports  \\\n",
       "0  A recent study has found that a diet high in c...   \n",
       "1  A recent study found that a diet rich in calci...   \n",
       "2  Weight stigma can negatively impact health beh...   \n",
       "3  Weight stigma, or discrimination based on a pe...   \n",
       "\n",
       "                        add relevance task (seniors)  \\\n",
       "0  Rewrite this summary to include a statement of...   \n",
       "1  Rewrite this summary to include a statement of...   \n",
       "2  Rewrite this summary to include a statement of...   \n",
       "3  Rewrite this summary to include a statement of...   \n",
       "\n",
       "                   full add relevance task (seniors)  \\\n",
       "0  Rewrite this summary to include a statement of...   \n",
       "1  Rewrite this summary to include a statement of...   \n",
       "2  Rewrite this summary to include a statement of...   \n",
       "3  Rewrite this summary to include a statement of...   \n",
       "\n",
       "                                             seniors  \n",
       "0  A recent study has found that a diet high in c...  \n",
       "1  A recent study found that a diet rich in calci...  \n",
       "2  Weight stigma can negatively impact health beh...  \n",
       "3  Weight stigma, or discrimination based on a pe...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test response loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time completed: 2023-06-12 22:48:47.227427\n",
      "Dictionary keys: ['text1_prompt00', 'text2_prompt00']\n",
      "Article title: Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: folder\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['date', 'folder', 'article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: [1]\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: [1, 2]\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: ['simply_summary', 'relevance']\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 1\n",
      "\t\t\tAdded relevance: 2\n",
      "Article title: Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: folder\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['date', 'folder', 'article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: [1]\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: [1, 2]\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: ['simply_summary', 'relevance']\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 1\n",
      "\t\t\tAdded relevance: 2\n",
      "\n",
      "\n",
      "New chatbot dict keys: ['text1_prompt00', 'text2_prompt00']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a journalist writing content based on science research articles.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'folder': '2023-06-12 1',\n",
       " 'qna': {'date': '2023-06-12 1916',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "  'summary': [\"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "   'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.']},\n",
       " 'summaries_dict': {'response_01': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "  'response_02': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {1: {'response_01': {0: {'simple summary choice': 1,\n",
       "     'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "     'audience': 'people who are not science experts',\n",
       "     'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "     'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "     'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {0: {'simple summary choice': 1,\n",
       "     'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "     'audience': 'people who are not science experts',\n",
       "     'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "     'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "     'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       " 'relevance_dict': {1: {'response_01': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'seniors',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "     'relevance statement': 'A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. The findings suggest that inadequate intake of calcium and protein may contribute to the high incidence of fractures in the elderly population. This study is relevant for seniors as it highlights the importance of a balanced diet to maintain bone health and prevent falls.',\n",
       "     'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'seniors',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "     'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially important because many seniors have inadequate calcium and protein intake, which contributes to a large portion of the fracture burden in the community. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the health and well-being of seniors.',\n",
       "     'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}},\n",
       "  2: {'response_01': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'people who enjoy sports',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "     'relevance statement': 'A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. This is important for sports enthusiasts who are aging and want to maintain their physical activity levels. The study suggests that inadequate intake of calcium and protein may contribute to fractures and falls in older adults, and a diet rich in these nutrients may help prevent these injuries.',\n",
       "     'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {0: {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'people who enjoy sports',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "     'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially relevant for sports enthusiasts who want to maintain their physical health and avoid injuries. The study showed that many people have inadequate calcium and protein intake, which increases their risk of fractures. By incorporating high calcium and protein foods into their diet, sports enthusiasts can reduce their risk of fractures and falls, and maintain their active lifestyle.',\n",
       "     'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       " 'n_previous_prompts': {'summaries': 2, 'simple_summary': 1, 'relevance': 2},\n",
       " 'date_created': '2023-06-12_2110'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filename = 'batch_Chaining_attributes_2023-06-12_2110.sav'\n",
    "\n",
    "loaded_pickle = loadpickle(filename, folder_path)\n",
    "chatbot_dict[3] = revive_chatbot_dict(loaded_pickle)\n",
    "sample_Chaining_attr(iteration_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'/batch_Chaining_attributes_2023-06-12_2110.json') as file:\n",
    "    jsonfile = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1_prompt00': {'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'temperature': 0.7,\n",
       "  'max_tokens': 1000,\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'qna': {'date': '2023-06-12 1916',\n",
       "   'folder': '2023-06-12 1',\n",
       "   'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "   'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "   'model': 'gpt-3.5-turbo',\n",
       "   'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "   'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "   'summarization task': 'summarize for a LinkedIn post.',\n",
       "   'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "   'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "   'summary': [\"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "    'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.']},\n",
       "  'summaries_dict': {'response_01': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "   'response_02': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'},\n",
       "  'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'response_regex': 'response_(.*)',\n",
       "  'simple_summary_dict': {'1': {'response_01': {'0': {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "      'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "    'response_02': {'0': {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "      'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       "  'relevance_dict': {'1': {'response_01': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'seniors',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "      'relevance statement': 'A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. The findings suggest that inadequate intake of calcium and protein may contribute to the high incidence of fractures in the elderly population. This study is relevant for seniors as it highlights the importance of a balanced diet to maintain bone health and prevent falls.',\n",
       "      'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "    'response_02': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'seniors',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "      'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially important because many seniors have inadequate calcium and protein intake, which contributes to a large portion of the fracture burden in the community. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the health and well-being of seniors.',\n",
       "      'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}},\n",
       "   '2': {'response_01': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'people who enjoy sports',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "      'relevance statement': 'A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. This is important for sports enthusiasts who are aging and want to maintain their physical activity levels. The study suggests that inadequate intake of calcium and protein may contribute to fractures and falls in older adults, and a diet rich in these nutrients may help prevent these injuries.',\n",
       "      'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "    'response_02': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'people who enjoy sports',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "      'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially relevant for sports enthusiasts who want to maintain their physical health and avoid injuries. The study showed that many people have inadequate calcium and protein intake, which increases their risk of fractures. By incorporating high calcium and protein foods into their diet, sports enthusiasts can reduce their risk of fractures and falls, and maintain their active lifestyle.',\n",
       "      'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       "  'n_previous_prompts': {'simply_summary': 0, 'relevance': 1},\n",
       "  'date_created': '2023-06-12_2110'},\n",
       " 'text2_prompt00': {'text': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-focused health promotion policies. These policies assume that individuals can improve their health by losing weight, employing weight stigma as one strategy for motivating behavior change [5]. However, our findings indicate that weight stigma is associated with poorer health behaviors, independent of BMI. Given that physical health and weight are largely shaped by factors outside of an individual\\x92s control (i.e., genetics and social determinants like socioeconomic status) [5], it is concerning that multiple behaviors, for which individuals have some control over, may be undermined by weight stigma.\\nFurthermore, a lower BMI may not necessarily be protective against weight stigma. In our sample, individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. In fact, moderation analyses indicated that individuals with\\xa0lower\\xa0BMIs showed greater disordered eating and alcohol use in the face of weight stigma. These results emerged despite individuals with higher weight reporting greater daily weight stigma. One explanation for the observed differences in health behavioral outcomes across the weight spectrum is that infrequent health behaviors may be less likely to be enacted as coping strategies. For instance, previous research has shown that alcohol use decreases as BMI increases among females with higher weight [44]. Thus, using food, instead of alcohol, may be the more common coping strategy among individuals with higher BMIs, as previous research suggests [45]. Nonetheless, the sizes of the moderation effects were very small, with some confidence intervals functionally at zero, and thus further interpretation of the present findings should only be done with caution.\\nPrior research has found conflicting evidence for the relationship between weight stigma and physical activity. Some studies have found that greater weight stigma is associated with short-term increases in reported exercise behavior [16,\\xa046]. Others have shown that weight stigma is positively correlated with increased exercise avoidance, but has no direct link to self-reported exercise [14,\\xa047]. The current study adds to the latter base of evidence showing no relationship between weight stigma and physical activity. One possible explanation is that participants were asked about their daily experiences with weight stigma, which may not correspond to their level of physical activity over the past month. Ecological momentary assessment methodology may provide better insight into this relationship, as demonstrated by Vartanian et al. who examined health motivations following stigmatizing events in daily life [48].\\nDespite emerging evidence that weight stigma is prevalent among men [28], there is a lack of research on men\\x92s health outcomes related to weight stigma. In this study, moderation by gender was not observed for any outcome. These results are consistent with previous research reporting no gender differences in poor health outcomes such as mortality and obesity due to weight stigma [3,\\xa049]. Men may also feel pressured to meet societal body standards and thus may display the same magnitude of associations between weight stigma and health behaviors. It is recommended that the null gender findings are interpreted with caution, as more research is needed.\\nHow might weight stigma influence an individual\\x92s health behaviors? One potential mechanism is stress. Previous work suggests that weight stigma is stressful [6,\\xa050] and experimental lab studies manipulating weight stigma have shown that individuals with higher weight, as well as those who perceive themselves as overweight, show elevated levels of the stress hormone cortisol following exposure to a weight-stigmatizing event [51,\\xa052]. Additionally, some research has found that individuals who experience more weight-based discrimination have higher hair cortisol levels\\x97a finding most pronounced in those at the highest BMI [53]. Individuals who experience greater stress may engage in more unhealthy coping behaviors. Indeed, stress can drive changes in behaviors such as eating, physical activity, and sleep [54]. For example, Tataranni et al. administered synthetic cortisol vs. placebo and found greater food consumption in the cortisol group [55]. This early work is supported by accumulating evidence that cortisol is associated with increased caloric intake and greater abdominal fat storage [56]. The health behavior pathway may not be independent from that of stress but rather reflect a serial mediation model, wherein weight stigma increases stress that in turn causes decrements in health behaviors.\\nThe present study contributes to the weight stigma literature in several ways. As noted, a key strength of this study is the assessment of several health behaviors within a large, national census-matched sample. Previous studies that have examined weight stigma in relation to different health behaviors have often had small sample sizes or were limited to female subjects. Thus, the present study may provide more generalizable information about health behaviors in the U.S. A related strength of the study is that higher BMI scores were well-represented in the sample, with 31.4% meeting BMI criteria for obesity. This is a closer estimate of the proportion of the American population that is classified with obesity (42%) compared to previous studies [57]. Therefore, there is greater confidence that these findings reflect the experiences of individuals with obesity in the population, aiding generalizability. Lastly, we enhance reproducibility by presenting a two-stage research program of exploratory and confirmatory analyses based on recommended open science practices.\\nThere are some limitations to consider. First, a composite weight stigma score was used due to survey constraints. While early tests indicate good construct validity, additional psychometric testing is warranted (see Online Supplementary Materials\\xa04). Another limitation is the use of self-reported weight, which is subject to inaccuracies. Additionally, the data collection period overlapped with winter holidays. Individuals may have made new year\\x92s health resolutions, and therefore the self-reported health behaviors may be more indicative of newly established goals rather than typical health habits. However, such resolutions would likely dampen, rather than magnify, the relationship between weight stigma and poor health behaviors. Lastly, the study is cross-sectional and therefore causal direction cannot be determined. Weight stigma may operate as a feedback loop that leads to weight gain through certain behaviors such as comfort eating [6], but further investigation is required. Given survey constraints, weight bias internalization was not assessed. Future research should build on these findings to determine the potential role of weight bias internalization in these health behaviors.\\nDespite these limitations, these study\\x92s findings show that weight stigma is significantly associated with several health behaviors. If future research confirms that this is indeed a causal relationship, weight stigma could cumulatively undermine physical health over time. Taken together, these findings highlight weight stigma as a potential barrier to healthy behaviors, and suggest that one strategy to improve population health may be to reduce weight stigma. Though more research is needed, it may be important to employ more weight-inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].\\n\\n',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'temperature': 0.7,\n",
       "  'max_tokens': 1000,\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'qna': {'date': '2023-06-12 1916',\n",
       "   'folder': '2023-06-12 1',\n",
       "   'article_title': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity',\n",
       "   'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "   'model': 'gpt-3.5-turbo',\n",
       "   'text': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-focused health promotion policies. These policies assume that individuals can improve their health by losing weight, employing weight stigma as one strategy for motivating behavior change [5]. However, our findings indicate that weight stigma is associated with poorer health behaviors, independent of BMI. Given that physical health and weight are largely shaped by factors outside of an individual\\x92s control (i.e., genetics and social determinants like socioeconomic status) [5], it is concerning that multiple behaviors, for which individuals have some control over, may be undermined by weight stigma.\\nFurthermore, a lower BMI may not necessarily be protective against weight stigma. In our sample, individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. In fact, moderation analyses indicated that individuals with\\xa0lower\\xa0BMIs showed greater disordered eating and alcohol use in the face of weight stigma. These results emerged despite individuals with higher weight reporting greater daily weight stigma. One explanation for the observed differences in health behavioral outcomes across the weight spectrum is that infrequent health behaviors may be less likely to be enacted as coping strategies. For instance, previous research has shown that alcohol use decreases as BMI increases among females with higher weight [44]. Thus, using food, instead of alcohol, may be the more common coping strategy among individuals with higher BMIs, as previous research suggests [45]. Nonetheless, the sizes of the moderation effects were very small, with some confidence intervals functionally at zero, and thus further interpretation of the present findings should only be done with caution.\\nPrior research has found conflicting evidence for the relationship between weight stigma and physical activity. Some studies have found that greater weight stigma is associated with short-term increases in reported exercise behavior [16,\\xa046]. Others have shown that weight stigma is positively correlated with increased exercise avoidance, but has no direct link to self-reported exercise [14,\\xa047]. The current study adds to the latter base of evidence showing no relationship between weight stigma and physical activity. One possible explanation is that participants were asked about their daily experiences with weight stigma, which may not correspond to their level of physical activity over the past month. Ecological momentary assessment methodology may provide better insight into this relationship, as demonstrated by Vartanian et al. who examined health motivations following stigmatizing events in daily life [48].\\nDespite emerging evidence that weight stigma is prevalent among men [28], there is a lack of research on men\\x92s health outcomes related to weight stigma. In this study, moderation by gender was not observed for any outcome. These results are consistent with previous research reporting no gender differences in poor health outcomes such as mortality and obesity due to weight stigma [3,\\xa049]. Men may also feel pressured to meet societal body standards and thus may display the same magnitude of associations between weight stigma and health behaviors. It is recommended that the null gender findings are interpreted with caution, as more research is needed.\\nHow might weight stigma influence an individual\\x92s health behaviors? One potential mechanism is stress. Previous work suggests that weight stigma is stressful [6,\\xa050] and experimental lab studies manipulating weight stigma have shown that individuals with higher weight, as well as those who perceive themselves as overweight, show elevated levels of the stress hormone cortisol following exposure to a weight-stigmatizing event [51,\\xa052]. Additionally, some research has found that individuals who experience more weight-based discrimination have higher hair cortisol levels\\x97a finding most pronounced in those at the highest BMI [53]. Individuals who experience greater stress may engage in more unhealthy coping behaviors. Indeed, stress can drive changes in behaviors such as eating, physical activity, and sleep [54]. For example, Tataranni et al. administered synthetic cortisol vs. placebo and found greater food consumption in the cortisol group [55]. This early work is supported by accumulating evidence that cortisol is associated with increased caloric intake and greater abdominal fat storage [56]. The health behavior pathway may not be independent from that of stress but rather reflect a serial mediation model, wherein weight stigma increases stress that in turn causes decrements in health behaviors.\\nThe present study contributes to the weight stigma literature in several ways. As noted, a key strength of this study is the assessment of several health behaviors within a large, national census-matched sample. Previous studies that have examined weight stigma in relation to different health behaviors have often had small sample sizes or were limited to female subjects. Thus, the present study may provide more generalizable information about health behaviors in the U.S. A related strength of the study is that higher BMI scores were well-represented in the sample, with 31.4% meeting BMI criteria for obesity. This is a closer estimate of the proportion of the American population that is classified with obesity (42%) compared to previous studies [57]. Therefore, there is greater confidence that these findings reflect the experiences of individuals with obesity in the population, aiding generalizability. Lastly, we enhance reproducibility by presenting a two-stage research program of exploratory and confirmatory analyses based on recommended open science practices.\\nThere are some limitations to consider. First, a composite weight stigma score was used due to survey constraints. While early tests indicate good construct validity, additional psychometric testing is warranted (see Online Supplementary Materials\\xa04). Another limitation is the use of self-reported weight, which is subject to inaccuracies. Additionally, the data collection period overlapped with winter holidays. Individuals may have made new year\\x92s health resolutions, and therefore the self-reported health behaviors may be more indicative of newly established goals rather than typical health habits. However, such resolutions would likely dampen, rather than magnify, the relationship between weight stigma and poor health behaviors. Lastly, the study is cross-sectional and therefore causal direction cannot be determined. Weight stigma may operate as a feedback loop that leads to weight gain through certain behaviors such as comfort eating [6], but further investigation is required. Given survey constraints, weight bias internalization was not assessed. Future research should build on these findings to determine the potential role of weight bias internalization in these health behaviors.\\nDespite these limitations, these study\\x92s findings show that weight stigma is significantly associated with several health behaviors. If future research confirms that this is indeed a causal relationship, weight stigma could cumulatively undermine physical health over time. Taken together, these findings highlight weight stigma as a potential barrier to healthy behaviors, and suggest that one strategy to improve population health may be to reduce weight stigma. Though more research is needed, it may be important to employ more weight-inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].\\n\\n',\n",
       "   'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "   'summarization task': 'summarize for a LinkedIn post.',\n",
       "   'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "   'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "   'summary': ['Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.',\n",
       "    \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"]},\n",
       "  'summaries_dict': {'response_01': 'Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.',\n",
       "   'response_02': \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"},\n",
       "  'article_title': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity',\n",
       "  'response_regex': 'response_(.*)',\n",
       "  'simple_summary_dict': {'1': {'response_01': {'0': {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': \"Weight stigma can negatively impact health behaviors, regardless of a person's weight, according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep problems, but not physical activity. The researchers also discovered that people of all weights reported experiencing weight stigma. This suggests that weight stigma can be a barrier to healthy behaviors and reducing it could improve overall health.\",\n",
       "      'original summary': 'Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.'}},\n",
       "    'response_02': {'0': {'simple summary choice': 1,\n",
       "      'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "      'audience': 'people who are not science experts',\n",
       "      'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "      'simple summary': \"Weight discrimination, or being treated unfairly because of one's weight, is a common problem that can lead to unhealthy behaviors, according to a recent study published in the International Journal of Obesity. The study found that weight discrimination was linked to disordered eating, comfort eating, alcohol use, and sleep problems, regardless of a person's body mass index (BMI). Interestingly, the study found no connection between weight discrimination and physical activity. These findings suggest that weight discrimination can make it harder for people to adopt healthy habits, and that promoting a more inclusive approach to health may be more effective. More research is needed to understand how weight bias affects people's health behaviors. The study was conducted with a large group of adults from across the United States.\",\n",
       "      'original summary': \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"}}}},\n",
       "  'relevance_dict': {'1': {'response_01': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'seniors',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "      'relevance statement': 'Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, but not physical activity. The authors suggest that weight stigma may hinder healthy behaviors, which could be a potential barrier to improving population health. This study highlights the importance of reducing weight stigma for individuals of all weights.',\n",
       "      'preceding summary': 'Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.'}},\n",
       "    'response_02': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'seniors',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "      'relevance statement': \"Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found that weight stigma was associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. These findings suggest that weight-inclusive approaches to health promotion may be more effective. The study was conducted with a large, national census-matched sample of U.S. adults. It is important for seniors to be aware of weight stigma and its potential impact on their health behaviors.\",\n",
       "      'preceding summary': \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"}}},\n",
       "   '2': {'response_01': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'people who enjoy sports',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "      'relevance statement': 'Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, but not physical activity. Interestingly, individuals across the weight spectrum reported experiencing weight stigma. This study highlights the potential barriers that weight stigma can create for healthy behaviors, and suggests that reducing weight stigma could be a strategy to improve population health. This information is relevant for sports enthusiasts who may be interested in understanding how weight stigma can impact their overall health and well-being.',\n",
       "      'preceding summary': 'Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.'}},\n",
       "    'response_02': {'0': {'relevance choice': 1,\n",
       "      'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "      'audience': 'people who enjoy sports',\n",
       "      'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "      'relevance statement': \"Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, regardless of BMI. Interestingly, there was no relationship found between weight stigma and physical activity. These findings suggest that weight stigma may be a barrier to healthy behaviors, and that weight-inclusive approaches to health promotion may be more effective. This study was conducted with a large, national census-matched sample of U.S. adults. As a sports enthusiast, understanding the impact of weight stigma on health behaviors can help you make informed decisions about your own health and well-being.\",\n",
       "      'preceding summary': \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"}}}},\n",
       "  'n_previous_prompts': {'simply_summary': 0, 'relevance': 1},\n",
       "  'date_created': '2023-06-12_2110'}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text1_prompt00', 'text2_prompt00'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonfile.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: folder\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['date', 'folder', 'article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: ['1']\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: ['1', '2']\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: ['simply_summary', 'relevance']\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 1\n",
      "\t\t\tAdded relevance: 2\n",
      "Article title: Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: folder\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['date', 'folder', 'article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: ['1']\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: ['1', '2']\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: ['simply_summary', 'relevance']\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 1\n",
      "\t\t\tAdded relevance: 2\n",
      "\n",
      "\n",
      "New chatbot dict keys: ['text1_prompt00', 'text2_prompt00']\n"
     ]
    }
   ],
   "source": [
    "chatbot_dict[3.1] = revive_chatbot_dict(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a journalist writing content based on science research articles.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'folder': '2023-06-12 1',\n",
       " 'qna': {'date': '2023-06-12 1916',\n",
       "  'folder': '2023-06-12 1',\n",
       "  'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing or redundant.     \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response in this format:    \\n<headline>\\n\\n<summary>    \\nwhere the summary is in paragraph form.    \\nDo not label the headline and summary.',\n",
       "  'summary': [\"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "   'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.']},\n",
       " 'summaries_dict': {'response_01': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\",\n",
       "  'response_02': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {'1': {'response_01': {'0': {'simple summary choice': 1,\n",
       "     'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "     'audience': 'people who are not science experts',\n",
       "     'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "     'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "     'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {'0': {'simple summary choice': 1,\n",
       "     'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "     'audience': 'people who are not science experts',\n",
       "     'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "     'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "     'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       " 'relevance_dict': {'1': {'response_01': {'0': {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'seniors',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "     'relevance statement': 'A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. The findings suggest that inadequate intake of calcium and protein may contribute to the high incidence of fractures in the elderly population. This study is relevant for seniors as it highlights the importance of a balanced diet to maintain bone health and prevent falls.',\n",
       "     'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {'0': {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'seniors',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of seniors',\n",
       "     'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially important because many seniors have inadequate calcium and protein intake, which contributes to a large portion of the fracture burden in the community. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the health and well-being of seniors.',\n",
       "     'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}},\n",
       "  '2': {'response_01': {'0': {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'people who enjoy sports',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "     'relevance statement': 'A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. This is important for sports enthusiasts who are aging and want to maintain their physical activity levels. The study suggests that inadequate intake of calcium and protein may contribute to fractures and falls in older adults, and a diet rich in these nutrients may help prevent these injuries.',\n",
       "     'preceding summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "   'response_02': {'0': {'relevance choice': 1,\n",
       "     'relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of',\n",
       "     'audience': 'people who enjoy sports',\n",
       "     'full relevance task': 'Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports',\n",
       "     'relevance statement': 'A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially relevant for sports enthusiasts who want to maintain their physical health and avoid injuries. The study showed that many people have inadequate calcium and protein intake, which increases their risk of fractures. By incorporating high calcium and protein foods into their diet, sports enthusiasts can reduce their risk of fractures and falls, and maintain their active lifestyle.',\n",
       "     'preceding summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}},\n",
       " 'n_previous_prompts': {'summaries': 2, 'simple_summary': 1, 'relevance': 2},\n",
       " 'date_created': '2023-06-12_2110'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr(iteration_id=3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1_prompt00': <summary_chain.Chaining at 0x1d56cf96190>,\n",
       " 'text2_prompt00': <summary_chain.Chaining at 0x1d56cf96050>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict[3.1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1_prompt00</th>\n",
       "      <th>text2_prompt00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folder</th>\n",
       "      <td>2023-06-12 1</td>\n",
       "      <td>2023-06-12 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system_role</th>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qna</th>\n",
       "      <td>{'date': '2023-06-12 1916', 'folder': '2023-06...</td>\n",
       "      <td>{'date': '2023-06-12 1916', 'folder': '2023-06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summaries_dict</th>\n",
       "      <td>{'response_01': 'High calcium and protein diet...</td>\n",
       "      <td>{'response_01': 'Weight Stigma Linked to Poor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_title</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_regex</th>\n",
       "      <td>response_(.*)</td>\n",
       "      <td>response_(.*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_summary_dict</th>\n",
       "      <td>{'1': {'response_01': {'0': {'simple summary c...</td>\n",
       "      <td>{'1': {'response_01': {'0': {'simple summary c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance_dict</th>\n",
       "      <td>{'1': {'response_01': {'0': {'relevance choice...</td>\n",
       "      <td>{'1': {'response_01': {'0': {'relevance choice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_previous_prompts</th>\n",
       "      <td>{'simply_summary': 0, 'relevance': 1}</td>\n",
       "      <td>{'simply_summary': 0, 'relevance': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_created</th>\n",
       "      <td>2023-06-12_2110</td>\n",
       "      <td>2023-06-12_2110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text1_prompt00  \\\n",
       "text                 Effect of dietary sources of calcium and prote...   \n",
       "folder                                                    2023-06-12 1   \n",
       "system_role          You are a journalist writing content based on ...   \n",
       "temperature                                                        0.7   \n",
       "max_tokens                                                        1000   \n",
       "model                                                    gpt-3.5-turbo   \n",
       "qna                  {'date': '2023-06-12 1916', 'folder': '2023-06...   \n",
       "summaries_dict       {'response_01': 'High calcium and protein diet...   \n",
       "article_title        Effect of dietary sources of calcium and prote...   \n",
       "response_regex                                           response_(.*)   \n",
       "simple_summary_dict  {'1': {'response_01': {'0': {'simple summary c...   \n",
       "relevance_dict       {'1': {'response_01': {'0': {'relevance choice...   \n",
       "n_previous_prompts               {'simply_summary': 0, 'relevance': 1}   \n",
       "date_created                                           2023-06-12_2110   \n",
       "\n",
       "                                                        text2_prompt00  \n",
       "text                 Weight stigma and health behaviors: evidence f...  \n",
       "folder                                                    2023-06-12 1  \n",
       "system_role          You are a journalist writing content based on ...  \n",
       "temperature                                                        0.7  \n",
       "max_tokens                                                        1000  \n",
       "model                                                    gpt-3.5-turbo  \n",
       "qna                  {'date': '2023-06-12 1916', 'folder': '2023-06...  \n",
       "summaries_dict       {'response_01': 'Weight Stigma Linked to Poor ...  \n",
       "article_title        Weight stigma and health behaviors: evidence f...  \n",
       "response_regex                                           response_(.*)  \n",
       "simple_summary_dict  {'1': {'response_01': {'0': {'simple summary c...  \n",
       "relevance_dict       {'1': {'response_01': {'0': {'relevance choice...  \n",
       "n_previous_prompts               {'simply_summary': 0, 'relevance': 1}  \n",
       "date_created                                           2023-06-12_2110  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_json\n",
    "\n",
    "\n",
    "read_json(folder_path+'/batch_Chaining_attributes_2023-06-12_2110.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
