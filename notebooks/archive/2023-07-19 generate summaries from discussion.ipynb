{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from silvhua import *\n",
    "# from datetime import datetime\n",
    "# sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from `main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import *\n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "n_choices = 1\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = '/database'\n",
    "\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "    if sources_df['title'].tolist() == references_df_dict[iteration_id]['title'].tolist():\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Create summaries (functions contained in orm_summarize.py)\n",
    "        chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "            sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "            simplify_task, simplify_audience, format_task,\n",
    "            chatbot_dict, temperature=temperature,\n",
    "            system_role=system_role, model=model, max_tokens=1000,\n",
    "            n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "            iteration_id=iteration_id, save_outputs=save_outputs\n",
    "            )\n",
    "        #########\n",
    "        # Step 4: Create summaries table\n",
    "        qna_dict = create_summaries_df(\n",
    "            qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "            )\n",
    "\n",
    "        ##########\n",
    "        # Step 5: Add results to summaries and prompts table \n",
    "        bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, article_limit=article_limit)\n",
    "    print(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update `main.py` so it can use local article files or articles in gpt_queue table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "Adding 9 rows to the database...\n",
      "\tDaily Energy Expenditure through the Human Life Course\n",
      "\tDifferential effects of attentional focus strategies during long-term resistance training\n",
      "\tEffect of different doses of supervised exercise on food intake, metabolism, and non-exercise physical activity: The E-MECHANIC randomized controlled trial.\n",
      "\tHabitual tub bathing and risks of incident coronary heart disease and stroke\n",
      "\tHigh doses of anti-inflammatory drugs compromise muscle strength and hypertrophic adaptations to resistance training in young adults.\n",
      "\tHigher muscle fiber conduction velocity and early rate of torque development in chronically strength-trained individuals\n",
      "\tImpact of insufficient sleep on dysregulated blood glucose control under standardised meal conditions\n",
      "\tRecovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Similar Maximum Strength: Combining Cold Water Immersion and Compression\n",
      "\tThe Impact of Sleep Duration on Performance Among Competitive Athletes: A Systematic Literature Review  \n",
      "New records added successfully (if applicable)!\n",
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 9\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-19 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "    if sources_df['title'].tolist() == references_df_dict[iteration_id]['title'].tolist():\n",
    "\n",
    "        # ##### \n",
    "        # Step 3: Create summaries (functions contained in orm_summarize.py)\n",
    "        chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "            sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "            simplify_task, simplify_audience, format_task,\n",
    "            chatbot_dict, temperature=temperature,\n",
    "            system_role=system_role, model=model, max_tokens=1000,\n",
    "            n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "            iteration_id=iteration_id, save_outputs=save_outputs\n",
    "            )\n",
    "        #########\n",
    "        # Step 4: Create summaries table\n",
    "        qna_dict = create_summaries_df(\n",
    "            qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "            )\n",
    "\n",
    "        ##########\n",
    "        # Step 5: Add results to summaries and prompts table \n",
    "        bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "        return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>section</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily Energy Expenditure through the Human Lif...</td>\n",
       "      <td>In addition to providing empirical measures an...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>Total daily energy expenditure (\"total expendi...</td>\n",
       "      <td>Science (New York, N.Y.)</td>\n",
       "      <td>Herman Pontzer, Yosuke Yamada, Hiroyuki Sagaya...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Aug</td>\n",
       "      <td>373</td>\n",
       "      <td>6556</td>\n",
       "      <td>808</td>\n",
       "      <td>812</td>\n",
       "      <td>10.1126/science.abe5017</td>\n",
       "      <td>In addition to providing empirical measures an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Differential effects of attentional focus stra...</td>\n",
       "      <td>This is the first study to investigate the eff...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>The purpose of this study was to investigate t...</td>\n",
       "      <td>European journal of sport science</td>\n",
       "      <td>Brad Jon Schoenfeld, Andrew Vigotsky, Bret Con...</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "      <td>10.1080/17461391.2018.1447020</td>\n",
       "      <td>This is the first study to investigate the eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effect of different doses of supervised exerci...</td>\n",
       "      <td>In this large randomized controlled trial with...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>Exercise is recommended for weight management,...</td>\n",
       "      <td>The American journal of clinical nutrition</td>\n",
       "      <td>Corby K Martin, William D Johnson, Candice A M...</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>583</td>\n",
       "      <td>592</td>\n",
       "      <td>10.1093/ajcn/nqz054</td>\n",
       "      <td>In this large randomized controlled trial with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Habitual tub bathing and risks of incident cor...</td>\n",
       "      <td></td>\n",
       "      <td>discussion</td>\n",
       "      <td>Tub bathing is considered to have a preventive...</td>\n",
       "      <td>Heart (British Cardiac Society)</td>\n",
       "      <td>Tomohiko Ukai, Hiroyasu Iso, Kazumasa Yamagish...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>106</td>\n",
       "      <td>10</td>\n",
       "      <td>732</td>\n",
       "      <td>737</td>\n",
       "      <td>10.1136/heartjnl-2019-315752</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High doses of anti-inflammatory drugs compromi...</td>\n",
       "      <td>The interest in this study was spurred by the ...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>This study tested the hypothesis that high dos...</td>\n",
       "      <td>Acta physiologica (Oxford, England)</td>\n",
       "      <td>M Lilja, M Mandi&amp;#x107;, W Apr&amp;#xf3;, M Melin,...</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10.1111/apha.12948</td>\n",
       "      <td>The interest in this study was spurred by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Higher muscle fiber conduction velocity and ea...</td>\n",
       "      <td>MFCV was measured during explosive force contr...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>Strength-trained individuals (ST) develop grea...</td>\n",
       "      <td>Journal of applied physiology (Bethesda, Md. :...</td>\n",
       "      <td>A Del Vecchio, F Negro, D Falla, I Bazzucchi, ...</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>1218</td>\n",
       "      <td>1226</td>\n",
       "      <td>10.1152/japplphysiol.00025.2018</td>\n",
       "      <td>MFCV was measured during explosive force contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Impact of insufficient sleep on dysregulated b...</td>\n",
       "      <td>Here, we describe for the first time how sleep...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>Sleep, diet and exercise are fundamental to me...</td>\n",
       "      <td>Diabetologia</td>\n",
       "      <td>Neli Tsereteli, Raphael Vallat, Juan Fernandez...</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "      <td>365</td>\n",
       "      <td>10.1007/s00125-021-05608-y</td>\n",
       "      <td>Here, we describe for the first time how sleep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recovery From Eccentric Squat Exercise in Resi...</td>\n",
       "      <td>The study aimed at investigating the effects o...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>The aim of this study was to investigate wheth...</td>\n",
       "      <td>Frontiers in physiology</td>\n",
       "      <td>Julian Schmidt, Alexander Ferrauti, Michael Ke...</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>665204</td>\n",
       "      <td></td>\n",
       "      <td>10.3389/fphys.2021.665204</td>\n",
       "      <td>The study aimed at investigating the effects o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Impact of Sleep Duration on Performance Am...</td>\n",
       "      <td>This literature review, although diverse in th...</td>\n",
       "      <td>discussion</td>\n",
       "      <td>The athletic advantage of sleep, although comm...</td>\n",
       "      <td>Clinical journal of sport medicine : official ...</td>\n",
       "      <td>Gregory W Kirschen, Jason J Jones, Lauren Hale</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>503</td>\n",
       "      <td>512</td>\n",
       "      <td>10.1097/JSM.0000000000000622</td>\n",
       "      <td>This literature review, although diverse in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Daily Energy Expenditure through the Human Lif...   \n",
       "1  Differential effects of attentional focus stra...   \n",
       "2  Effect of different doses of supervised exerci...   \n",
       "3  Habitual tub bathing and risks of incident cor...   \n",
       "4  High doses of anti-inflammatory drugs compromi...   \n",
       "5  Higher muscle fiber conduction velocity and ea...   \n",
       "6  Impact of insufficient sleep on dysregulated b...   \n",
       "7  Recovery From Eccentric Squat Exercise in Resi...   \n",
       "8  The Impact of Sleep Duration on Performance Am...   \n",
       "\n",
       "                                                body     section  \\\n",
       "0  In addition to providing empirical measures an...  discussion   \n",
       "1  This is the first study to investigate the eff...  discussion   \n",
       "2  In this large randomized controlled trial with...  discussion   \n",
       "3                                                     discussion   \n",
       "4  The interest in this study was spurred by the ...  discussion   \n",
       "5  MFCV was measured during explosive force contr...  discussion   \n",
       "6  Here, we describe for the first time how sleep...  discussion   \n",
       "7  The study aimed at investigating the effects o...  discussion   \n",
       "8  This literature review, although diverse in th...  discussion   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Total daily energy expenditure (\"total expendi...   \n",
       "1  The purpose of this study was to investigate t...   \n",
       "2  Exercise is recommended for weight management,...   \n",
       "3  Tub bathing is considered to have a preventive...   \n",
       "4  This study tested the hypothesis that high dos...   \n",
       "5  Strength-trained individuals (ST) develop grea...   \n",
       "6  Sleep, diet and exercise are fundamental to me...   \n",
       "7  The aim of this study was to investigate wheth...   \n",
       "8  The athletic advantage of sleep, although comm...   \n",
       "\n",
       "                                         publication  \\\n",
       "0                           Science (New York, N.Y.)   \n",
       "1                  European journal of sport science   \n",
       "2         The American journal of clinical nutrition   \n",
       "3                    Heart (British Cardiac Society)   \n",
       "4                Acta physiologica (Oxford, England)   \n",
       "5  Journal of applied physiology (Bethesda, Md. :...   \n",
       "6                                       Diabetologia   \n",
       "7                            Frontiers in physiology   \n",
       "8  Clinical journal of sport medicine : official ...   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Herman Pontzer, Yosuke Yamada, Hiroyuki Sagaya...  2021   Aug        373   \n",
       "1  Brad Jon Schoenfeld, Andrew Vigotsky, Bret Con...  2018               18   \n",
       "2  Corby K Martin, William D Johnson, Candice A M...  2019              110   \n",
       "3  Tomohiko Ukai, Hiroyasu Iso, Kazumasa Yamagish...  2020              106   \n",
       "4  M Lilja, M Mandi&#x107;, W Apr&#xf3;, M Melin,...  2018              222   \n",
       "5  A Del Vecchio, F Negro, D Falla, I Bazzucchi, ...  2018              125   \n",
       "6  Neli Tsereteli, Raphael Vallat, Juan Fernandez...  2022               65   \n",
       "7  Julian Schmidt, Alexander Ferrauti, Michael Ke...  2021               12   \n",
       "8     Gregory W Kirschen, Jason J Jones, Lauren Hale  2020               30   \n",
       "\n",
       "  pub_issue start_page end_page                              doi  \\\n",
       "0      6556        808      812          10.1126/science.abe5017   \n",
       "1         5        705      712    10.1080/17461391.2018.1447020   \n",
       "2         3        583      592              10.1093/ajcn/nqz054   \n",
       "3        10        732      737     10.1136/heartjnl-2019-315752   \n",
       "4         2                                   10.1111/apha.12948   \n",
       "5         4       1218     1226  10.1152/japplphysiol.00025.2018   \n",
       "6         2        356      365       10.1007/s00125-021-05608-y   \n",
       "7               665204                 10.3389/fphys.2021.665204   \n",
       "8         5        503      512     10.1097/JSM.0000000000000622   \n",
       "\n",
       "                                                text  \n",
       "0  In addition to providing empirical measures an...  \n",
       "1  This is the first study to investigate the eff...  \n",
       "2  In this large randomized controlled trial with...  \n",
       "3                                                     \n",
       "4  The interest in this study was spurred by the ...  \n",
       "5  MFCV was measured during explosive force contr...  \n",
       "6  Here, we describe for the first time how sleep...  \n",
       "7  The study aimed at investigating the effects o...  \n",
       "8  This literature review, although diverse in th...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qna_dict[iteration_id]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "Adding 9 rows to the database...\n",
      "\t** Already exists in the database: Daily Energy Expenditure through the Human Life Course.\n",
      "\t** Already exists in the database: Differential effects of attentional focus strategies during long-term resistance training.\n",
      "\t** Already exists in the database: Effect of different doses of supervised exercise on food intake, metabolism, and non-exercise physical activity: The E-MECHANIC randomized controlled trial..\n",
      "\t** Already exists in the database: Habitual tub bathing and risks of incident coronary heart disease and stroke.\n",
      "\t** Already exists in the database: High doses of anti-inflammatory drugs compromise muscle strength and hypertrophic adaptations to resistance training in young adults..\n",
      "\t** Already exists in the database: Higher muscle fiber conduction velocity and early rate of torque development in chronically strength-trained individuals.\n",
      "\t** Already exists in the database: Impact of insufficient sleep on dysregulated blood glucose control under standardised meal conditions.\n",
      "\t** Already exists in the database: Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Similar Maximum Strength: Combining Cold Water Immersion and Compression.\n",
      "\t** Already exists in the database: The Impact of Sleep Duration on Performance Among Competitive Athletes: A Systematic Literature Review  .\n",
      "New records added successfully (if applicable)!\n",
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 9\n",
      "**Text #169 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #169 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #169 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #169 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #168 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #168 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #168 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #168 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #167 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #167 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #167 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #167 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #166 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #166 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #166 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #166 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #165 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #165 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #165 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #165 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #164 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "An error occurred on line 136 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : 'NoneType' object is not subscriptable\n",
      "\t...Error making chatbot request\n",
      "**Text #163 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #163 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #163 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #163 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #162 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #162 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #162 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #162 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #161 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #161 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #161 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #161 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 169_prompt00...\n",
      "Processing 169_prompt01...\n",
      "Processing 169_prompt02...\n",
      "Processing 169_prompt03...\n",
      "Processing 168_prompt00...\n",
      "Processing 168_prompt01...\n",
      "Processing 168_prompt02...\n",
      "Processing 168_prompt03...\n",
      "Processing 167_prompt00...\n",
      "Processing 167_prompt01...\n",
      "Processing 167_prompt02...\n",
      "Processing 167_prompt03...\n",
      "Processing 166_prompt00...\n",
      "Processing 166_prompt01...\n",
      "Processing 166_prompt02...\n",
      "Processing 166_prompt03...\n",
      "Processing 165_prompt00...\n",
      "Processing 165_prompt01...\n",
      "Processing 165_prompt02...\n",
      "Processing 165_prompt03...\n",
      "Processing 163_prompt00...\n",
      "Processing 163_prompt01...\n",
      "Processing 163_prompt02...\n",
      "Processing 163_prompt03...\n",
      "Processing 162_prompt00...\n",
      "Processing 162_prompt01...\n",
      "Processing 162_prompt02...\n",
      "Processing 162_prompt03...\n",
      "Processing 161_prompt00...\n",
      "Processing 161_prompt01...\n",
      "Processing 161_prompt02...\n",
      "Processing 161_prompt03...\n",
      "Error converting summary column to JSON: Invalid control character at: line 2 column 514 (char 590); will do row by row\n",
      "Error converting summary 21 to JSON: Invalid control character at: line 2 column 514 (char 590)\n",
      "Error converting summary 31 to JSON: Invalid control character at: line 3 column 126 (char 215)\n",
      "Original summaries DataFrame shape: (32, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 32 rows to the database...\n",
      "\tReference #169: Sleep and Sports: Surprising Facts Revealed\n",
      "\tReference #169: Sleep and Sports: The Surprising Connection\n",
      "\tReference #169: New Research Reveals Surprising Impact of Sleep on Athletic Performance\n",
      "\tReference #169: Get the scoop on how sleep affects athletic performance!\n",
      "\tReference #168: Fascinating research on muscle soreness and recovery\n",
      "\tReference #168: Fascinating Research on Aging and Muscle Soreness\n",
      "\tReference #168: New Research Reveals Surprising Findings About Muscle Soreness and Recovery\n",
      "\tReference #168: Fascinating Research on Muscle Soreness and Recovery\n",
      "\tReference #167: Discover the Surprising Link Between Sleep and Blood Sugar Levels!\n",
      "\tReference #167: Discover the Surprising Link Between Sleep and Blood Sugar Control\n",
      "\tReference #167: Discover how sleep duration and quality can improve your metabolic health!\n",
      "\tReference #167: Discover the Surprising Link between Sleep and Blood Sugar Levels\n",
      "\tReference #166: Exciting Health Research on Explosive Force and Muscle Fiber Conduction Velocity\n",
      "\tReference #166: Impressive Study on Muscle Fiber Conduction Velocity\n",
      "\tReference #166: New Study Reveals Exciting Facts About Muscle Fiber Conduction Velocity\n",
      "\tReference #166: Exciting New Research on Explosive Strength and Muscle Fiber Conduction Velocity!\n",
      "\tReference #165: Surprising Study Shows Painkillers Can Affect Muscle Growth\n",
      "\tReference #165: You won't believe what this study found about NSAIDs and exercise!\n",
      "\tReference #165: New Research Shows NSAIDs May Hinder Muscle Growth from Exercise\n",
      "\tReference #165: Surprising Study Reveals How Ibuprofen Affects Muscle Growth During Exercise\n",
      "\tReference #163: Learn how exercise affects weight loss and appetite\n",
      "\tReference #163: Discover the Surprising Truth About Exercise and Weight Loss\n",
      "\tReference #163: Exciting Research on Exercise and Weight Loss\n",
      "\tReference #163: Fascinating Findings on Exercise and Weight Loss!\n",
      "\tReference #162: Exciting Study Reveals How to Maximize Muscle Growth\n",
      "\tReference #162: Discover the Surprising Effects of Attentional Focus on Muscle Growth!\n",
      "\tReference #162: Mind-Muscle Connection: The Key to Muscle Growth?\n",
      "\tReference #162: New Study Reveals Mind-Muscle Connection for Muscle Growth\n",
      "\tReference #161: Fascinating research on changes in metabolism across the lifespan\n",
      "\tReference #161: Discover the Surprising Facts About How Our Metabolism Changes Throughout Life\n",
      "\tReference #161: Fascinating research on how our metabolism changes throughout our lives\n",
      "\tReference #161: Discover the Surprising Ways Our Metabolic Rate Changes Throughout Life!\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-19 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "Adding 9 rows to the database...\n",
      "\t** Already exists in the database: Daily Energy Expenditure through the Human Life Course.\n",
      "\t** Already exists in the database: Differential effects of attentional focus strategies during long-term resistance training.\n",
      "\t** Already exists in the database: Effect of different doses of supervised exercise on food intake, metabolism, and non-exercise physical activity: The E-MECHANIC randomized controlled trial..\n",
      "\t** Already exists in the database: Habitual tub bathing and risks of incident coronary heart disease and stroke.\n",
      "\t** Already exists in the database: High doses of anti-inflammatory drugs compromise muscle strength and hypertrophic adaptations to resistance training in young adults..\n",
      "\t** Already exists in the database: Higher muscle fiber conduction velocity and early rate of torque development in chronically strength-trained individuals.\n",
      "\t** Already exists in the database: Impact of insufficient sleep on dysregulated blood glucose control under standardised meal conditions.\n",
      "\t** Already exists in the database: Recovery From Eccentric Squat Exercise in Resistance-Trained Young and Master Athletes With Similar Maximum Strength: Combining Cold Water Immersion and Compression.\n",
      "\t** Already exists in the database: The Impact of Sleep Duration on Performance Among Competitive Athletes: A Systematic Literature Review  .\n",
      "New records added successfully (if applicable)!\n",
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 9\n",
      "**Text #169 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #169 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #168 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #168 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #167 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #167 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #166 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #166 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #165 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #165 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #164 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "An error occurred on line 136 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : 'NoneType' object is not subscriptable\n",
      "\t...Error making chatbot request\n",
      "**Text #163 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #163 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #162 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #162 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #161 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : The server is overloaded or not ready yet.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #161 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 169_prompt00...\n",
      "Processing 169_prompt01...\n",
      "Processing 168_prompt00...\n",
      "Processing 168_prompt01...\n",
      "Processing 167_prompt00...\n",
      "Processing 167_prompt01...\n",
      "Processing 166_prompt00...\n",
      "Processing 166_prompt01...\n",
      "Processing 165_prompt00...\n",
      "Processing 165_prompt01...\n",
      "Processing 163_prompt00...\n",
      "Processing 163_prompt01...\n",
      "Processing 162_prompt00...\n",
      "Processing 162_prompt01...\n",
      "Processing 161_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 161_prompt00: 'summary'\n",
      "Processing 161_prompt01...\n",
      "Original summaries DataFrame shape: (15, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 15 rows to the database...\n",
      "\tReference #169: Sleep duration positively impacts athletic performance\n",
      "\tReference #169: Improve your athletic performance with better sleep!\n",
      "\tReference #168: Fascinating Study on Muscle Soreness and Recovery\n",
      "\tReference #168: Fascinating Study on Aging and Muscle Soreness\n",
      "\tReference #167: Discover the Surprising Link Between Sleep and Blood Sugar\n",
      "\tReference #167: New research shows how sleep affects blood sugar levels\n",
      "\tReference #166: Exciting research on muscle performance\n",
      "\tReference #166: Faster muscle recruitment and increased force observed in resistance-trained individuals\n",
      "\tReference #165: NSAIDS can impact muscle growth and strength gains in young adults\n",
      "\tReference #165: Surprising findings on the effects of NSAIDs on muscle growth\n",
      "\tReference #163: Exercise doesn't always lead to weight loss as expected\n",
      "\tReference #163: New study reveals why exercise may not always lead to weight loss\n",
      "\tReference #162: Mind-Muscle Connection: How Your Focus Affects Muscle Growth\n",
      "\tReference #162: Attentional focus affects muscle growth in a surprising way\n",
      "\tReference #161: New research reveals fascinating changes in our metabolism throughout life\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-19 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 4 from `2023-07-14 full` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
      "\n",
      "Flagged: \n",
      "\tArticle title: Exploring participants perspectives on adverse events due to resistance training: a qualitative study\n",
      "\tPubMed title: Exploring participants' perspectives on adverse events due to resistance training: a qualitative study.\n",
      "\n",
      "Adding 14 rows to the database...\n",
      "\tA systematic review examining associations between physical activity, sedentary behaviour, and sleep duration with quality of life in older adults aged 65 years and above\n",
      "\tAdvertising expenditures across media on food and beverage products heavily advertised on youth-appealing television stations in Canada\n",
      "\tCalcaneal tendon stiffness is not associated with dynamic time-dependent contractile output\n",
      "\tCreatine supplementation combined with blood flow restriction training enhances muscle thickness and performance: a randomized, placebo-controlled, and double-blind study\n",
      "\tEconomic burden of low muscle strength in Canadian adults\n",
      "\tExploring participants perspectives on adverse events due to resistance training: a qualitative study\n",
      "\tFast food consumption in adults living in Canada: alternative measurement methods, consumption choices, and correlates\n",
      "\tLoneliness and resilience are associated with nutrition risk after the first wave of COVID-19 in community-dwelling older Canadians\n",
      "\tLow vitamin K status in adults with cystic fibrosis is associated with reduced body mass index, insulin secretion, and increased pseudomonal colonization\n",
      "\tMilk protein ingestion does not enhance recovery from muscle-damaging resistance exercise in untrained males and females: a randomized controlled trial\n",
      "\tPrevalence of sarcopenia indicators and sub-optimal protein intake among elective total joint replacement patients\n",
      "\tSex differences and indications of metabolic compensation in within-day energy balance in elite Division 1 swimmers\n",
      "\tSimilar body composition, muscle size, and strength adaptations to resistance training in lacto-ovo-vegetarians and non-vegetarians\n",
      "\tThe influence of training status and parasympathetic blockade on the cardiac rate, rhythm, and functional response to autonomic stress\n",
      "New records added successfully (if applicable)!\n",
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 14\n",
      "**Text #187 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #187 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #186 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #186 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #185 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #185 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : The server is overloaded or not ready yet.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #184 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #184 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #183 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #183 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #182 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #182 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #181 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #181 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #180 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #180 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #179 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #179 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #178 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #178 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #177 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #177 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #176 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #176 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #175 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #175 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #174 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 16564 tokens (15564 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #174 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 16564 tokens (15564 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 187_prompt00...\n",
      "Processing 187_prompt01...\n",
      "Processing 186_prompt00...\n",
      "Processing 186_prompt01...\n",
      "Processing 185_prompt00...\n",
      "Processing 185_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 185_prompt01: 'summary'\n",
      "Processing 184_prompt00...\n",
      "Processing 184_prompt01...\n",
      "Processing 183_prompt00...\n",
      "Processing 183_prompt01...\n",
      "Processing 182_prompt00...\n",
      "Processing 182_prompt01...\n",
      "Processing 181_prompt00...\n",
      "Processing 181_prompt01...\n",
      "Processing 180_prompt00...\n",
      "Processing 180_prompt01...\n",
      "Processing 179_prompt00...\n",
      "Processing 179_prompt01...\n",
      "Processing 178_prompt00...\n",
      "Processing 178_prompt01...\n",
      "Processing 177_prompt00...\n",
      "Processing 177_prompt01...\n",
      "Processing 176_prompt00...\n",
      "Processing 176_prompt01...\n",
      "Processing 175_prompt00...\n",
      "Processing 175_prompt01...\n",
      "Processing 174_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 174_prompt00: 'summary'\n",
      "Processing 174_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 174_prompt01: 'summary'\n",
      "Error converting summary column to JSON: Expecting ',' delimiter: line 4 column 1 (char 984); will do row by row\n",
      "Error converting summary 38 to JSON: Expecting ',' delimiter: line 4 column 1 (char 984)\n",
      "Error converting summary 40 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Original summaries DataFrame shape: (50, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 50 rows to the database...\n",
      "\tReference #187: Interesting research on the effects of endurance training on the heart\n",
      "\tReference #187: The Impact of Vagal Tone on Heart Health\n",
      "\tReference #187: New research shows endurance-trained athletes are more susceptible to cardiac arrhythmias\n",
      "\tReference #187: Interesting findings on heart rhythm in endurance-trained athletes\n",
      "\tReference #186: New research shows that a meat-free diet doesn't hinder muscle growth!\n",
      "\tReference #186: New Study Shows Vegetarian Diet Doesn't Hinder Muscle Growth\n",
      "\tReference #186: New Research: Plant-based Diet Doesn't Impair Strength Training Results\n",
      "\tReference #186: Exciting new research on strength training and vegetarian diets!\n",
      "\tReference #185: New research shows that male athletes have a better energy balance than females\n",
      "\tReference #185: New research reveals how elite athletes can struggle to maintain energy balance\n",
      "\tReference #184: New research reveals the importance of protein intake for muscle health in older adults\n",
      "\tReference #184: New research reveals the importance of protein intake for muscle health\n",
      "\tReference #184: Fascinating research on muscle loss and protein intake!\n",
      "\tReference #184: New research on muscle loss in older adults\n",
      "\tReference #183: Milk protein does not help with muscle recovery after exercise, study finds\n",
      "\tReference #183: New research on milk protein and muscle recovery\n",
      "\tReference #183: New Study: Milk Protein Not Effective for Muscle Recovery\n",
      "\tReference #183: New research on milk protein and exercise recovery\n",
      "\tReference #182: New research reveals the importance of vitamin K for people with cystic fibrosis\n",
      "\tReference #182: Fascinating Research on Vitamin K and Insulin Secretion in Cystic Fibrosis\n",
      "\tReference #182: New research on cystic fibrosis reveals potential link between vitamin K deficiency and insulin secretion\n",
      "\tReference #182: New research on cystic fibrosis and vitamin K deficiency\n",
      "\tReference #181: New research shows loneliness increases nutrition risk in older adults\n",
      "\tReference #181: Loneliness linked to higher nutrition risk in older adults\n",
      "\tReference #181: Loneliness linked to higher nutrition risk in older adults during the pandemic\n",
      "\tReference #181: New research shows that loneliness increases nutrition risk in older adults\n",
      "\tReference #180: Discover the Impact of Fast Food on Canadians' Diets\n",
      "\tReference #180: New research reveals the popularity of fast food in Canada\n",
      "\tReference #180: New study finds that Canadians are consuming fast food twice a week on average\n",
      "\tReference #180: New research shows that fast food consumption is common among Canadians\n",
      "\tReference #179: New Research Reveals the Importance of Exercise Safety\n",
      "\tReference #179: Discover the Importance of Reporting Adverse Events in Resistance Training\n",
      "\tReference #179: Research shows the importance of accurate reporting of adverse events during resistance training\n",
      "\tReference #179: Discover the risks of resistance training and why accurate reporting is crucial\n",
      "\tReference #178: Discover the Economic Costs of Low Muscle Strength\n",
      "\tReference #178: Muscle strength linked to billions in healthcare costs\n",
      "\tReference #178: Did you know low muscle strength costs billions of dollars?\n",
      "\tReference #178: New Research: Low Muscle Strength Costs $3.0 Billion in Canada\n",
      "\tReference #177: Exciting new research on muscle strength and hypertrophy!\n",
      "\tReference #177: Exciting new research on muscle growth and strength training!\n",
      "\tReference #177: Exciting new research on muscle growth and strength!\n",
      "\tReference #177: Exciting new research on muscle strength and hypertrophy\n",
      "\tReference #176: New Research: Tendon Stiffness and Explosive Movements\n",
      "\tReference #176: Fascinating study on muscle and tendon function\n",
      "\tReference #176: New Study: Tendon Stiffness and Muscle Performance\n",
      "\tReference #176: The Influence of Tendon Stiffness on Muscle Performance\n",
      "\tReference #175: Shocking Research on Unhealthy Food Advertising to Adolescents\n",
      "\tReference #175: Shockingly High Advertising Expenditures on Unhealthy Food for Adolescents\n",
      "\tReference #175: Shocking research: Unhealthy food ads targeted at teens!\n",
      "\tReference #175: Shocking Stats on Unhealthy Food Advertising\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\tA systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care\n",
      "\tDietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity\n",
      "\tEffects of exercise timing on metabolic health\n",
      "\tThe burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review\n",
      "New records added successfully (if applicable)!\n",
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 4\n",
      "**Text #191 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 191_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt00: 'summary'\n",
      "Processing 191_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt01: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Original summaries DataFrame shape: (4, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 4 rows to the database...\n",
      "\tReference #190: Time of day exercise can impact metabolism, says research\n",
      "\tReference #190: New research shows that the timing of exercise can affect your health\n",
      "\tReference #190: Timing of exercise can impact metabolic health\n",
      "\tReference #190: Fascinating new research on the timing of exercise and metabolic health\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 6: use the correct articles from the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, limit, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).order_by(order_by).limit(limit).all()\n",
    "        return result\n",
    "        # return pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        # return pd.Series({column.name: getattr(row, column.name) for column in row.__table__.columns})\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    # sources_df = session.query(Sources).filter_by(\n",
    "    #     # title=input_df['title'].tolist()[0],\n",
    "    #     # section=input_df['section'].tolist()[0],\n",
    "    #     # title=input_df.loc[0, 'title'],\n",
    "    #     # section=input_df.loc[0, 'section'],\n",
    "    # # ).order_by(order_by).limit(limit).all()\n",
    "\n",
    "    # ).order_by(order_by).limit(limit).all()\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    sources_df = get_from_queue(input_df=text_df, limit=article_limit, order_by='id', order='ASC')\n",
    "    return sources_df\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 3: Get the new sources for summarization\n",
    "    # sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [<db_orm.Sources object at 0x000001DE8347C7D0>]\n",
       "1    [<db_orm.Sources object at 0x000001DE8347FB50>]\n",
       "2    [<db_orm.Sources object at 0x000001DE8347F610>]\n",
       "3    [<db_orm.Sources object at 0x000001DE8347D3D0>]\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           188\n",
       "title          A systematic review of patient barriers and fa...\n",
       "text           Despite increasing awareness of the consequenc...\n",
       "abstract       Numerous barriers are experienced by people wi...\n",
       "publication    Obesity reviews : an official journal of the I...\n",
       "authors        Maxim de Jong, N&#xfa;ria Jansen, Marienke van...\n",
       "year                                                        2023\n",
       "month                                                        Aug\n",
       "pub_volume                                                    24\n",
       "pub_issue                                                      8\n",
       "start_page                                                e13571\n",
       "end_page                                                        \n",
       "doi                                            10.1111/obr.13571\n",
       "section                                               discussion\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = qna_dict.loc[0][0]\n",
    "pd.Series({column.name: getattr(row, column.name) for column in row.__table__.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                            32\n",
      "title          A systematic review of patient barriers and fa...\n",
      "text           Despite increasing awareness of the consequenc...\n",
      "abstract       Numerous barriers are experienced by people wi...\n",
      "publication    Obesity reviews : an official journal of the I...\n",
      "authors        Maxim de Jong, N&#xfa;ria Jansen, Marienke van...\n",
      "year                                                        2023\n",
      "month                                                        Aug\n",
      "pub_volume                                                    24\n",
      "pub_issue                                                      8\n",
      "start_page                                                e13571\n",
      "end_page                                                        \n",
      "doi                                            10.1111/obr.13571\n",
      "section                                                      NaN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index, row in enumerate(qna_dict[1]):\n",
    "    print(pd.Series({column.name: getattr(row, column.name) for column in row.__table__.columns}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, limit, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).order_by(order_by).limit(1).all()[0]\n",
    "        # return result\n",
    "        return pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        # return pd.Series({column.name: getattr(row, column.name) for column in row.__table__.columns})\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    # sources_df = session.query(Sources).filter_by(\n",
    "    #     # title=input_df['title'].tolist()[0],\n",
    "    #     # section=input_df['section'].tolist()[0],\n",
    "    #     # title=input_df.loc[0, 'title'],\n",
    "    #     # section=input_df.loc[0, 'section'],\n",
    "    # # ).order_by(order_by).limit(limit).all()\n",
    "\n",
    "    # ).order_by(order_by).limit(limit).all()\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    sources_df = get_from_queue(input_df=text_df, limit=article_limit, order_by='id', order='ASC')\n",
    "    return sources_df\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 3: Get the new sources for summarization\n",
    "    # sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "      <td>A systematic review of patient barriers and fa...</td>\n",
       "      <td>Despite increasing awareness of the consequenc...</td>\n",
       "      <td>Numerous barriers are experienced by people wi...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Maxim de Jong, N&amp;#xfa;ria Jansen, Marienke van...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Aug</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>e13571</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13571</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>Dietary pulses as a means to improve the gut m...</td>\n",
       "      <td>According to the World Health Organization, th...</td>\n",
       "      <td>A dysbiotic intestinal microbiome has been lin...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Hannah St John, &amp;#xc9;ric Doucet, Krista A Power</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13598</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13598</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>The increasing prevalence of metabolic syndrom...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Jos&amp;#xe9; Ignacio Mart&amp;#xed;nez-Montoro, Javie...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13599</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13599</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>The burden of type 2 diabetes mellitus in stat...</td>\n",
       "      <td>Type 2 diabetes mellitus (T2D) is a complex me...</td>\n",
       "      <td>Type 2 diabetes mellitus (T2D) is a highly pre...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Carlos Alexandre Soares Andrade, Balqees Shahi...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13593</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13593</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "0  188  A systematic review of patient barriers and fa...   \n",
       "1  189  Dietary pulses as a means to improve the gut m...   \n",
       "2  190     Effects of exercise timing on metabolic health   \n",
       "3  191  The burden of type 2 diabetes mellitus in stat...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Despite increasing awareness of the consequenc...   \n",
       "1  According to the World Health Organization, th...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  Type 2 diabetes mellitus (T2D) is a complex me...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Numerous barriers are experienced by people wi...   \n",
       "1  A dysbiotic intestinal microbiome has been lin...   \n",
       "2  The increasing prevalence of metabolic syndrom...   \n",
       "3  Type 2 diabetes mellitus (T2D) is a highly pre...   \n",
       "\n",
       "                                         publication  \\\n",
       "0  Obesity reviews : an official journal of the I...   \n",
       "1  Obesity reviews : an official journal of the I...   \n",
       "2  Obesity reviews : an official journal of the I...   \n",
       "3  Obesity reviews : an official journal of the I...   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Maxim de Jong, N&#xfa;ria Jansen, Marienke van...  2023   Aug         24   \n",
       "1   Hannah St John, &#xc9;ric Doucet, Krista A Power  2023                    \n",
       "2  Jos&#xe9; Ignacio Mart&#xed;nez-Montoro, Javie...  2023                    \n",
       "3  Carlos Alexandre Soares Andrade, Balqees Shahi...  2023                    \n",
       "\n",
       "  pub_issue start_page end_page                doi     section  \n",
       "0         8     e13571           10.1111/obr.13571  discussion  \n",
       "1               e13598           10.1111/obr.13598  discussion  \n",
       "2               e13599           10.1111/obr.13599  discussion  \n",
       "3               e13593           10.1111/obr.13593  discussion  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    return sources_df\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 3: Get the new sources for summarization\n",
    "    # sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # # ##### \n",
    "    # # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    # chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "    #     sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "    #     simplify_task, simplify_audience, format_task,\n",
    "    #     chatbot_dict, temperature=temperature,\n",
    "    #     system_role=system_role, model=model, max_tokens=1000,\n",
    "    #     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    #     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    #     )\n",
    "    # #########\n",
    "    # # Step 5: Create summaries table\n",
    "    # qna_dict = create_summaries_df(\n",
    "    #     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    #     )\n",
    "\n",
    "    # ##########\n",
    "    # # Step 5: Add results to summaries and prompts table \n",
    "    # bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "      <td>A systematic review of patient barriers and fa...</td>\n",
       "      <td>Despite increasing awareness of the consequenc...</td>\n",
       "      <td>Numerous barriers are experienced by people wi...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Maxim de Jong, N&amp;#xfa;ria Jansen, Marienke van...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Aug</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>e13571</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13571</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>Dietary pulses as a means to improve the gut m...</td>\n",
       "      <td>According to the World Health Organization, th...</td>\n",
       "      <td>A dysbiotic intestinal microbiome has been lin...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Hannah St John, &amp;#xc9;ric Doucet, Krista A Power</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13598</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13598</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>The increasing prevalence of metabolic syndrom...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Jos&amp;#xe9; Ignacio Mart&amp;#xed;nez-Montoro, Javie...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13599</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13599</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>The burden of type 2 diabetes mellitus in stat...</td>\n",
       "      <td>Type 2 diabetes mellitus (T2D) is a complex me...</td>\n",
       "      <td>Type 2 diabetes mellitus (T2D) is a highly pre...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Carlos Alexandre Soares Andrade, Balqees Shahi...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13593</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13593</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "0  188  A systematic review of patient barriers and fa...   \n",
       "1  189  Dietary pulses as a means to improve the gut m...   \n",
       "2  190     Effects of exercise timing on metabolic health   \n",
       "3  191  The burden of type 2 diabetes mellitus in stat...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Despite increasing awareness of the consequenc...   \n",
       "1  According to the World Health Organization, th...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  Type 2 diabetes mellitus (T2D) is a complex me...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Numerous barriers are experienced by people wi...   \n",
       "1  A dysbiotic intestinal microbiome has been lin...   \n",
       "2  The increasing prevalence of metabolic syndrom...   \n",
       "3  Type 2 diabetes mellitus (T2D) is a highly pre...   \n",
       "\n",
       "                                         publication  \\\n",
       "0  Obesity reviews : an official journal of the I...   \n",
       "1  Obesity reviews : an official journal of the I...   \n",
       "2  Obesity reviews : an official journal of the I...   \n",
       "3  Obesity reviews : an official journal of the I...   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Maxim de Jong, N&#xfa;ria Jansen, Marienke van...  2023   Aug         24   \n",
       "1   Hannah St John, &#xc9;ric Doucet, Krista A Power  2023                    \n",
       "2  Jos&#xe9; Ignacio Mart&#xed;nez-Montoro, Javie...  2023                    \n",
       "3  Carlos Alexandre Soares Andrade, Balqees Shahi...  2023                    \n",
       "\n",
       "  pub_issue start_page end_page                doi     section  \n",
       "0         8     e13571           10.1111/obr.13571  discussion  \n",
       "1               e13598           10.1111/obr.13598  discussion  \n",
       "2               e13599           10.1111/obr.13599  discussion  \n",
       "3               e13593           10.1111/obr.13593  discussion  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n",
      "Query: SELECT * from sources ORDER BY id DESC LIMIT 4\n",
      "**Text #191 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 191_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt00: 'summary'\n",
      "Processing 191_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt01: 'summary'\n",
      "Processing 191_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt02: 'summary'\n",
      "Processing 191_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt03: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Processing 190_prompt02...\n",
      "Processing 190_prompt03...\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 189_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt02: 'summary'\n",
      "Processing 189_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt03: 'summary'\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Processing 188_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt02: 'summary'\n",
      "Processing 188_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt03: 'summary'\n",
      "Original summaries DataFrame shape: (8, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 8 rows to the database...\n",
      "\tReference #190: Discover the Best Time to Exercise for a Healthier You!\n",
      "\tReference #190: Amazing Health Research Reveals Surprising Results!\n",
      "\tReference #190: Exciting Research on the Timing of Exercise and Metabolic Health\n",
      "\tReference #190: Timing your exercise can improve metabolic health\n",
      "\tReference #190: Discover the Best Time to Exercise for Optimal Health!\n",
      "\tReference #190: Exciting new health research: Exercise timing can shape your metabolism!\n",
      "\tReference #190: Exercise timing can affect your metabolic health\n",
      "\tReference #190: Fascinating research on exercise timing and metabolic health\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_table(table='sources', limit=len(text_df), order='DESC') # db_orm.py\n",
    "\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-21 08:23:46.152933-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>In a recent study, researchers found that exer...</td>\n",
       "      <td>Discover the Best Time to Exercise for a Healt...</td>\n",
       "      <td>Did you know that the time you exercise can im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-21 08:23:46.152933-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey, I just read some fascinating health resea...</td>\n",
       "      <td>Amazing Health Research Reveals Surprising Res...</td>\n",
       "      <td>Hey there! I just read this super cool study t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-21 08:23:53.324742-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I just came across some fascinating...</td>\n",
       "      <td>Exciting Research on the Timing of Exercise an...</td>\n",
       "      <td>Check out this cool research I found! They dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-21 08:23:53.324742-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>A recent study found that the timing of exerci...</td>\n",
       "      <td>Timing your exercise can improve metabolic health</td>\n",
       "      <td>Did you know that the time of day you exercise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-21 08:24:00.558030-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read this super interesting resear...</td>\n",
       "      <td>Discover the Best Time to Exercise for Optimal...</td>\n",
       "      <td>Hey! Did you know that when you exercise can m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-21 08:24:00.558030-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read this amazing health research ...</td>\n",
       "      <td>Exciting new health research: Exercise timing ...</td>\n",
       "      <td>Hey! I just read this awesome study about how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-21 08:24:10.097888-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read a super interesting research ...</td>\n",
       "      <td>Exercise timing can affect your metabolic health</td>\n",
       "      <td>Hey! Just found out that the time you exercise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-21 08:24:10.097888-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I came across this interesting research a...</td>\n",
       "      <td>Fascinating research on exercise timing and me...</td>\n",
       "      <td>Hey! I found this cool research on how the tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-21 08:23:46.152933-07:00           190   \n",
       "1  2023-07-21 08:23:46.152933-07:00           190   \n",
       "2  2023-07-21 08:23:53.324742-07:00           190   \n",
       "3  2023-07-21 08:23:53.324742-07:00           190   \n",
       "4  2023-07-21 08:24:00.558030-07:00           190   \n",
       "5  2023-07-21 08:24:00.558030-07:00           190   \n",
       "6  2023-07-21 08:24:10.097888-07:00           190   \n",
       "7  2023-07-21 08:24:10.097888-07:00           190   \n",
       "\n",
       "                                    article_title  choice  \\\n",
       "0  Effects of exercise timing on metabolic health       1   \n",
       "1  Effects of exercise timing on metabolic health       2   \n",
       "2  Effects of exercise timing on metabolic health       1   \n",
       "3  Effects of exercise timing on metabolic health       2   \n",
       "4  Effects of exercise timing on metabolic health       1   \n",
       "5  Effects of exercise timing on metabolic health       2   \n",
       "6  Effects of exercise timing on metabolic health       1   \n",
       "7  Effects of exercise timing on metabolic health       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  In the last decades, the dramatic increase in ...   \n",
       "1  In the last decades, the dramatic increase in ...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  In the last decades, the dramatic increase in ...   \n",
       "4  In the last decades, the dramatic increase in ...   \n",
       "5  In the last decades, the dramatic increase in ...   \n",
       "6  In the last decades, the dramatic increase in ...   \n",
       "7  In the last decades, the dramatic increase in ...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "3            1  In the summary, cover the following informatio...   \n",
       "4            1  In the summary, cover the following informatio...   \n",
       "5            1  In the summary, cover the following informatio...   \n",
       "6            1  In the summary, cover the following informatio...   \n",
       "7            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "3  Write a casual text message to your friend abo...   \n",
       "4  Write a casual text message to your friend abo...   \n",
       "5  Write a casual text message to your friend abo...   \n",
       "6  Write a casual text message to your friend abo...   \n",
       "7  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "3  Once you have written your text message:     \\...   \n",
       "4  Once you have written your text message:     \\...   \n",
       "5  Once you have written your text message:     \\...   \n",
       "6  Once you have written your text message:     \\...   \n",
       "7  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2  3. Make a more concise and simple version of t...   \n",
       "3  3. Make a more concise and simple version of t...   \n",
       "4  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "5  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "6  3. Make a more concise and simple version of t...   \n",
       "7  3. Make a more concise and simple version of t...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "3  people who like fun facts but don't know much ...   \n",
       "4  people who like fun facts but don't know much ...   \n",
       "5  people who like fun facts but don't know much ...   \n",
       "6  people who like fun facts but don't know much ...   \n",
       "7  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "3  4. Return your final response in a JSON format...   \n",
       "4  4. Return your final response in a JSON format...   \n",
       "5  4. Return your final response in a JSON format...   \n",
       "6  4. Return your final response in a JSON format...   \n",
       "7  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                 folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "3  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "4  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "5  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "6  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "7  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "\n",
       "                                             summary  \\\n",
       "0  In a recent study, researchers found that exer...   \n",
       "1  Hey, I just read some fascinating health resea...   \n",
       "2  Hey there! I just came across some fascinating...   \n",
       "3  A recent study found that the timing of exerci...   \n",
       "4  Hey! I just read this super interesting resear...   \n",
       "5  Hey! I just read this amazing health research ...   \n",
       "6  Hey! I just read a super interesting research ...   \n",
       "7  Hey! I came across this interesting research a...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Discover the Best Time to Exercise for a Healt...   \n",
       "1  Amazing Health Research Reveals Surprising Res...   \n",
       "2  Exciting Research on the Timing of Exercise an...   \n",
       "3  Timing your exercise can improve metabolic health   \n",
       "4  Discover the Best Time to Exercise for Optimal...   \n",
       "5  Exciting new health research: Exercise timing ...   \n",
       "6   Exercise timing can affect your metabolic health   \n",
       "7  Fascinating research on exercise timing and me...   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Did you know that the time you exercise can im...  \n",
       "1  Hey there! I just read this super cool study t...  \n",
       "2  Check out this cool research I found! They dis...  \n",
       "3  Did you know that the time of day you exercise...  \n",
       "4  Hey! Did you know that when you exercise can m...  \n",
       "5  Hey! I just read this awesome study about how ...  \n",
       "6  Hey! Just found out that the time you exercise...  \n",
       "7  Hey! I found this cool research on how the tim...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #188 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #191 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Processing 188_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt02: 'summary'\n",
      "Processing 188_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt03: 'summary'\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 189_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt02: 'summary'\n",
      "Processing 189_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt03: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Processing 190_prompt02...\n",
      "Processing 190_prompt03...\n",
      "Processing 191_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt00: 'summary'\n",
      "Processing 191_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt01: 'summary'\n",
      "Processing 191_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt02: 'summary'\n",
      "Processing 191_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt03: 'summary'\n",
      "Original summaries DataFrame shape: (8, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 8 rows to the database...\n",
      "\tReference #190: New Research Reveals Surprising Health Benefits of Exercise Timing!\n",
      "\tReference #190: Discover the Best Time to Exercise for a Healthier You!\n",
      "\tReference #190: Exercise timing affects metabolic health: Here's what the research says\n",
      "\tReference #190: New research shows that afternoon exercise may be more effective for improving metabolic health\n",
      "\tReference #190: Exciting Health Research: Time of Exercise Matters!\n",
      "\tReference #190: The Best Time to Exercise for Health and Weight Loss\n",
      "\tReference #190: New research reveals the best time of day to exercise for your health!\n",
      "\tReference #190: Time of day may affect the effectiveness of exercise for metabolic health\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-21 08:26:51.877950-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read some really interesting resea...</td>\n",
       "      <td>New Research Reveals Surprising Health Benefit...</td>\n",
       "      <td>Hey, guess what? I just found out that the tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-21 08:26:51.877950-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just came across some interesting resea...</td>\n",
       "      <td>Discover the Best Time to Exercise for a Healt...</td>\n",
       "      <td>Hey! Did you know that the time you exercise c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-21 08:27:01.448126-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just came across some interesting resea...</td>\n",
       "      <td>Exercise timing affects metabolic health: Here...</td>\n",
       "      <td>Just found some cool research on exercise timi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-21 08:27:01.448126-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>In recent health research, it was found that e...</td>\n",
       "      <td>New research shows that afternoon exercise may...</td>\n",
       "      <td>Did you know that exercising in the afternoon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-21 08:27:07.660828-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read an interesting research artic...</td>\n",
       "      <td>Exciting Health Research: Time of Exercise Mat...</td>\n",
       "      <td>Hey there! I just came across some really cool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-21 08:27:07.660828-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Did you know that the time of day you exercise...</td>\n",
       "      <td>The Best Time to Exercise for Health and Weigh...</td>\n",
       "      <td>Hey, did you know that the time you exercise c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-21 08:27:16.693273-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read about an interesting research...</td>\n",
       "      <td>New research reveals the best time of day to e...</td>\n",
       "      <td>Hey! Did you know that the time you exercise c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-21 08:27:16.693273-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read an interesting research artic...</td>\n",
       "      <td>Time of day may affect the effectiveness of ex...</td>\n",
       "      <td>Did you know that the time of day you exercise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-21 08:26:51.877950-07:00           190   \n",
       "1  2023-07-21 08:26:51.877950-07:00           190   \n",
       "2  2023-07-21 08:27:01.448126-07:00           190   \n",
       "3  2023-07-21 08:27:01.448126-07:00           190   \n",
       "4  2023-07-21 08:27:07.660828-07:00           190   \n",
       "5  2023-07-21 08:27:07.660828-07:00           190   \n",
       "6  2023-07-21 08:27:16.693273-07:00           190   \n",
       "7  2023-07-21 08:27:16.693273-07:00           190   \n",
       "\n",
       "                                    article_title  choice  \\\n",
       "0  Effects of exercise timing on metabolic health       1   \n",
       "1  Effects of exercise timing on metabolic health       2   \n",
       "2  Effects of exercise timing on metabolic health       1   \n",
       "3  Effects of exercise timing on metabolic health       2   \n",
       "4  Effects of exercise timing on metabolic health       1   \n",
       "5  Effects of exercise timing on metabolic health       2   \n",
       "6  Effects of exercise timing on metabolic health       1   \n",
       "7  Effects of exercise timing on metabolic health       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  In the last decades, the dramatic increase in ...   \n",
       "1  In the last decades, the dramatic increase in ...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  In the last decades, the dramatic increase in ...   \n",
       "4  In the last decades, the dramatic increase in ...   \n",
       "5  In the last decades, the dramatic increase in ...   \n",
       "6  In the last decades, the dramatic increase in ...   \n",
       "7  In the last decades, the dramatic increase in ...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "3            1  In the summary, cover the following informatio...   \n",
       "4            1  In the summary, cover the following informatio...   \n",
       "5            1  In the summary, cover the following informatio...   \n",
       "6            1  In the summary, cover the following informatio...   \n",
       "7            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "3  Write a casual text message to your friend abo...   \n",
       "4  Write a casual text message to your friend abo...   \n",
       "5  Write a casual text message to your friend abo...   \n",
       "6  Write a casual text message to your friend abo...   \n",
       "7  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "3  Once you have written your text message:     \\...   \n",
       "4  Once you have written your text message:     \\...   \n",
       "5  Once you have written your text message:     \\...   \n",
       "6  Once you have written your text message:     \\...   \n",
       "7  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2  3. Make a more concise and simple version of t...   \n",
       "3  3. Make a more concise and simple version of t...   \n",
       "4  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "5  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "6  3. Make a more concise and simple version of t...   \n",
       "7  3. Make a more concise and simple version of t...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "3  people who like fun facts but don't know much ...   \n",
       "4  people who like fun facts but don't know much ...   \n",
       "5  people who like fun facts but don't know much ...   \n",
       "6  people who like fun facts but don't know much ...   \n",
       "7  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "3  4. Return your final response in a JSON format...   \n",
       "4  4. Return your final response in a JSON format...   \n",
       "5  4. Return your final response in a JSON format...   \n",
       "6  4. Return your final response in a JSON format...   \n",
       "7  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                 folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "3  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "4  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "5  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "6  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "7  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hey! I just read some really interesting resea...   \n",
       "1  Hey! I just came across some interesting resea...   \n",
       "2  Hey! I just came across some interesting resea...   \n",
       "3  In recent health research, it was found that e...   \n",
       "4  Hey! I just read an interesting research artic...   \n",
       "5  Did you know that the time of day you exercise...   \n",
       "6  Hey! I just read about an interesting research...   \n",
       "7  Hey! I just read an interesting research artic...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  New Research Reveals Surprising Health Benefit...   \n",
       "1  Discover the Best Time to Exercise for a Healt...   \n",
       "2  Exercise timing affects metabolic health: Here...   \n",
       "3  New research shows that afternoon exercise may...   \n",
       "4  Exciting Health Research: Time of Exercise Mat...   \n",
       "5  The Best Time to Exercise for Health and Weigh...   \n",
       "6  New research reveals the best time of day to e...   \n",
       "7  Time of day may affect the effectiveness of ex...   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Hey, guess what? I just found out that the tim...  \n",
       "1  Hey! Did you know that the time you exercise c...  \n",
       "2  Just found some cool research on exercise timi...  \n",
       "3  Did you know that exercising in the afternoon ...  \n",
       "4  Hey there! I just came across some really cool...  \n",
       "5  Hey, did you know that the time you exercise c...  \n",
       "6  Hey! Did you know that the time you exercise c...  \n",
       "7  Did you know that the time of day you exercise...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "    return sources_df\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "      <td>A systematic review of patient barriers and fa...</td>\n",
       "      <td>Despite increasing awareness of the consequenc...</td>\n",
       "      <td>Numerous barriers are experienced by people wi...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Maxim de Jong, N&amp;#xfa;ria Jansen, Marienke van...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Aug</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>e13571</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13571</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>Dietary pulses as a means to improve the gut m...</td>\n",
       "      <td>According to the World Health Organization, th...</td>\n",
       "      <td>A dysbiotic intestinal microbiome has been lin...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Hannah St John, &amp;#xc9;ric Doucet, Krista A Power</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13598</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13598</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>The increasing prevalence of metabolic syndrom...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Jos&amp;#xe9; Ignacio Mart&amp;#xed;nez-Montoro, Javie...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13599</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13599</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>The burden of type 2 diabetes mellitus in stat...</td>\n",
       "      <td>Type 2 diabetes mellitus (T2D) is a complex me...</td>\n",
       "      <td>Type 2 diabetes mellitus (T2D) is a highly pre...</td>\n",
       "      <td>Obesity reviews : an official journal of the I...</td>\n",
       "      <td>Carlos Alexandre Soares Andrade, Balqees Shahi...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e13593</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/obr.13593</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title  \\\n",
       "0  188  A systematic review of patient barriers and fa...   \n",
       "1  189  Dietary pulses as a means to improve the gut m...   \n",
       "2  190     Effects of exercise timing on metabolic health   \n",
       "3  191  The burden of type 2 diabetes mellitus in stat...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Despite increasing awareness of the consequenc...   \n",
       "1  According to the World Health Organization, th...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  Type 2 diabetes mellitus (T2D) is a complex me...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Numerous barriers are experienced by people wi...   \n",
       "1  A dysbiotic intestinal microbiome has been lin...   \n",
       "2  The increasing prevalence of metabolic syndrom...   \n",
       "3  Type 2 diabetes mellitus (T2D) is a highly pre...   \n",
       "\n",
       "                                         publication  \\\n",
       "0  Obesity reviews : an official journal of the I...   \n",
       "1  Obesity reviews : an official journal of the I...   \n",
       "2  Obesity reviews : an official journal of the I...   \n",
       "3  Obesity reviews : an official journal of the I...   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Maxim de Jong, N&#xfa;ria Jansen, Marienke van...  2023   Aug         24   \n",
       "1   Hannah St John, &#xc9;ric Doucet, Krista A Power  2023                    \n",
       "2  Jos&#xe9; Ignacio Mart&#xed;nez-Montoro, Javie...  2023                    \n",
       "3  Carlos Alexandre Soares Andrade, Balqees Shahi...  2023                    \n",
       "\n",
       "  pub_issue start_page end_page                doi     section  \n",
       "0         8     e13571           10.1111/obr.13571  discussion  \n",
       "1               e13598           10.1111/obr.13598  discussion  \n",
       "2               e13599           10.1111/obr.13599  discussion  \n",
       "3               e13593           10.1111/obr.13593  discussion  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #188 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24397 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17653 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #191 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17102 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Processing 188_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt02: 'summary'\n",
      "Processing 188_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt03: 'summary'\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 189_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt02: 'summary'\n",
      "Processing 189_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt03: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Processing 190_prompt02...\n",
      "Processing 190_prompt03...\n",
      "Processing 191_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt00: 'summary'\n",
      "Processing 191_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt01: 'summary'\n",
      "Processing 191_prompt02...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt02: 'summary'\n",
      "Processing 191_prompt03...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt03: 'summary'\n",
      "Original summaries DataFrame shape: (8, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 8 rows to the database...\n",
      "\tReference #190: Discover the Best Time to Exercise for a Healthier You!\n",
      "\tReference #190: New Research Reveals the Best Time to Exercise for a Healthy Metabolism\n",
      "\tReference #190: Discover the Best Time to Exercise for Optimal Health!\n",
      "\tReference #190: New research shows that timing of exercise can impact metabolic health\n",
      "\tReference #190: Fascinating Research on Exercise Timing!\n",
      "\tReference #190: New research shows the best time to exercise for your health!\n",
      "\tReference #190: Interesting findings on exercise timing and metabolic health\n",
      "\tReference #190: Timing of Exercise Can Impact Metabolic Health\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-21 08:34:33.147173-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I just read this fascinating resear...</td>\n",
       "      <td>Discover the Best Time to Exercise for a Healt...</td>\n",
       "      <td>Hey friend! Check out this cool research on wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-21 08:34:33.147173-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I just came across some interesting...</td>\n",
       "      <td>New Research Reveals the Best Time to Exercise...</td>\n",
       "      <td>Hey, guess what? I just found out that the tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-21 08:34:40.919846-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>In recent research, it has been found that the...</td>\n",
       "      <td>Discover the Best Time to Exercise for Optimal...</td>\n",
       "      <td>Did you know that the time you exercise can af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-21 08:34:40.919846-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>In the last decades, there has been a dramatic...</td>\n",
       "      <td>New research shows that timing of exercise can...</td>\n",
       "      <td>Did you know that the timing of exercise can i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-21 08:34:46.852544-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I came across some interesting rese...</td>\n",
       "      <td>Fascinating Research on Exercise Timing!</td>\n",
       "      <td>Hey! I just came across a mind-blowing study t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-21 08:34:46.852544-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I just read an interesting study ab...</td>\n",
       "      <td>New research shows the best time to exercise f...</td>\n",
       "      <td>Hey friend! I just came across some super cool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-21 08:34:54.156406-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>A recent study explored the effects of exercis...</td>\n",
       "      <td>Interesting findings on exercise timing and me...</td>\n",
       "      <td>Did you know that when you exercise can affect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-21 08:34:54.156406-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Make a more concise and simple version of t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I came across some interesting research o...</td>\n",
       "      <td>Timing of Exercise Can Impact Metabolic Health</td>\n",
       "      <td>Did you know that the time of day you exercise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-21 08:34:33.147173-07:00           190   \n",
       "1  2023-07-21 08:34:33.147173-07:00           190   \n",
       "2  2023-07-21 08:34:40.919846-07:00           190   \n",
       "3  2023-07-21 08:34:40.919846-07:00           190   \n",
       "4  2023-07-21 08:34:46.852544-07:00           190   \n",
       "5  2023-07-21 08:34:46.852544-07:00           190   \n",
       "6  2023-07-21 08:34:54.156406-07:00           190   \n",
       "7  2023-07-21 08:34:54.156406-07:00           190   \n",
       "\n",
       "                                    article_title  choice  \\\n",
       "0  Effects of exercise timing on metabolic health       1   \n",
       "1  Effects of exercise timing on metabolic health       2   \n",
       "2  Effects of exercise timing on metabolic health       1   \n",
       "3  Effects of exercise timing on metabolic health       2   \n",
       "4  Effects of exercise timing on metabolic health       1   \n",
       "5  Effects of exercise timing on metabolic health       2   \n",
       "6  Effects of exercise timing on metabolic health       1   \n",
       "7  Effects of exercise timing on metabolic health       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  In the last decades, the dramatic increase in ...   \n",
       "1  In the last decades, the dramatic increase in ...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  In the last decades, the dramatic increase in ...   \n",
       "4  In the last decades, the dramatic increase in ...   \n",
       "5  In the last decades, the dramatic increase in ...   \n",
       "6  In the last decades, the dramatic increase in ...   \n",
       "7  In the last decades, the dramatic increase in ...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "3            1  In the summary, cover the following informatio...   \n",
       "4            1  In the summary, cover the following informatio...   \n",
       "5            1  In the summary, cover the following informatio...   \n",
       "6            1  In the summary, cover the following informatio...   \n",
       "7            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "3  Write a casual text message to your friend abo...   \n",
       "4  Write a casual text message to your friend abo...   \n",
       "5  Write a casual text message to your friend abo...   \n",
       "6  Write a casual text message to your friend abo...   \n",
       "7  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "3  Once you have written your text message:     \\...   \n",
       "4  Once you have written your text message:     \\...   \n",
       "5  Once you have written your text message:     \\...   \n",
       "6  Once you have written your text message:     \\...   \n",
       "7  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2  3. Make a more concise and simple version of t...   \n",
       "3  3. Make a more concise and simple version of t...   \n",
       "4  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "5  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "6  3. Make a more concise and simple version of t...   \n",
       "7  3. Make a more concise and simple version of t...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "3  people who like fun facts but don't know much ...   \n",
       "4  people who like fun facts but don't know much ...   \n",
       "5  people who like fun facts but don't know much ...   \n",
       "6  people who like fun facts but don't know much ...   \n",
       "7  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "3  4. Return your final response in a JSON format...   \n",
       "4  4. Return your final response in a JSON format...   \n",
       "5  4. Return your final response in a JSON format...   \n",
       "6  4. Return your final response in a JSON format...   \n",
       "7  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                 folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "3  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "4  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "5  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "6  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "7  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hey there! I just read this fascinating resear...   \n",
       "1  Hey there! I just came across some interesting...   \n",
       "2  In recent research, it has been found that the...   \n",
       "3  In the last decades, there has been a dramatic...   \n",
       "4  Hey there! I came across some interesting rese...   \n",
       "5  Hey there! I just read an interesting study ab...   \n",
       "6  A recent study explored the effects of exercis...   \n",
       "7  Hey! I came across some interesting research o...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Discover the Best Time to Exercise for a Healt...   \n",
       "1  New Research Reveals the Best Time to Exercise...   \n",
       "2  Discover the Best Time to Exercise for Optimal...   \n",
       "3  New research shows that timing of exercise can...   \n",
       "4           Fascinating Research on Exercise Timing!   \n",
       "5  New research shows the best time to exercise f...   \n",
       "6  Interesting findings on exercise timing and me...   \n",
       "7     Timing of Exercise Can Impact Metabolic Health   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Hey friend! Check out this cool research on wh...  \n",
       "1  Hey, guess what? I just found out that the tim...  \n",
       "2  Did you know that the time you exercise can af...  \n",
       "3  Did you know that the timing of exercise can i...  \n",
       "4  Hey! I just came across a mind-blowing study t...  \n",
       "5  Hey friend! I just came across some super cool...  \n",
       "6  Did you know that when you exercise can affect...  \n",
       "7  Did you know that the time of day you exercise...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Hey there! I just read this fascinating research on the best time to exercise for better health. Turns out, afternoon and evening exercise might be the way to go!  The study showed that afternoon/evening exercise can help with glycemic control, blood pressure, and even lipid profile. Plus, it's especially effective for people with the evening chronotype. But here's the fun part - morning exercise is great for weight loss! So, if you want to shed those pounds, a morning workout might be the way to go. \\u200d Overall, exercise timing can have a big impact on our metabolism and well-being. Isn't that amazing? \",\n",
       "       \"Hey there! I just came across some interesting research about exercise and metabolism that I think you'll find fascinating. According to the study, the timing of exercise can have a big impact on our metabolic health. It turns out that afternoon and evening exercise may be more effective than morning exercise when it comes to improving glycemic control, blood pressure, and lipid profile. And for those looking to lose weight, morning workouts seem to have an edge. Isn't that cool? This research involved participants with different health conditions, like obesity and type 2 diabetes, and it showed some impressive results. It's a reminder that exercise is not just about what we do, but also when we do it. So, let's keep this in mind next time we plan our workout! \",\n",
       "       'In recent research, it has been found that the timing of exercise can have a significant impact on metabolic health. For example, afternoon and evening exercise may be more effective than morning exercise for improving glycemic control, blood pressure, and lipid profile. Additionally, certain exercise modalities, like high-intensity interval training (HIIT) and resistance training, may lead to different metabolic adaptations depending on the time of day. These findings suggest that when you exercise could play a crucial role in maximizing the benefits for your health.',\n",
       "       'In the last decades, there has been a dramatic increase in obesity and related metabolic complications. A recent review found that the timing of exercise can have different effects on weight loss, glycemic control, lipid profile, and blood pressure. For example, afternoon/evening exercise is more effective for glycemic control, while morning exercise is better for weight loss. These findings suggest that the timing of exercise may be an important factor to consider in improving metabolic health.',\n",
       "       \"Hey there! I came across some interesting research on exercise and its effects on our health. This study found that the timing of exercise can actually have an impact on our metabolism and overall well-being. They found that afternoon and evening exercises can be more effective than morning workouts for improving glycemic control, blood pressure, and lipid profile. Isn't that cool? They also found that morning exercise may be more beneficial for weight loss. The study involved a variety of participants, including individuals with obesity and type 2 diabetes. So, if you're looking to optimize your exercise routine, considering the time of day may be worth it! Keep in mind, everyone is different, so finding what works best for you is key. Stay healthy and keep rocking those workouts!\",\n",
       "       \"Hey there! I just read an interesting study about the best time to exercise for your health. It turns out that exercising in the afternoon or evening might be more effective for improving glycemic control, blood pressure, and lipid profile. On the other hand, morning exercise could be better for weight loss. The study also found that different types of exercise, like aerobic training or resistance training, may have different effects. Isn't that cool? So next time you hit the gym, think about the time of day that works best for you. Keep up the good work!\",\n",
       "       'A recent study explored the effects of exercise timing on metabolic health. It found that afternoon and evening exercise may be more effective than morning exercise in improving glycemic control, blood pressure, and lipid profile. The study also highlighted the role of the circadian clock in regulating these metabolic responses. While more research is needed, the findings suggest that timing of exercise could be an important factor in achieving optimal metabolic outcomes.',\n",
       "       'Hey! I came across some interesting research on the impact of exercise timing on metabolic health. The study found that exercising in the afternoon or evening can have different effects on weight loss, glycemic control, and lipid profile compared to morning exercise. The research suggests that the circadian clock and metabolic signatures imprinted by timely exercise play a role in these findings. This study included participants with overweight, type 2 diabetes, and obesity, among others. So if you want to optimize the benefits of your workout, the timing might be something to consider!'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict['summary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #188 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #191 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Processing 191_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt00: 'summary'\n",
      "Processing 191_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt01: 'summary'\n",
      "Original summaries DataFrame shape: (4, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 4 rows to the database...\n",
      "\tReference #190: Exercise Timing: The Key to Maximizing Your Metabolic Health!\n",
      "\tReference #190: Exciting Health Research Findings: Exercise Timing and Metabolic Health\n",
      "\tReference #190: Exciting new research on exercise and metabolic health!\n",
      "\tReference #190: Exciting Health Research: Exercise Timing Can Boost Your Metabolism!\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "\t** Already exists in the database: The burden of type 2 diabetes mellitus in states of the European Union and United Kingdom at the national and subnational levels: A systematic review.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #188 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #191 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #191 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17086 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Processing 191_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt00: 'summary'\n",
      "Processing 191_prompt01...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 191_prompt01: 'summary'\n",
      "Error converting summary column to JSON: Expecting ',' delimiter: line 2 column 739 (char 815); will do row by row\n",
      "Error converting summary 2 to JSON: Expecting ',' delimiter: line 2 column 739 (char 815)\n",
      "Original summaries DataFrame shape: (4, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 4 rows to the database...\n",
      "\tReference #190: Exciting new health research! Discover the best time to exercise for optimal health\n",
      "\tReference #190: Discover the Best Time to Exercise for Your Health!\n",
      "\tReference #190: Fascinating Research on Exercise Timing and Metabolic Health\n",
      "\tReference #190: Discover the Best Time to Exercise for Your Health!\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 2\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section)\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4])\n",
      "\n",
      "Adding 3 rows to the database...\n",
      "\t** Already exists in the database: A systematic review of patient barriers and facilitators for implementing lifestyle interventions targeting weight loss in primary care.\n",
      "\t** Already exists in the database: Dietary pulses as a means to improve the gut microbiome, inflammation, and appetite control in obesity.\n",
      "\t** Already exists in the database: Effects of exercise timing on metabolic health.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #188 prompt #1 of 2**\n",
      "\tText ID: 188\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #188 prompt #2 of 2**\n",
      "\tText ID: 188\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 24381 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #1 of 2**\n",
      "\tText ID: 189\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #189 prompt #2 of 2**\n",
      "\tText ID: 189\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, your messages resulted in 17637 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #190 prompt #1 of 2**\n",
      "\tText ID: 190\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #190 prompt #2 of 2**\n",
      "\tText ID: 190\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 188_prompt00...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt00: 'summary'\n",
      "Processing 188_prompt01...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 188_prompt01: 'summary'\n",
      "Processing 189_prompt00...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt00: 'summary'\n",
      "Processing 189_prompt01...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 189_prompt01: 'summary'\n",
      "Processing 190_prompt00...\n",
      "Processing 190_prompt01...\n",
      "Error converting summary column to JSON: Invalid control character at: line 2 column 188 (char 246); will do row by row\n",
      "Error converting summary 0 to JSON: Invalid control character at: line 2 column 188 (char 246)\n",
      "Error converting summary 3 to JSON: Expecting ',' delimiter: line 3 column 517 (char 1331)\n",
      "Original summaries DataFrame shape: (4, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 4 rows to the database...\n",
      "\tReference #190: Exciting Health Research - Exercise Timing\n",
      "\tReference #190: Fascinating new health research!\n",
      "\tReference #190: Discover the surprising benefits of timing your exercise!\n",
      "\tReference #190: Timing is everything: Exercise and metabolism\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full2'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 3\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-21 08:48:40.043214-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I just read some fascinating health...</td>\n",
       "      <td>Exciting Health Research - Exercise Timing</td>\n",
       "      <td>Hey there! I just read this awesome research a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-21 08:48:40.043214-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just read some interesting health resea...</td>\n",
       "      <td>Fascinating new health research!</td>\n",
       "      <td>Hey! Just read some amazing new health researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-21 08:48:46.590697-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>1</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey! I just came across some interesting resea...</td>\n",
       "      <td>Discover the surprising benefits of timing you...</td>\n",
       "      <td>Hey! Just stumbled upon this super cool info a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-21 08:48:46.590697-07:00</td>\n",
       "      <td>190</td>\n",
       "      <td>Effects of exercise timing on metabolic health</td>\n",
       "      <td>2</td>\n",
       "      <td>In the last decades, the dramatic increase in ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full2</td>\n",
       "      <td>Hey there! I just read this really interesting...</td>\n",
       "      <td>Timing is everything: Exercise and metabolism</td>\n",
       "      <td>Hey there! Did you know that when you exercise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-21 08:48:40.043214-07:00           190   \n",
       "1  2023-07-21 08:48:40.043214-07:00           190   \n",
       "2  2023-07-21 08:48:46.590697-07:00           190   \n",
       "3  2023-07-21 08:48:46.590697-07:00           190   \n",
       "\n",
       "                                    article_title  choice  \\\n",
       "0  Effects of exercise timing on metabolic health       1   \n",
       "1  Effects of exercise timing on metabolic health       2   \n",
       "2  Effects of exercise timing on metabolic health       1   \n",
       "3  Effects of exercise timing on metabolic health       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  In the last decades, the dramatic increase in ...   \n",
       "1  In the last decades, the dramatic increase in ...   \n",
       "2  In the last decades, the dramatic increase in ...   \n",
       "3  In the last decades, the dramatic increase in ...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "3            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "3  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "3  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "3  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "3  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "3  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                 folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "3  Write a casual text message to your friend abo...  text/2023-07-14 full2   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hey there! I just read some fascinating health...   \n",
       "1  Hey! I just read some interesting health resea...   \n",
       "2  Hey! I just came across some interesting resea...   \n",
       "3  Hey there! I just read this really interesting...   \n",
       "\n",
       "                                            headline  \\\n",
       "0         Exciting Health Research - Exercise Timing   \n",
       "1                   Fascinating new health research!   \n",
       "2  Discover the surprising benefits of timing you...   \n",
       "3      Timing is everything: Exercise and metabolism   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Hey there! I just read this awesome research a...  \n",
       "1  Hey! Just read some amazing new health researc...  \n",
       "2  Hey! Just stumbled upon this super cool info a...  \n",
       "3  Hey there! Did you know that when you exercise...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
      "\n",
      "Adding 2 rows to the database...\n",
      "\t** Already exists in the database: A systematic review examining associations between physical activity, sedentary behaviour, and sleep duration with quality of life in older adults aged 65 years and above.\n",
      "\t** Already exists in the database: Advertising expenditures across media on food and beverage products heavily advertised on youth-appealing television stations in Canada.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #174 prompt #1 of 2**\n",
      "\tText ID: 174\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 16548 tokens (15548 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #174 prompt #2 of 2**\n",
      "\tText ID: 174\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 16548 tokens (15548 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #175 prompt #1 of 2**\n",
      "\tText ID: 175\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #175 prompt #2 of 2**\n",
      "\tText ID: 175\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 174_prompt00...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 174_prompt00: 'summary'\n",
      "Processing 174_prompt01...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 174_prompt01: 'summary'\n",
      "Processing 175_prompt00...\n",
      "Processing 175_prompt01...\n",
      "Original summaries DataFrame shape: (4, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 4 rows to the database...\n",
      "\tReference #175: Shocking Facts About Food Advertising and its Impact on Adolescents\n",
      "\tReference #175: Shocking Facts About Junk Food Advertising\n",
      "\tReference #175: Junk food ads target teens and it's a big health concern!\n",
      "\tReference #175: Shocking stats about unhealthy food ads!\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 2\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-21 08:53:52.336866-07:00</td>\n",
       "      <td>175</td>\n",
       "      <td>Advertising expenditures across media on food ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy diets characterized by the consumpti...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! I just read some interesting research on ...</td>\n",
       "      <td>Shocking Facts About Food Advertising and its ...</td>\n",
       "      <td>Hey! Guess what? I just found out some mind-bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-21 08:53:52.336866-07:00</td>\n",
       "      <td>175</td>\n",
       "      <td>Advertising expenditures across media on food ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Unhealthy diets characterized by the consumpti...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Did you know that unhealthy diets filled with ...</td>\n",
       "      <td>Shocking Facts About Junk Food Advertising</td>\n",
       "      <td>Hey! Did you know that junk food advertising i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-21 08:54:02.486978-07:00</td>\n",
       "      <td>175</td>\n",
       "      <td>Advertising expenditures across media on food ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy diets characterized by the consumpti...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! You won't believe what I just read about ...</td>\n",
       "      <td>Junk food ads target teens and it's a big heal...</td>\n",
       "      <td>Hey there! Check out this cool study I found a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-21 08:54:02.486978-07:00</td>\n",
       "      <td>175</td>\n",
       "      <td>Advertising expenditures across media on food ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Unhealthy diets characterized by the consumpti...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! Did you know that unhealthy diets and adv...</td>\n",
       "      <td>Shocking stats about unhealthy food ads!</td>\n",
       "      <td>Hey! Did you know that unhealthy diets and adv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-21 08:53:52.336866-07:00           175   \n",
       "1  2023-07-21 08:53:52.336866-07:00           175   \n",
       "2  2023-07-21 08:54:02.486978-07:00           175   \n",
       "3  2023-07-21 08:54:02.486978-07:00           175   \n",
       "\n",
       "                                       article_title  choice  \\\n",
       "0  Advertising expenditures across media on food ...       1   \n",
       "1  Advertising expenditures across media on food ...       2   \n",
       "2  Advertising expenditures across media on food ...       1   \n",
       "3  Advertising expenditures across media on food ...       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  Unhealthy diets characterized by the consumpti...   \n",
       "1  Unhealthy diets characterized by the consumpti...   \n",
       "2  Unhealthy diets characterized by the consumpti...   \n",
       "3  Unhealthy diets characterized by the consumpti...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "3            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "3  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "3  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "3  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "3  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "3  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "3  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hey! I just read some interesting research on ...   \n",
       "1  Did you know that unhealthy diets filled with ...   \n",
       "2  Hey! You won't believe what I just read about ...   \n",
       "3  Hey! Did you know that unhealthy diets and adv...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Shocking Facts About Food Advertising and its ...   \n",
       "1         Shocking Facts About Junk Food Advertising   \n",
       "2  Junk food ads target teens and it's a big heal...   \n",
       "3           Shocking stats about unhealthy food ads!   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Hey! Guess what? I just found out some mind-bl...  \n",
       "1  Hey! Did you know that junk food advertising i...  \n",
       "2  Hey there! Check out this cool study I found a...  \n",
       "3  Hey! Did you know that unhealthy diets and adv...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
      "\n",
      "Adding 4 rows to the database...\n",
      "\t** Already exists in the database: A systematic review examining associations between physical activity, sedentary behaviour, and sleep duration with quality of life in older adults aged 65 years and above.\n",
      "\t** Already exists in the database: Advertising expenditures across media on food and beverage products heavily advertised on youth-appealing television stations in Canada.\n",
      "\t** Already exists in the database: Calcaneal tendon stiffness is not associated with dynamic time-dependent contractile output.\n",
      "\t** Already exists in the database: Creatine supplementation combined with blood flow restriction training enhances muscle thickness and performance: a randomized, placebo-controlled, and double-blind study.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #174 prompt #1 of 2**\n",
      "\tText ID: 174\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 16548 tokens (15548 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #174 prompt #2 of 2**\n",
      "\tText ID: 174\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 16385 tokens. However, you requested 16548 tokens (15548 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "**Text #175 prompt #1 of 2**\n",
      "\tText ID: 175\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #175 prompt #2 of 2**\n",
      "\tText ID: 175\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #176 prompt #1 of 2**\n",
      "\tText ID: 176\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #176 prompt #2 of 2**\n",
      "\tText ID: 176\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #177 prompt #1 of 2**\n",
      "\tText ID: 177\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #177 prompt #2 of 2**\n",
      "\tText ID: 177\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 1 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 174_prompt00...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 174_prompt00: 'summary'\n",
      "Processing 174_prompt01...\n",
      "\tAn error occurred on line 196 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 174_prompt01: 'summary'\n",
      "Processing 175_prompt00...\n",
      "Processing 175_prompt01...\n",
      "Processing 176_prompt00...\n",
      "Processing 176_prompt01...\n",
      "Processing 177_prompt00...\n",
      "Processing 177_prompt01...\n",
      "Error converting summary column to JSON: Expecting ',' delimiter: line 4 column 820 (char 1805); will do row by row\n",
      "Error converting summary 3 to JSON: Expecting ',' delimiter: line 4 column 820 (char 1805)\n",
      "Original summaries DataFrame shape: (6, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 6 rows to the database...\n",
      "\tReference #175: Shocking facts about food marketing to teenagers\n",
      "\tReference #175: Shocking Stats on Unhealthy Food Advertising to Teens\n",
      "\tReference #176: Discover the Link Between Tendon Stiffness and Muscle Performance!\n",
      "\tReference #176: Did you know? Tendon stiffness affects your muscle performance!\n",
      "\tReference #177: Amazing Research about Muscle Strength and Creatine Supplementation\n",
      "\tReference #177: Unlocking the Secrets of Muscle Growth and Strength\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 4\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-21 08:55:50.359320-07:00</td>\n",
       "      <td>175</td>\n",
       "      <td>Advertising expenditures across media on food ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy diets characterized by the consumpti...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Did you know that unhealthy diets and food mar...</td>\n",
       "      <td>Shocking facts about food marketing to teenagers</td>\n",
       "      <td>Did you know that the food industry spends bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-21 08:55:56.337733-07:00</td>\n",
       "      <td>175</td>\n",
       "      <td>Advertising expenditures across media on food ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy diets characterized by the consumpti...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey friend! I just read a fascinating research...</td>\n",
       "      <td>Shocking Stats on Unhealthy Food Advertising t...</td>\n",
       "      <td>Hey buddy! Guess what I just found out? Unheal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-21 08:56:06.644264-07:00</td>\n",
       "      <td>176</td>\n",
       "      <td>Calcaneal tendon stiffness is not associated w...</td>\n",
       "      <td>1</td>\n",
       "      <td>The rates at which muscles generate torque and...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! I just came across a super interesting re...</td>\n",
       "      <td>Discover the Link Between Tendon Stiffness and...</td>\n",
       "      <td>Hey! You know how our muscles work, right? Wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-21 08:56:13.638023-07:00</td>\n",
       "      <td>176</td>\n",
       "      <td>Calcaneal tendon stiffness is not associated w...</td>\n",
       "      <td>1</td>\n",
       "      <td>The rates at which muscles generate torque and...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! I just read a really interesting research...</td>\n",
       "      <td>Did you know? Tendon stiffness affects your mu...</td>\n",
       "      <td>Hey! Guess what? I just found out that the way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-21 08:56:21.160177-07:00</td>\n",
       "      <td>177</td>\n",
       "      <td>Creatine supplementation combined with blood f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Increases in muscular strength and hypertrophy...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! I just read this incredible research abou...</td>\n",
       "      <td>Amazing Research about Muscle Strength and Cre...</td>\n",
       "      <td>Hey there! I just came across this awesome res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-21 08:56:28.470882-07:00</td>\n",
       "      <td>177</td>\n",
       "      <td>Creatine supplementation combined with blood f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Increases in muscular strength and hypertrophy...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-07-14 full</td>\n",
       "      <td>Hey! I just read this amazing study on how to ...</td>\n",
       "      <td>Unlocking the Secrets of Muscle Growth and Str...</td>\n",
       "      <td>Hey there! I just came across this fascinating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  reference_id  \\\n",
       "0  2023-07-21 08:55:50.359320-07:00           175   \n",
       "1  2023-07-21 08:55:56.337733-07:00           175   \n",
       "2  2023-07-21 08:56:06.644264-07:00           176   \n",
       "3  2023-07-21 08:56:13.638023-07:00           176   \n",
       "4  2023-07-21 08:56:21.160177-07:00           177   \n",
       "5  2023-07-21 08:56:28.470882-07:00           177   \n",
       "\n",
       "                                       article_title  choice  \\\n",
       "0  Advertising expenditures across media on food ...       1   \n",
       "1  Advertising expenditures across media on food ...       1   \n",
       "2  Calcaneal tendon stiffness is not associated w...       1   \n",
       "3  Calcaneal tendon stiffness is not associated w...       1   \n",
       "4  Creatine supplementation combined with blood f...       1   \n",
       "5  Creatine supplementation combined with blood f...       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Unhealthy diets characterized by the consumpti...   \n",
       "1  Unhealthy diets characterized by the consumpti...   \n",
       "2  The rates at which muscles generate torque and...   \n",
       "3  The rates at which muscles generate torque and...   \n",
       "4  Increases in muscular strength and hypertrophy...   \n",
       "5  Increases in muscular strength and hypertrophy...   \n",
       "\n",
       "                                         system_role                   model  \\\n",
       "0  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "   temperature                                          prep_step  \\\n",
       "0            1  In the summary, cover the following informatio...   \n",
       "1            1  In the summary, cover the following informatio...   \n",
       "2            1  In the summary, cover the following informatio...   \n",
       "3            1  In the summary, cover the following informatio...   \n",
       "4            1  In the summary, cover the following informatio...   \n",
       "5            1  In the summary, cover the following informatio...   \n",
       "\n",
       "                                      summarize_task  \\\n",
       "0  Write a casual text message to your friend abo...   \n",
       "1  Write a casual text message to your friend abo...   \n",
       "2  Write a casual text message to your friend abo...   \n",
       "3  Write a casual text message to your friend abo...   \n",
       "4  Write a casual text message to your friend abo...   \n",
       "5  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                           edit_task  \\\n",
       "0  Once you have written your text message:     \\...   \n",
       "1  Once you have written your text message:     \\...   \n",
       "2  Once you have written your text message:     \\...   \n",
       "3  Once you have written your text message:     \\...   \n",
       "4  Once you have written your text message:     \\...   \n",
       "5  Once you have written your text message:     \\...   \n",
       "\n",
       "                                       simplify_task  \\\n",
       "0  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "3  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "4  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "5  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "\n",
       "                                   simplify_audience  \\\n",
       "0  people who like fun facts but don't know much ...   \n",
       "1  people who like fun facts but don't know much ...   \n",
       "2  people who like fun facts but don't know much ...   \n",
       "3  people who like fun facts but don't know much ...   \n",
       "4  people who like fun facts but don't know much ...   \n",
       "5  people who like fun facts but don't know much ...   \n",
       "\n",
       "                                         format_task  \\\n",
       "0  4. Return your final response in a JSON format...   \n",
       "1  4. Return your final response in a JSON format...   \n",
       "2  4. Return your final response in a JSON format...   \n",
       "3  4. Return your final response in a JSON format...   \n",
       "4  4. Return your final response in a JSON format...   \n",
       "5  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                 full_summarize_task                folder  \\\n",
       "0  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "1  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "2  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "3  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "4  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "5  Write a casual text message to your friend abo...  text/2023-07-14 full   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Did you know that unhealthy diets and food mar...   \n",
       "1  Hey friend! I just read a fascinating research...   \n",
       "2  Hey! I just came across a super interesting re...   \n",
       "3  Hey! I just read a really interesting research...   \n",
       "4  Hey! I just read this incredible research abou...   \n",
       "5  Hey! I just read this amazing study on how to ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0   Shocking facts about food marketing to teenagers   \n",
       "1  Shocking Stats on Unhealthy Food Advertising t...   \n",
       "2  Discover the Link Between Tendon Stiffness and...   \n",
       "3  Did you know? Tendon stiffness affects your mu...   \n",
       "4  Amazing Research about Muscle Strength and Cre...   \n",
       "5  Unlocking the Secrets of Muscle Growth and Str...   \n",
       "\n",
       "                                      simple_summary  \n",
       "0  Did you know that the food industry spends bil...  \n",
       "1  Hey buddy! Guess what I just found out? Unheal...  \n",
       "2  Hey! You know how our muscles work, right? Wel...  \n",
       "3  Hey! Guess what? I just found out that the way...  \n",
       "4  Hey there! I just came across this awesome res...  \n",
       "5  Hey there! I just came across this fascinating...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
