{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from silvhua import *\n",
    "# sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\src\")\n",
    "# import json\n",
    "# from pandas import json_normalize  \n",
    "# from plotly.subplots import make_subplots\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "# pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code from `2023-07-11 create references table` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "api_key = os.getenv('api_ncbi')\n",
    "\n",
    "def parse_fulltext(series, title_pattern=r'^(.*)\\n*.+'):\n",
    "    # Initialize empty lists to store the captured groups\n",
    "    titles = []\n",
    "    bodies = []\n",
    "    \n",
    "    # Iterate over each element in the series\n",
    "    for text in series:\n",
    "        # Apply the regular expression pattern\n",
    "        title_match = re.search(title_pattern, text)\n",
    "        \n",
    "        # Extract the capture groups and append them to the lists\n",
    "        if title_match:\n",
    "            titles.append(title_match.group(1))\n",
    "            body = re.sub(title_pattern, '', text)\n",
    "            bodies.append(body.strip())\n",
    "            \n",
    "        else:\n",
    "            titles.append(None)\n",
    "            bodies.append(None)\n",
    "\n",
    "        \n",
    "    \n",
    "    # Create a new DataFrame from the captured groups\n",
    "    df = pd.DataFrame({ 'title': titles, 'text': bodies })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def search_article(title, api_key, verbose=False):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    response (str): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    title_without_not = re.sub(r'not', '', title)\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': title_without_not,\n",
    "        'field': 'title',\n",
    "        'retmax': 5,\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    cleaned_title = re.sub(f'[{string.punctuation}]', '', title).lower().strip()\n",
    "\n",
    "    try:\n",
    "        id_list = data['esearchresult']['idlist']\n",
    "        if id_list:\n",
    "            result = retrieve_citation(id_list[0], api_key).decode('utf-8')\n",
    "            cleaned_result = re.sub(f'[{string.punctuation}]', '', result).lower().strip()\n",
    "            for article_id in id_list:\n",
    "                result = retrieve_citation(article_id, api_key).decode('utf-8')\n",
    "                if cleaned_title in cleaned_result:\n",
    "                    if verbose:\n",
    "                        print(f'Match found for {title}: PMID = {article_id}.')\n",
    "                    return result\n",
    "            print('Article title not found in PMIDs.')\n",
    "            print(f'\\tInput title: {title.lower().strip()}')\n",
    "            # print(f'Result title: {re.sub(r\":\", r\"\", result.lower())}')\n",
    "            return id_list        \n",
    "    except:\n",
    "        print('Article not found.')\n",
    "        return id_list \n",
    "    \n",
    "def retrieve_citation(article_id, api_key):\n",
    "    \"\"\"\n",
    "    Retrieve article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': article_id\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def extract_pubmed_details(record_string):\n",
    "    \"\"\"\n",
    "    Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "    formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "    # Extract publication year\n",
    "    publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "    publication_year = publication_year.group(1) if publication_year else ''\n",
    "    publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "    publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "    # Extract article title\n",
    "    article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "    article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "    # Extract journal title\n",
    "    journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "    journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "    # Extract journal volume\n",
    "    journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "    journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "    # Extract journal issue\n",
    "    journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "    journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "    # Extract start page\n",
    "    start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "    start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "    # Extract end page\n",
    "    end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "    end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "    # Extract ELocationID\n",
    "    doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "    doi = doi.group(1) if doi else ''\n",
    "\n",
    "    abstract = re.search(r'<AbstractText.*?>(.*?)</AbstractText>', record_string)\n",
    "    abstract = abstract.group(1) if abstract else ''\n",
    "\n",
    "    return {\n",
    "        'pubmed_title': article_title,\n",
    "        'abstract': abstract,\n",
    "        'publication': journal_title,\n",
    "        'authors': formatted_authors,\n",
    "        'year': publication_year,\n",
    "        'month': publication_month,\n",
    "        'pub_volume': journal_volume,\n",
    "        'pub_issue': journal_issue,\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page,\n",
    "        'doi': doi,\n",
    "    }\n",
    "\n",
    "\n",
    "def pubmed_details_by_title(title, api_key):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database and return article details.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    article_details (dict): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    record_string = search_article(title, api_key)\n",
    "    # return record_string\n",
    "    if record_string:\n",
    "        article_details = extract_pubmed_details(record_string)\n",
    "        return article_details\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_pubmed_details(text_df, api_key):\n",
    "    \"\"\"\n",
    "    Add the article metadata to a DataFrame containing article title and text.\n",
    "\n",
    "    Parameters:\n",
    "    - text_df (pd.DataFrame): DataFrame containing article title and text.\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added PubMed details for each article.\n",
    "    \"\"\"\n",
    "    article_details_list = []\n",
    "    for article in text_df['title']:\n",
    "        article_details = pubmed_details_by_title(article, api_key)\n",
    "        if article_details:\n",
    "            article_details_list.append(article_details)\n",
    "        else:\n",
    "            article_details_list.append({\n",
    "                'pubmed_title': article,\n",
    "                'abstract': '',\n",
    "                'publication': '',\n",
    "                'authors': '',\n",
    "                'year': '',\n",
    "                'month': '',\n",
    "                'pub_volume': '',\n",
    "                'pub_issue': '',\n",
    "                'start_page': '',\n",
    "                'end_page': '',\n",
    "                'doi': '',\n",
    "            })\n",
    "    article_details_df = pd.DataFrame(article_details_list)\n",
    "    return pd.concat([text_df.reset_index(drop=True), article_details_df], axis=1)\n",
    "\n",
    "def compare_columns(df, col1='title', col2='pubmed_title'):\n",
    "    \"\"\"\n",
    "    Compare two columns in a DataFrame. Drop the second column if the two columns are identical.\n",
    "    Otherwise, return the dataframe with new column with the comparison results, \n",
    "    where `True` indicates a mismatch.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the two columns to be compared.\n",
    "    - col1 (str): Name of the first column to be compared.\n",
    "    - col2 (str): Name of the second column to be compared.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added column containing the comparison results.\n",
    "    \"\"\"\n",
    "    # Remove punctuation and special characters\n",
    "    remove_punct = lambda text: re.sub(f'[{string.punctuation}]', '', text)\n",
    "    col1 = df[col1].apply(remove_punct)\n",
    "    col2 = df[col2].apply(remove_punct)\n",
    "\n",
    "    # Convert to lowercase and remove white spaces\n",
    "    clean_text = lambda text: text.lower().strip()\n",
    "    col1 = col1.apply(clean_text)\n",
    "    col2 = col2.apply(clean_text)\n",
    "\n",
    "    # Perform the comparison\n",
    "    comparison = col1 != col2\n",
    "    if sum(comparison) == 0:\n",
    "        df = df.drop(columns=['pubmed_title'])\n",
    "    else:\n",
    "        df['flag_title'] = comparison\n",
    "    \n",
    "    return df\n",
    "\n",
    "iteration = 11\n",
    "\n",
    "\n",
    "\n",
    "text_df = parse_fulltext(fulltext)\n",
    "text_df\n",
    "# references_df_dict = {}\n",
    "references_df_dict[iteration] = add_pubmed_details(dummy_df, api_key)\n",
    "references_df_dict[iteration] \n",
    "compare_columns(references_df_dict[iteration])\n",
    "\n",
    "# test_id = search_article(text_df.loc[4,'Title'], api_key)\n",
    "# test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "references_df_dict = {}\n",
    "\n",
    "# Create text dictionary\n",
    "folder_path = '../text/2023-06-20 discussion' # ** UPDATE REQUIRED**\n",
    "\n",
    "encoding='ISO-8859-1'\n",
    "subset=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_dict = dict()\n",
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "save = True\n",
    "# save_outputs = False\n",
    "save_outputs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\\n\\nDiscussion\\nResults of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory\\n\\nDISCUSSION\\nThis preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women\\n\\nDISCUSSION\\nThis study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationshi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text\n",
       "1  Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\\n\\nDiscussion\\nResults of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences ...\n",
       "2  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to cont...\n",
       "3  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory\\n\\nDISCUSSION\\nThis preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk...\n",
       "4  Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women\\n\\nDISCUSSION\\nThis study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, no...\n",
       "5  Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationshi..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from article_processing import create_text_dict_from_folder\n",
    "api_key = os.getenv('api_ncbi')\n",
    "\n",
    "def initialize_text_df(folder_path, encoding='ISO-8859-1', subset=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from a folder containing text files.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to folder containing text files.\n",
    "    - encoding (str): Encoding of the text files.\n",
    "    - subset (int): Number of text files to be read. If None, read all files.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame containing the text files.\n",
    "    \"\"\"\n",
    "    text_dict = create_text_dict_from_folder(folder_path, encoding, subset)\n",
    "    text_df = pd.DataFrame.from_dict(text_dict, orient='index', columns=['text'])\n",
    "    return text_df\n",
    "\n",
    "def parse_fulltext(folder_path, title_pattern=r'^(.*)\\n*.+', encoding='ISO-8859-1', subset=None):\n",
    "    # Initialize empty lists to store the captured groups\n",
    "    titles = []\n",
    "    bodies = []\n",
    "    \n",
    "    text_df = initialize_text_df(folder_path, encoding, subset)\n",
    "    return text_df\n",
    "    # Iterate over each element in the series\n",
    "    for text in text_df:\n",
    "        # Apply the regular expression pattern\n",
    "        title_match = re.search(title_pattern, text)\n",
    "        \n",
    "        # Extract the capture groups and append them to the lists\n",
    "        if title_match:\n",
    "            titles.append(title_match.group(1))\n",
    "            body = re.sub(title_pattern, '', text)\n",
    "            bodies.append(body.strip())\n",
    "            \n",
    "        else:\n",
    "            titles.append(None)\n",
    "            bodies.append(None)\n",
    "    \n",
    "    # Create a new DataFrame from the captured groups\n",
    "    df = pd.DataFrame({ 'title': titles, 'text': bodies })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def search_article(title, api_key, verbose=False):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    response (str): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    title_without_not = re.sub(r'not', '', title)\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': title_without_not,\n",
    "        'field': 'title',\n",
    "        'retmax': 5,\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    cleaned_title = re.sub(f'[{string.punctuation}]', '', title).lower().strip()\n",
    "\n",
    "    try:\n",
    "        id_list = data['esearchresult']['idlist']\n",
    "        if id_list:\n",
    "            result = retrieve_citation(id_list[0], api_key).decode('utf-8')\n",
    "            cleaned_result = re.sub(f'[{string.punctuation}]', '', result).lower().strip()\n",
    "            for article_id in id_list:\n",
    "                result = retrieve_citation(article_id, api_key).decode('utf-8')\n",
    "                if cleaned_title in cleaned_result:\n",
    "                    if verbose:\n",
    "                        print(f'Match found for {title}: PMID = {article_id}.')\n",
    "                    return result\n",
    "            print('Article title not found in PMIDs.')\n",
    "            print(f'\\tInput title: {title.lower().strip()}')\n",
    "            # print(f'Result title: {re.sub(r\":\", r\"\", result.lower())}')\n",
    "            return id_list        \n",
    "    except:\n",
    "        print('Article not found.')\n",
    "        return id_list \n",
    "    \n",
    "def retrieve_citation(article_id, api_key):\n",
    "    \"\"\"\n",
    "    Retrieve article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': article_id\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def extract_pubmed_details(record_string):\n",
    "    \"\"\"\n",
    "    Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "    formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "    # Extract publication year\n",
    "    publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "    publication_year = publication_year.group(1) if publication_year else ''\n",
    "    publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "    publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "    # Extract article title\n",
    "    article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "    article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "    # Extract journal title\n",
    "    journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "    journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "    # Extract journal volume\n",
    "    journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "    journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "    # Extract journal issue\n",
    "    journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "    journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "    # Extract start page\n",
    "    start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "    start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "    # Extract end page\n",
    "    end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "    end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "    # Extract ELocationID\n",
    "    doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "    doi = doi.group(1) if doi else ''\n",
    "\n",
    "    abstract = re.search(r'<AbstractText.*?>(.*?)</AbstractText>', record_string)\n",
    "    abstract = abstract.group(1) if abstract else ''\n",
    "\n",
    "    return {\n",
    "        'pubmed_title': article_title,\n",
    "        'abstract': abstract,\n",
    "        'publication': journal_title,\n",
    "        'authors': formatted_authors,\n",
    "        'year': publication_year,\n",
    "        'month': publication_month,\n",
    "        'pub_volume': journal_volume,\n",
    "        'pub_issue': journal_issue,\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page,\n",
    "        'doi': doi,\n",
    "    }\n",
    "\n",
    "\n",
    "def pubmed_details_by_title(title, api_key):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database and return article details.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    article_details (dict): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    record_string = search_article(title, api_key)\n",
    "    # return record_string\n",
    "    if record_string:\n",
    "        article_details = extract_pubmed_details(record_string)\n",
    "        return article_details\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_pubmed_details(text_df, api_key):\n",
    "    \"\"\"\n",
    "    Add the article metadata to a DataFrame containing article title and text.\n",
    "\n",
    "    Parameters:\n",
    "    - text_df (pd.DataFrame): DataFrame containing article title and text.\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added PubMed details for each article.\n",
    "    \"\"\"\n",
    "    article_details_list = []\n",
    "    for article in text_df['title']:\n",
    "        article_details = pubmed_details_by_title(article, api_key)\n",
    "        if article_details:\n",
    "            article_details_list.append(article_details)\n",
    "        else:\n",
    "            article_details_list.append({\n",
    "                'pubmed_title': article,\n",
    "                'abstract': '',\n",
    "                'publication': '',\n",
    "                'authors': '',\n",
    "                'year': '',\n",
    "                'month': '',\n",
    "                'pub_volume': '',\n",
    "                'pub_issue': '',\n",
    "                'start_page': '',\n",
    "                'end_page': '',\n",
    "                'doi': '',\n",
    "            })\n",
    "    article_details_df = pd.DataFrame(article_details_list)\n",
    "    return pd.concat([text_df.reset_index(drop=True), article_details_df], axis=1)\n",
    "\n",
    "def compare_columns(df, col1='title', col2='pubmed_title'):\n",
    "    \"\"\"\n",
    "    Compare two columns in a DataFrame. Drop the second column if the two columns are identical.\n",
    "    Otherwise, return the dataframe with new column with the comparison results, \n",
    "    where `True` indicates a mismatch.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the two columns to be compared.\n",
    "    - col1 (str): Name of the first column to be compared.\n",
    "    - col2 (str): Name of the second column to be compared.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added column containing the comparison results.\n",
    "    \"\"\"\n",
    "    # Remove punctuation and special characters\n",
    "    remove_punct = lambda text: re.sub(f'[{string.punctuation}]', '', text)\n",
    "    col1 = df[col1].apply(remove_punct)\n",
    "    col2 = df[col2].apply(remove_punct)\n",
    "\n",
    "    # Convert to lowercase and remove white spaces\n",
    "    clean_text = lambda text: text.lower().strip()\n",
    "    col1 = col1.apply(clean_text)\n",
    "    col2 = col2.apply(clean_text)\n",
    "\n",
    "    # Perform the comparison\n",
    "    comparison = col1 != col2\n",
    "    if sum(comparison) == 0:\n",
    "        df = df.drop(columns=['pubmed_title'])\n",
    "    else:\n",
    "        df['flag_title'] = comparison\n",
    "    \n",
    "    return df\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "\n",
    "\n",
    "text_df = parse_fulltext(folder_path)\n",
    "text_df\n",
    "# references_df_dict[iteration] = add_pubmed_details(dummy_df, api_key)\n",
    "# references_df_dict[iteration] \n",
    "# compare_columns(references_df_dict[iteration])\n",
    "\n",
    "# test_id = search_article(text_df.loc[4,'Title'], api_key)\n",
    "# test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict = create_text_dict_from_folder(folder_path, encoding, subset)\n",
    "type(text_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from article_processing import create_text_dict_from_folder\n",
    "api_key = os.getenv('api_ncbi')\n",
    "\n",
    "def initialize_text_df(folder_path, encoding='ISO-8859-1', subset=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from a folder containing text files.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to folder containing text files.\n",
    "    - encoding (str): Encoding of the text files.\n",
    "    - subset (int): Number of text files to be read. If None, read all files.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame containing the text files.\n",
    "    \"\"\"\n",
    "    text_dict = create_text_dict_from_folder(folder_path, encoding, subset)\n",
    "    text_df = pd.Series(text_dict, index=text_dict.keys())\n",
    "    return text_df\n",
    "\n",
    "def parse_fulltext(folder_path, title_pattern=r'^(.*)\\n*.+', encoding='ISO-8859-1', subset=None):\n",
    "    # Initialize empty lists to store the captured groups\n",
    "    titles = []\n",
    "    bodies = []\n",
    "    \n",
    "    text_df = initialize_text_df(folder_path, encoding, subset)\n",
    "    # Iterate over each element in the series\n",
    "    for text in text_df:\n",
    "        # print(text)\n",
    "        # Apply the regular expression pattern\n",
    "        title_match = re.search(title_pattern, text)\n",
    "        \n",
    "        # Extract the capture groups and append them to the lists\n",
    "        if title_match:\n",
    "            titles.append(title_match.group(1))\n",
    "            body = re.sub(title_pattern, '', text)\n",
    "            bodies.append(body.strip())\n",
    "            \n",
    "        else:\n",
    "            titles.append(None)\n",
    "            bodies.append(None)\n",
    "    \n",
    "    # Create a new DataFrame from the captured groups\n",
    "    df = pd.DataFrame({ 'title': titles, 'text': bodies })\n",
    "    \n",
    "    return df\n",
    "    # return text_df\n",
    "\n",
    "def search_article(title, api_key, verbose=False):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    response (str): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    title_without_not = re.sub(r'not', '', title)\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': title_without_not,\n",
    "        'field': 'title',\n",
    "        'retmax': 5,\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    cleaned_title = re.sub(f'[{string.punctuation}]', '', title).lower().strip()\n",
    "\n",
    "    try:\n",
    "        id_list = data['esearchresult']['idlist']\n",
    "        if id_list:\n",
    "            result = retrieve_citation(id_list[0], api_key).decode('utf-8')\n",
    "            cleaned_result = re.sub(f'[{string.punctuation}]', '', result).lower().strip()\n",
    "            for article_id in id_list:\n",
    "                result = retrieve_citation(article_id, api_key).decode('utf-8')\n",
    "                if cleaned_title in cleaned_result:\n",
    "                    if verbose:\n",
    "                        print(f'Match found for {title}: PMID = {article_id}.')\n",
    "                    return result\n",
    "            print('Article title not found in PMIDs.')\n",
    "            print(f'\\tInput title: {title.lower().strip()}')\n",
    "            # print(f'Result title: {re.sub(r\":\", r\"\", result.lower())}')\n",
    "            return id_list        \n",
    "    except:\n",
    "        print('Article not found.')\n",
    "        return id_list \n",
    "    \n",
    "def retrieve_citation(article_id, api_key):\n",
    "    \"\"\"\n",
    "    Retrieve article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': article_id\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def extract_pubmed_details(record_string):\n",
    "    \"\"\"\n",
    "    Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "    formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "    # Extract publication year\n",
    "    publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "    publication_year = publication_year.group(1) if publication_year else ''\n",
    "    publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "    publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "    # Extract article title\n",
    "    article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "    article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "    # Extract journal title\n",
    "    journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "    journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "    # Extract journal volume\n",
    "    journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "    journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "    # Extract journal issue\n",
    "    journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "    journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "    # Extract start page\n",
    "    start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "    start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "    # Extract end page\n",
    "    end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "    end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "    # Extract ELocationID\n",
    "    doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "    doi = doi.group(1) if doi else ''\n",
    "\n",
    "    abstract = re.search(r'<AbstractText.*?>(.*?)</AbstractText>', record_string)\n",
    "    abstract = abstract.group(1) if abstract else ''\n",
    "\n",
    "    return {\n",
    "        'pubmed_title': article_title,\n",
    "        'abstract': abstract,\n",
    "        'publication': journal_title,\n",
    "        'authors': formatted_authors,\n",
    "        'year': publication_year,\n",
    "        'month': publication_month,\n",
    "        'pub_volume': journal_volume,\n",
    "        'pub_issue': journal_issue,\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page,\n",
    "        'doi': doi,\n",
    "    }\n",
    "\n",
    "\n",
    "def pubmed_details_by_title(title, api_key):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database and return article details.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    article_details (dict): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    record_string = search_article(title, api_key)\n",
    "    # return record_string\n",
    "    if record_string:\n",
    "        article_details = extract_pubmed_details(record_string)\n",
    "        return article_details\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_pubmed_details(text_df, api_key):\n",
    "    \"\"\"\n",
    "    Add the article metadata to a DataFrame containing article title and text.\n",
    "\n",
    "    Parameters:\n",
    "    - text_df (pd.DataFrame): DataFrame containing article title and text.\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added PubMed details for each article.\n",
    "    \"\"\"\n",
    "    article_details_list = []\n",
    "    for article in text_df['title']:\n",
    "        article_details = pubmed_details_by_title(article, api_key)\n",
    "        if article_details:\n",
    "            article_details_list.append(article_details)\n",
    "        else:\n",
    "            article_details_list.append({\n",
    "                'pubmed_title': article,\n",
    "                'abstract': '',\n",
    "                'publication': '',\n",
    "                'authors': '',\n",
    "                'year': '',\n",
    "                'month': '',\n",
    "                'pub_volume': '',\n",
    "                'pub_issue': '',\n",
    "                'start_page': '',\n",
    "                'end_page': '',\n",
    "                'doi': '',\n",
    "            })\n",
    "    article_details_df = pd.DataFrame(article_details_list)\n",
    "    return pd.concat([text_df.reset_index(drop=True), article_details_df], axis=1)\n",
    "\n",
    "def compare_columns(df, col1='title', col2='pubmed_title'):\n",
    "    \"\"\"\n",
    "    Compare two columns in a DataFrame. Drop the second column if the two columns are identical.\n",
    "    Otherwise, return the dataframe with new column with the comparison results, \n",
    "    where `True` indicates a mismatch.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the two columns to be compared.\n",
    "    - col1 (str): Name of the first column to be compared.\n",
    "    - col2 (str): Name of the second column to be compared.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added column containing the comparison results.\n",
    "    \"\"\"\n",
    "    # Remove punctuation and special characters\n",
    "    remove_punct = lambda text: re.sub(f'[{string.punctuation}]', '', text)\n",
    "    col1 = df[col1].apply(remove_punct)\n",
    "    col2 = df[col2].apply(remove_punct)\n",
    "\n",
    "    # Convert to lowercase and remove white spaces\n",
    "    clean_text = lambda text: text.lower().strip()\n",
    "    col1 = col1.apply(clean_text)\n",
    "    col2 = col2.apply(clean_text)\n",
    "\n",
    "    # Perform the comparison\n",
    "    comparison = col1 != col2\n",
    "    if sum(comparison) == 0:\n",
    "        df = df.drop(columns=['pubmed_title'])\n",
    "    else:\n",
    "        df['flag_title'] = comparison\n",
    "    \n",
    "    return df\n",
    "\n",
    "iteration = 1.1\n",
    "\n",
    "\n",
    "\n",
    "text_df = parse_fulltext(folder_path)\n",
    "text_df\n",
    "references_df_dict[iteration] = add_pubmed_details(text_df, api_key)\n",
    "\n",
    "references_df_dict[iteration] = compare_columns(references_df_dict[iteration])\n",
    "\n",
    "# test_id = search_article(text_df.loc[4,'Title'], api_key)\n",
    "# test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences in the recovery response from high-volume resistance exercise between recreationally trained young and middle-a...</td>\n",
       "      <td>Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery response from resistance exercise between young and middle-aged men. J Strength Cond Res 31(12): 3454-3462, 2017-The purpose of this study was to compare the effects of a bout of high-volume isokinetic resistance exercise protocol (HVP) on lower-body strength and markers of inflammation and muscle damage during recovery between young and middle-aged a...</td>\n",
       "      <td>Journal of strength and conditioning research</td>\n",
       "      <td>Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>3454</td>\n",
       "      <td>3462</td>\n",
       "      <td>10.1519/JSC.0000000000002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis ...</td>\n",
       "      <td>To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &amp;lt;1 g/kg body weight protein/day.</td>\n",
       "      <td>BMJ (Clinical research ed.)</td>\n",
       "      <td>S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>375</td>\n",
       "      <td></td>\n",
       "      <td>n2364</td>\n",
       "      <td></td>\n",
       "      <td>10.1136/bmj.n2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory</td>\n",
       "      <td>This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk, a direct comparison of these contexts could identify similar and differential processes that may underlie food motivat...</td>\n",
       "      <td>Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes to the global obesity epidemic. However, subjective and biobehavioral processes that may increase HP overeating are not clear. Using a novel experimental approach, we examined HP food motivation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.</td>\n",
       "      <td>Physiology &amp;amp; behavior</td>\n",
       "      <td>Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td>208</td>\n",
       "      <td></td>\n",
       "      <td>112563</td>\n",
       "      <td></td>\n",
       "      <td>10.1016/j.physbeh.2019.112563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, nor did it influence the effect of hypohydration on pain, and 3) acute water ingestion did not redu...</td>\n",
       "      <td>Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17&amp;#x3b2;-estradiol and progesterone) throughout the menstrual cycle may influence a woman's pain sensitivity, ...</td>\n",
       "      <td>Journal of applied physiology (Bethesda, Md. : 1985)</td>\n",
       "      <td>Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&amp;#xfc;ndel</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>611</td>\n",
       "      <td>621</td>\n",
       "      <td>10.1152/japplphysiol.00402.2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity</td>\n",
       "      <td>The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-foc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 title  \\\n",
       "0                                                      Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "2                                             Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory   \n",
       "3                                                                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "4                                      Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0  Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences in the recovery response from high-volume resistance exercise between recreationally trained young and middle-a...   \n",
       "1  This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis ...   \n",
       "2  This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk, a direct comparison of these contexts could identify similar and differential processes that may underlie food motivat...   \n",
       "3  This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, nor did it influence the effect of hypohydration on pain, and 3) acute water ingestion did not redu...   \n",
       "4  The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-foc...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              abstract  \\\n",
       "0  Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery response from resistance exercise between young and middle-aged men. J Strength Cond Res 31(12): 3454-3462, 2017-The purpose of this study was to compare the effects of a bout of high-volume isokinetic resistance exercise protocol (HVP) on lower-body strength and markers of inflammation and muscle damage during recovery between young and middle-aged a...   \n",
       "1                                                                                                                                                                                                                                                                                              To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &lt;1 g/kg body weight protein/day.   \n",
       "2               Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes to the global obesity epidemic. However, subjective and biobehavioral processes that may increase HP overeating are not clear. Using a novel experimental approach, we examined HP food motivation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.   \n",
       "3  Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17&#x3b2;-estradiol and progesterone) throughout the menstrual cycle may influence a woman's pain sensitivity, ...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "\n",
       "                                            publication  \\\n",
       "0         Journal of strength and conditioning research   \n",
       "1                           BMJ (Clinical research ed.)   \n",
       "2                             Physiology &amp; behavior   \n",
       "3  Journal of applied physiology (Bethesda, Md. : 1985)   \n",
       "4                                                         \n",
       "\n",
       "                                                                                                                                             authors  \\\n",
       "0  Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda   \n",
       "1                                            S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman   \n",
       "2                                                                                               Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia   \n",
       "3                                                                          Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&#xfc;ndel   \n",
       "4                                                                                                                                                      \n",
       "\n",
       "   year month pub_volume pub_issue start_page end_page  \\\n",
       "0  2017               31        12       3454     3462   \n",
       "1  2021              375                n2364            \n",
       "2  2019              208               112563            \n",
       "3  2022              132         3        611      621   \n",
       "4                                                        \n",
       "\n",
       "                               doi  \n",
       "0     10.1519/JSC.0000000000002219  \n",
       "1                10.1136/bmj.n2364  \n",
       "2    10.1016/j.physbeh.2019.112563  \n",
       "3  10.1152/japplphysiol.00402.2021  \n",
       "4                                   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_df_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Add the section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences in the recovery response from high-volume resistance exercise between recreationally trained young and middle-a...</td>\n",
       "      <td>Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery response from resistance exercise between young and middle-aged men. J Strength Cond Res 31(12): 3454-3462, 2017-The purpose of this study was to compare the effects of a bout of high-volume isokinetic resistance exercise protocol (HVP) on lower-body strength and markers of inflammation and muscle damage during recovery between young and middle-aged a...</td>\n",
       "      <td>Journal of strength and conditioning research</td>\n",
       "      <td>Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>3454</td>\n",
       "      <td>3462</td>\n",
       "      <td>10.1519/JSC.0000000000002219</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis ...</td>\n",
       "      <td>To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &amp;lt;1 g/kg body weight protein/day.</td>\n",
       "      <td>BMJ (Clinical research ed.)</td>\n",
       "      <td>S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>375</td>\n",
       "      <td></td>\n",
       "      <td>n2364</td>\n",
       "      <td></td>\n",
       "      <td>10.1136/bmj.n2364</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory</td>\n",
       "      <td>This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk, a direct comparison of these contexts could identify similar and differential processes that may underlie food motivat...</td>\n",
       "      <td>Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes to the global obesity epidemic. However, subjective and biobehavioral processes that may increase HP overeating are not clear. Using a novel experimental approach, we examined HP food motivation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.</td>\n",
       "      <td>Physiology &amp;amp; behavior</td>\n",
       "      <td>Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td>208</td>\n",
       "      <td></td>\n",
       "      <td>112563</td>\n",
       "      <td></td>\n",
       "      <td>10.1016/j.physbeh.2019.112563</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, nor did it influence the effect of hypohydration on pain, and 3) acute water ingestion did not redu...</td>\n",
       "      <td>Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17&amp;#x3b2;-estradiol and progesterone) throughout the menstrual cycle may influence a woman's pain sensitivity, ...</td>\n",
       "      <td>Journal of applied physiology (Bethesda, Md. : 1985)</td>\n",
       "      <td>Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&amp;#xfc;ndel</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>611</td>\n",
       "      <td>621</td>\n",
       "      <td>10.1152/japplphysiol.00402.2021</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity</td>\n",
       "      <td>The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-foc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 title  \\\n",
       "0                                                      Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "2                                             Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory   \n",
       "3                                                                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "4                                      Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0  Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences in the recovery response from high-volume resistance exercise between recreationally trained young and middle-a...   \n",
       "1  This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis ...   \n",
       "2  This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk, a direct comparison of these contexts could identify similar and differential processes that may underlie food motivat...   \n",
       "3  This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, nor did it influence the effect of hypohydration on pain, and 3) acute water ingestion did not redu...   \n",
       "4  The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-foc...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              abstract  \\\n",
       "0  Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery response from resistance exercise between young and middle-aged men. J Strength Cond Res 31(12): 3454-3462, 2017-The purpose of this study was to compare the effects of a bout of high-volume isokinetic resistance exercise protocol (HVP) on lower-body strength and markers of inflammation and muscle damage during recovery between young and middle-aged a...   \n",
       "1                                                                                                                                                                                                                                                                                              To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &lt;1 g/kg body weight protein/day.   \n",
       "2               Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes to the global obesity epidemic. However, subjective and biobehavioral processes that may increase HP overeating are not clear. Using a novel experimental approach, we examined HP food motivation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.   \n",
       "3  Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17&#x3b2;-estradiol and progesterone) throughout the menstrual cycle may influence a woman's pain sensitivity, ...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "\n",
       "                                            publication  \\\n",
       "0         Journal of strength and conditioning research   \n",
       "1                           BMJ (Clinical research ed.)   \n",
       "2                             Physiology &amp; behavior   \n",
       "3  Journal of applied physiology (Bethesda, Md. : 1985)   \n",
       "4                                                         \n",
       "\n",
       "                                                                                                                                             authors  \\\n",
       "0  Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda   \n",
       "1                                            S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman   \n",
       "2                                                                                               Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia   \n",
       "3                                                                          Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&#xfc;ndel   \n",
       "4                                                                                                                                                      \n",
       "\n",
       "   year month pub_volume pub_issue start_page end_page  \\\n",
       "0  2017               31        12       3454     3462   \n",
       "1  2021              375                n2364            \n",
       "2  2019              208               112563            \n",
       "3  2022              132         3        611      621   \n",
       "4                                                        \n",
       "\n",
       "                               doi     section  \n",
       "0     10.1519/JSC.0000000000002219  discussion  \n",
       "1                10.1136/bmj.n2364  discussion  \n",
       "2    10.1016/j.physbeh.2019.112563  discussion  \n",
       "3  10.1152/japplphysiol.00402.2021  discussion  \n",
       "4                                   discussion  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from article_processing import create_text_dict_from_folder\n",
    "api_key = os.getenv('api_ncbi')\n",
    "\n",
    "def initialize_text_df(folder_path, encoding='ISO-8859-1', subset=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from a folder containing text files.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to folder containing text files.\n",
    "    - encoding (str): Encoding of the text files.\n",
    "    - subset (int): Number of text files to be read. If None, read all files.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame containing the text files.\n",
    "    \"\"\"\n",
    "    text_dict = create_text_dict_from_folder(folder_path, encoding, subset)\n",
    "    text_df = pd.Series(text_dict, index=text_dict.keys())\n",
    "    return text_df\n",
    "\n",
    "def parse_fulltext(folder_path, title_pattern=r'^(.*)\\n*.+', encoding='ISO-8859-1', subset=None):\n",
    "    # Initialize empty lists to store the captured groups\n",
    "    titles = []\n",
    "    bodies = []\n",
    "    \n",
    "    text_df = initialize_text_df(folder_path, encoding, subset)\n",
    "    # Iterate over each element in the series\n",
    "    for text in text_df:\n",
    "        # print(text)\n",
    "        # Apply the regular expression pattern\n",
    "        title_match = re.search(title_pattern, text)\n",
    "        \n",
    "        # Extract the capture groups and append them to the lists\n",
    "        if title_match:\n",
    "            titles.append(title_match.group(1))\n",
    "            body = re.sub(title_pattern, '', text)\n",
    "            bodies.append(body.strip())\n",
    "            \n",
    "        else:\n",
    "            titles.append(None)\n",
    "            bodies.append(None)\n",
    "    \n",
    "    # Create a new DataFrame from the captured groups\n",
    "    df = pd.DataFrame({ 'title': titles, 'text': bodies })\n",
    "    \n",
    "    return df\n",
    "    # return text_df\n",
    "\n",
    "def search_article(title, api_key, verbose=False):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    response (str): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    title_without_not = re.sub(r'not', '', title)\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': title_without_not,\n",
    "        'field': 'title',\n",
    "        'retmax': 5,\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    cleaned_title = re.sub(f'[{string.punctuation}]', '', title).lower().strip()\n",
    "\n",
    "    try:\n",
    "        id_list = data['esearchresult']['idlist']\n",
    "        if id_list:\n",
    "            result = retrieve_citation(id_list[0], api_key).decode('utf-8')\n",
    "            cleaned_result = re.sub(f'[{string.punctuation}]', '', result).lower().strip()\n",
    "            for article_id in id_list:\n",
    "                result = retrieve_citation(article_id, api_key).decode('utf-8')\n",
    "                if cleaned_title in cleaned_result:\n",
    "                    if verbose:\n",
    "                        print(f'Match found for {title}: PMID = {article_id}.')\n",
    "                    return result\n",
    "            print('Article title not found in PMIDs.')\n",
    "            print(f'\\tInput title: {title.lower().strip()}')\n",
    "            # print(f'Result title: {re.sub(r\":\", r\"\", result.lower())}')\n",
    "            return id_list        \n",
    "    except:\n",
    "        print('Article not found.')\n",
    "        return id_list \n",
    "    \n",
    "def retrieve_citation(article_id, api_key):\n",
    "    \"\"\"\n",
    "    Retrieve article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': article_id\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def extract_pubmed_details(record_string):\n",
    "    \"\"\"\n",
    "    Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "    formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "    # Extract publication year\n",
    "    publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "    publication_year = publication_year.group(1) if publication_year else ''\n",
    "    publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "    publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "    # Extract article title\n",
    "    article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "    article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "    # Extract journal title\n",
    "    journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "    journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "    # Extract journal volume\n",
    "    journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "    journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "    # Extract journal issue\n",
    "    journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "    journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "    # Extract start page\n",
    "    start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "    start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "    # Extract end page\n",
    "    end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "    end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "    # Extract ELocationID\n",
    "    doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "    doi = doi.group(1) if doi else ''\n",
    "\n",
    "    abstract = re.search(r'<AbstractText.*?>(.*?)</AbstractText>', record_string)\n",
    "    abstract = abstract.group(1) if abstract else ''\n",
    "\n",
    "    return {\n",
    "        'pubmed_title': article_title,\n",
    "        'abstract': abstract,\n",
    "        'publication': journal_title,\n",
    "        'authors': formatted_authors,\n",
    "        'year': publication_year,\n",
    "        'month': publication_month,\n",
    "        'pub_volume': journal_volume,\n",
    "        'pub_issue': journal_issue,\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page,\n",
    "        'doi': doi,\n",
    "    }\n",
    "\n",
    "\n",
    "def pubmed_details_by_title(title, api_key):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database and return article details.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    article_details (dict): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    record_string = search_article(title, api_key)\n",
    "    # return record_string\n",
    "    if record_string:\n",
    "        article_details = extract_pubmed_details(record_string)\n",
    "        return article_details\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_pubmed_details(text_df, api_key, section=None):\n",
    "    \"\"\"\n",
    "    Add the article metadata to a DataFrame containing article title and text.\n",
    "\n",
    "    Parameters:\n",
    "    - text_df (pd.DataFrame): DataFrame containing article title and text.\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added PubMed details for each article.\n",
    "    \"\"\"\n",
    "    article_details_list = []\n",
    "    for article in text_df['title']:\n",
    "        article_details = pubmed_details_by_title(article, api_key)\n",
    "        if article_details:\n",
    "            article_details_list.append(article_details)\n",
    "        else:\n",
    "            article_details_list.append({\n",
    "                'pubmed_title': article,\n",
    "                'abstract': '',\n",
    "                'publication': '',\n",
    "                'authors': '',\n",
    "                'year': '',\n",
    "                'month': '',\n",
    "                'pub_volume': '',\n",
    "                'pub_issue': '',\n",
    "                'start_page': '',\n",
    "                'end_page': '',\n",
    "                'doi': '',\n",
    "            })\n",
    "    article_details_df = pd.DataFrame(article_details_list)\n",
    "    article_details_df['section'] = pd.Series(section, index=article_details_df.index, dtype=str)\n",
    "    return pd.concat([text_df.reset_index(drop=True), article_details_df], axis=1)\n",
    "\n",
    "def compare_columns(df, col1='title', col2='pubmed_title'):\n",
    "    \"\"\"\n",
    "    Compare two columns in a DataFrame. Drop the second column if the two columns are identical.\n",
    "    Otherwise, return the dataframe with new column with the comparison results, \n",
    "    where `True` indicates a mismatch.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the two columns to be compared.\n",
    "    - col1 (str): Name of the first column to be compared.\n",
    "    - col2 (str): Name of the second column to be compared.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added column containing the comparison results.\n",
    "    \"\"\"\n",
    "    # Remove punctuation and special characters\n",
    "    remove_punct = lambda text: re.sub(f'[{string.punctuation}]', '', text)\n",
    "    col1 = df[col1].apply(remove_punct)\n",
    "    col2 = df[col2].apply(remove_punct)\n",
    "\n",
    "    # Convert to lowercase and remove white spaces\n",
    "    clean_text = lambda text: text.lower().strip()\n",
    "    col1 = col1.apply(clean_text)\n",
    "    col2 = col2.apply(clean_text)\n",
    "\n",
    "    # Perform the comparison\n",
    "    comparison = col1 != col2\n",
    "    if sum(comparison) == 0:\n",
    "        df = df.drop(columns=['pubmed_title'])\n",
    "    else:\n",
    "        df['flag_title'] = comparison\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_sources_table(text_df, col1='title', col2='pubmed_title', section=None):\n",
    "    references_df = add_pubmed_details(text_df, api_key, section=section)\n",
    "\n",
    "    references_df = compare_columns(references_df, col1=col1, col2=col2)\n",
    "    return references_df\n",
    "\n",
    "iteration = 1.11\n",
    "\n",
    "\n",
    "\n",
    "text_df = parse_fulltext(folder_path)\n",
    "text_df\n",
    "# references_df_dict[iteration] = add_pubmed_details(text_df, api_key)\n",
    "\n",
    "references_df_dict[iteration] = create_sources_table(text_df, section='discussion')\n",
    "references_df_dict[iteration]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(None, index=[1,2,3], dtype=\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 5 rows to the database...\n",
      "\tComparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\n",
      "\tEffect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tFood craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory\n",
      "\tHypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women\n",
      "\tWeight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\n",
      "Error adding data to the database: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type integer: \"\"\n",
      "\n",
      "[SQL: INSERT INTO sources (title, text, abstract, publication, authors, year, month, pub_volume, pub_issue, start_page, end_page, doi, section) SELECT p0::VARCHAR, p1::VARCHAR, p2::VARCHAR, p3::VARCHAR, p4::VARCHAR, p5::INTEGER, p6::VARCHAR, p7::VARCHAR, p ... 1185 characters truncated ... , p8, p9, p10, p11, p12, sen_counter) ORDER BY sen_counter RETURNING sources.id, sources.id AS id__1]\n",
      "[parameters: {'year__0': '2017', 'month__0': '', 'publication__0': 'Journal of strength and conditioning research', 'text__0': 'Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective leve ... (5816 characters truncated) ... ation groups using multijoint, dynamic constant resistance exercises common to the training programs of most recreational lifters, regardless of age.', 'title__0': 'Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men', 'start_page__0': '3454', 'section__0': 'discussion', 'doi__0': '10.1519/JSC.0000000000002219', 'pub_issue__0': '12', 'end_page__0': '3462', 'authors__0': 'Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda', 'pub_volume__0': '31', 'abstract__0': 'Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery respon ... (1786 characters truncated) ... ammatory and muscle damage response from high-volume isokinetic exercise is similar between recreationally trained, young, and middle-aged adult men.', 'year__1': '2021', 'month__1': '', 'publication__1': 'BMJ (Clinical research ed.)', 'text__1': 'This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults r ... (5249 characters truncated) ... ermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).', 'title__1': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial', 'start_page__1': 'n2364', 'section__1': 'discussion', 'doi__1': '10.1136/bmj.n2364', 'pub_issue__1': '', 'end_page__1': '', 'authors__1': 'S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman', 'pub_volume__1': '375', 'abstract__1': 'To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &lt;1 g/kg body weight protein/day.', 'year__2': '2019', 'month__2': '', 'publication__2': 'Physiology &amp; behavior', 'text__2': 'This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3 ... (9926 characters truncated) ... e findings suggest the need for further carefully controlled studies to understand the biobehavioral processes that drive overeating and weight gain.', 'title__2': 'Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory', 'start_page__2': '112563', 'section__2': 'discussion', 'doi__2': '10.1016/j.physbeh.2019.112563', 'pub_issue__2': '', 'end_page__2': '', 'authors__2': 'Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia', 'pub_volume__2': '208', 'abstract__2': 'Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes t ... (188 characters truncated) ... ation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.', 'year__3': '2022', 'month__3': '', 'publication__3': 'Journal of applied physiology (Bethesda, Md. : 1985)', 'text__3': 'This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrhei ... (12483 characters truncated) ...  Therefore, until a consensus on the topic has been reached, our data do not discount the need for future pain researchers to verify menstrual phase.', 'title__3': 'Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women', 'start_page__3': '611', 'section__3': 'discussion', 'doi__3': '10.1152/japplphysiol.00402.2021', 'pub_issue__3': '3', 'end_page__3': '621', 'authors__3': 'Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&#xfc;ndel', 'pub_volume__3': '132', 'abstract__3': \"Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffect ... (1968 characters truncated) ... ion did not acutely attenuate the negative effects of hypohydration on pain, highlighting the importance of staying well-hydrated throughout the day.\", 'year__4': '', 'month__4': '', 'publication__4': '', 'text__4': 'The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a lar ... (7850 characters truncated) ... -inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].', 'title__4': 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity', 'start_page__4': '', 'section__4': 'discussion', 'doi__4': '', 'pub_issue__4': '', 'end_page__4': '', 'authors__4': '', 'pub_volume__4': '', 'abstract__4': ''}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/9h9h)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "# # Set parameters\n",
    "# iteration_id = 1.6\n",
    "# article_limit = None\n",
    "# temperature = 1.5\n",
    "# n_choices = 2\n",
    "# pause_per_request=0\n",
    "# # summary_iteration_id = iteration_id\n",
    "# chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "# # model = 'gpt-4'\n",
    "# save_outputs=True\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=article_limit)\n",
    "# # sources_df\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # # chaining_dict[iteration_id]\n",
    "# qna_dict = create_summaries_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# qna_dict[iteration_id]\n",
    "\n",
    "# # Add rows from results to summaries and prompts table\n",
    "bulk_append(table='sources', input_df=references_df_dict[iteration])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 2: fix issues if null values from pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2, 3, 4, 5])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences in the recovery response from high-volume resistance exercise between recreationally trained young and middle-a...</td>\n",
       "      <td>Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery response from resistance exercise between young and middle-aged men. J Strength Cond Res 31(12): 3454-3462, 2017-The purpose of this study was to compare the effects of a bout of high-volume isokinetic resistance exercise protocol (HVP) on lower-body strength and markers of inflammation and muscle damage during recovery between young and middle-aged a...</td>\n",
       "      <td>Journal of strength and conditioning research</td>\n",
       "      <td>Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>3454</td>\n",
       "      <td>3462</td>\n",
       "      <td>10.1519/JSC.0000000000002219</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis ...</td>\n",
       "      <td>To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &amp;lt;1 g/kg body weight protein/day.</td>\n",
       "      <td>BMJ (Clinical research ed.)</td>\n",
       "      <td>S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>375</td>\n",
       "      <td></td>\n",
       "      <td>n2364</td>\n",
       "      <td></td>\n",
       "      <td>10.1136/bmj.n2364</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory</td>\n",
       "      <td>This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk, a direct comparison of these contexts could identify similar and differential processes that may underlie food motivat...</td>\n",
       "      <td>Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes to the global obesity epidemic. However, subjective and biobehavioral processes that may increase HP overeating are not clear. Using a novel experimental approach, we examined HP food motivation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.</td>\n",
       "      <td>Physiology &amp;amp; behavior</td>\n",
       "      <td>Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td>208</td>\n",
       "      <td></td>\n",
       "      <td>112563</td>\n",
       "      <td></td>\n",
       "      <td>10.1016/j.physbeh.2019.112563</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, nor did it influence the effect of hypohydration on pain, and 3) acute water ingestion did not redu...</td>\n",
       "      <td>Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17&amp;#x3b2;-estradiol and progesterone) throughout the menstrual cycle may influence a woman's pain sensitivity, ...</td>\n",
       "      <td>Journal of applied physiology (Bethesda, Md. : 1985)</td>\n",
       "      <td>Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&amp;#xfc;ndel</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>611</td>\n",
       "      <td>621</td>\n",
       "      <td>10.1152/japplphysiol.00402.2021</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-foc...</td>\n",
       "      <td>Weight stigma is pervasive across the U.S. and is associated with poor health outcomes including all-cause mortality. One potential reason that weight stigma may be detrimental to health is that it begets poorer health behaviors. Therefore, the present study tested for associations between weight stigma and four health behaviors (i.e., eating behavior, alcohol use, sleep disturbance, and physical activity), while controlling for BMI and other potential confounds.</td>\n",
       "      <td>International journal of obesity (2005)</td>\n",
       "      <td>Kristen M Lee, Jeffrey M Hunger, A Janet Tomiyama</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>1499</td>\n",
       "      <td>1509</td>\n",
       "      <td>10.1038/s41366-021-00814-5</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 title  \\\n",
       "0                                                      Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "2                                             Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory   \n",
       "3                                                                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "4                                                                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0  Results of this study indicated no differences in the recovery response between YA and MA for any of the performance measures, nor in subjective levels of muscle pain or soreness. Furthermore, no between-group differences were observed in the inflammatory or muscle damage response to the exercise protocol. To the best of our knowledge, this is the first study to examine differences in the recovery response from high-volume resistance exercise between recreationally trained young and middle-a...   \n",
       "1  This nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis ...   \n",
       "2  This preliminary study is the first to directly compare the effects of both food cue and stress exposure on HP food craving and HP food intake in a 3-day human laboratory experiment conducted within a controlled hospital-based setting with healthy community adults. As both the ubiquitous HP food environment and stressors are known to increase HP food intake and obesity risk, a direct comparison of these contexts could identify similar and differential processes that may underlie food motivat...   \n",
       "3  This study examined the independent and combined effects of hypohydration and menstrual phase on experimental pain sensitivity in healthy eumenorrheic women, and the potential efficacy of acute water ingestion as a remedy to the deleterious impact of hypohydration. The main findings were that: 1) mild hypohydration increased pain sensitivity, 2) menstrual phase did not affect pain sensitivity, nor did it influence the effect of hypohydration on pain, and 3) acute water ingestion did not redu...   \n",
       "4  The present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-foc...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              abstract  \\\n",
       "0  Gordon, JA III, Hoffman, JR, Arroyo, E, Varanoske, AN, Coker, NA, Gepner, Y, Wells, AJ, Stout, JR, and Fukuda, DH. Comparisons in the recovery response from resistance exercise between young and middle-aged men. J Strength Cond Res 31(12): 3454-3462, 2017-The purpose of this study was to compare the effects of a bout of high-volume isokinetic resistance exercise protocol (HVP) on lower-body strength and markers of inflammation and muscle damage during recovery between young and middle-aged a...   \n",
       "1                                                                                                                                                                                                                                                                                              To assess the antifracture efficacy and safety of a nutritional intervention in institutionalised older adults replete in vitamin D but with mean intakes of 600 mg/day calcium and &lt;1 g/kg body weight protein/day.   \n",
       "2               Overeating of highly palatable (HP) foods in the ubiquitous HP food cue environment and under stress is associated with weight gain and contributes to the global obesity epidemic. However, subjective and biobehavioral processes that may increase HP overeating are not clear. Using a novel experimental approach, we examined HP food motivation and intake and neuroendocrine responses in the context of food cues, stress and a control neutral relaxing cue exposure in healthy individuals.   \n",
       "3  Chronic pain is a pervasive health problem and is associated with tremendous socioeconomic costs. However, current pain treatments are often ineffective due, in part, to the multifactorial nature of pain. Mild hypohydration was shown to increase experimental pain sensitivity in men, but whether this also occurs in women has not been examined. Fluctuations in ovarian hormones (i.e., 17&#x3b2;-estradiol and progesterone) throughout the menstrual cycle may influence a woman's pain sensitivity, ...   \n",
       "4                                  Weight stigma is pervasive across the U.S. and is associated with poor health outcomes including all-cause mortality. One potential reason that weight stigma may be detrimental to health is that it begets poorer health behaviors. Therefore, the present study tested for associations between weight stigma and four health behaviors (i.e., eating behavior, alcohol use, sleep disturbance, and physical activity), while controlling for BMI and other potential confounds.   \n",
       "\n",
       "                                            publication  \\\n",
       "0         Journal of strength and conditioning research   \n",
       "1                           BMJ (Clinical research ed.)   \n",
       "2                             Physiology &amp; behavior   \n",
       "3  Journal of applied physiology (Bethesda, Md. : 1985)   \n",
       "4               International journal of obesity (2005)   \n",
       "\n",
       "                                                                                                                                             authors  \\\n",
       "0  Joseph A Gordon, Jay R Hoffman, Eliott Arroyo, Alyssa N Varanoske, Nicholas A Coker, Yftach Gepner, Adam J Wells, Jeffrey R Stout, David H Fukuda   \n",
       "1                                            S Iuliano, S Poon, J Robbins, M Bui, X Wang, L De Groot, M Van Loan, A Ghasem Zadeh, T Nguyen, E Seeman   \n",
       "2                                                                                               Rajita Sinha, Peihua Gu, Rachel Hart, J B Guarnaccia   \n",
       "3                                                                          Beverly Tan, Michael C Philipp, Ahmad Munir Che Muhamed, Toby M&#xfc;ndel   \n",
       "4                                                                                                  Kristen M Lee, Jeffrey M Hunger, A Janet Tomiyama   \n",
       "\n",
       "   year month pub_volume pub_issue start_page end_page  \\\n",
       "0  2017               31        12       3454     3462   \n",
       "1  2021              375                n2364            \n",
       "2  2019              208               112563            \n",
       "3  2022              132         3        611      621   \n",
       "4  2021               45         7       1499     1509   \n",
       "\n",
       "                               doi     section  \n",
       "0     10.1519/JSC.0000000000002219  discussion  \n",
       "1                10.1136/bmj.n2364  discussion  \n",
       "2    10.1016/j.physbeh.2019.112563  discussion  \n",
       "3  10.1152/japplphysiol.00402.2021  discussion  \n",
       "4       10.1038/s41366-021-00814-5  discussion  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from article_processing import create_text_dict_from_folder\n",
    "api_key = os.getenv('api_ncbi')\n",
    "\n",
    "def initialize_text_df(folder_path, encoding='ISO-8859-1', subset=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from a folder containing text files.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to folder containing text files.\n",
    "    - encoding (str): Encoding of the text files.\n",
    "    - subset (int): Number of text files to be read. If None, read all files.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame containing the text files.\n",
    "    \"\"\"\n",
    "    text_dict = create_text_dict_from_folder(folder_path, encoding, subset)\n",
    "    text_df = pd.Series(text_dict, index=text_dict.keys())\n",
    "    return text_df\n",
    "\n",
    "def parse_fulltext(folder_path, title_pattern=r'^(.*)\\n*.+', encoding='ISO-8859-1', subset=None):\n",
    "    # Initialize empty lists to store the captured groups\n",
    "    titles = []\n",
    "    bodies = []\n",
    "    \n",
    "    text_df = initialize_text_df(folder_path, encoding, subset)\n",
    "    # Iterate over each element in the series\n",
    "    for text in text_df:\n",
    "        # print(text)\n",
    "        # Apply the regular expression pattern\n",
    "        title_match = re.search(title_pattern, text)\n",
    "        \n",
    "        # Extract the capture groups and append them to the lists\n",
    "        if title_match:\n",
    "            titles.append(title_match.group(1))\n",
    "            body = re.sub(title_pattern, '', text)\n",
    "            bodies.append(body.strip())\n",
    "            \n",
    "        else:\n",
    "            titles.append(None)\n",
    "            bodies.append(None)\n",
    "    \n",
    "    # Create a new DataFrame from the captured groups\n",
    "    df = pd.DataFrame({ 'title': titles, 'text': bodies })\n",
    "    \n",
    "    return df\n",
    "    # return text_df\n",
    "\n",
    "def search_article(title, api_key, verbose=False):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    response (str): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    title_without_not = re.sub(r'not', '', title)\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': title_without_not,\n",
    "        'field': 'title',\n",
    "        'retmax': 5,\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    cleaned_title = re.sub(f'[{string.punctuation}]', '', title).lower().strip()\n",
    "\n",
    "    try:\n",
    "        id_list = data['esearchresult']['idlist']\n",
    "        if id_list:\n",
    "            result = retrieve_citation(id_list[0], api_key).decode('utf-8')\n",
    "            cleaned_result = re.sub(f'[{string.punctuation}]', '', result).lower().strip()\n",
    "            for article_id in id_list:\n",
    "                result = retrieve_citation(article_id, api_key).decode('utf-8')\n",
    "                if cleaned_title in cleaned_result:\n",
    "                    if verbose:\n",
    "                        print(f'Match found for {title}: PMID = {article_id}.')\n",
    "                    return result\n",
    "            print('Article title not found in PMIDs.')\n",
    "            print(f'\\tInput title: {title.lower().strip()}')\n",
    "            # print(f'Result title: {re.sub(r\":\", r\"\", result.lower())}')\n",
    "            return id_list        \n",
    "    except:\n",
    "        print('Article not found.')\n",
    "        return id_list \n",
    "    \n",
    "def retrieve_citation(article_id, api_key):\n",
    "    \"\"\"\n",
    "    Retrieve article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if api_key:\n",
    "        base_url += f'&api_key={api_key}'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': article_id\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def extract_pubmed_details(record_string):\n",
    "    \"\"\"\n",
    "    Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "    \"\"\"\n",
    "    authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "    formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "    # Extract publication year\n",
    "    publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "    publication_year = publication_year.group(1) if publication_year else ''\n",
    "    publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "    publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "    # Extract article title\n",
    "    article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "    article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "    # Extract journal title\n",
    "    journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "    journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "    # Extract journal volume\n",
    "    journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "    journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "    # Extract journal issue\n",
    "    journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "    journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "    # Extract start page\n",
    "    start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "    start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "    # Extract end page\n",
    "    end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "    end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "    # Extract ELocationID\n",
    "    doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "    doi = doi.group(1) if doi else ''\n",
    "\n",
    "    abstract = re.search(r'<AbstractText.*?>(.*?)</AbstractText>', record_string)\n",
    "    abstract = abstract.group(1) if abstract else ''\n",
    "\n",
    "    return {\n",
    "        'pubmed_title': article_title,\n",
    "        'abstract': abstract,\n",
    "        'publication': journal_title,\n",
    "        'authors': formatted_authors,\n",
    "        'year': publication_year,\n",
    "        'month': publication_month,\n",
    "        'pub_volume': journal_volume,\n",
    "        'pub_issue': journal_issue,\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page,\n",
    "        'doi': doi,\n",
    "    }\n",
    "\n",
    "\n",
    "def pubmed_details_by_title(title, api_key):\n",
    "    \"\"\"\n",
    "    Search for article title in PubMed database and return article details.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): article title\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    article_details (dict): Article metadata from PubMed database if present. Otherwise, returns list of PMIDs.\n",
    "    \"\"\"\n",
    "    record_string = search_article(title, api_key)\n",
    "    # return record_string\n",
    "    if record_string:\n",
    "        article_details = extract_pubmed_details(record_string)\n",
    "        return article_details\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_pubmed_details(text_df, api_key, section=None):\n",
    "    \"\"\"\n",
    "    Add the article metadata to a DataFrame containing article title and text.\n",
    "\n",
    "    Parameters:\n",
    "    - text_df (pd.DataFrame): DataFrame containing article title and text.\n",
    "    - api_key (str): NCBI API key\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added PubMed details for each article.\n",
    "    \"\"\"\n",
    "    article_details_list = []\n",
    "    for article in text_df['title']:\n",
    "        article_details = pubmed_details_by_title(article, api_key)\n",
    "        if article_details:\n",
    "            article_details_list.append(article_details)\n",
    "        else:\n",
    "            article_details_list.append({\n",
    "                'pubmed_title': article,\n",
    "                'abstract': '',\n",
    "                'publication': '',\n",
    "                'authors': '',\n",
    "                'year': '',\n",
    "                'month': '',\n",
    "                'pub_volume': '',\n",
    "                'pub_issue': '',\n",
    "                'start_page': '',\n",
    "                'end_page': '',\n",
    "                'doi': '',\n",
    "            })\n",
    "    article_details_df = pd.DataFrame(article_details_list)\n",
    "    article_details_df['section'] = pd.Series(section, index=article_details_df.index, dtype=str)\n",
    "    return pd.concat([text_df.reset_index(drop=True), article_details_df], axis=1)\n",
    "\n",
    "def compare_columns(df, col1='title', col2='pubmed_title'):\n",
    "    \"\"\"\n",
    "    Compare two columns in a DataFrame. Drop the second column if the two columns are identical.\n",
    "    Otherwise, return the dataframe with new column with the comparison results, \n",
    "    where `True` indicates a mismatch.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the two columns to be compared.\n",
    "    - col1 (str): Name of the first column to be compared.\n",
    "    - col2 (str): Name of the second column to be compared.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added column containing the comparison results.\n",
    "    \"\"\"\n",
    "    # Remove punctuation and special characters\n",
    "    remove_punct = lambda text: re.sub(f'[{string.punctuation}]', '', text)\n",
    "    col1 = df[col1].apply(remove_punct)\n",
    "    col2 = df[col2].apply(remove_punct)\n",
    "\n",
    "    # Convert to lowercase and remove white spaces\n",
    "    clean_text = lambda text: text.lower().strip()\n",
    "    col1 = col1.apply(clean_text)\n",
    "    col2 = col2.apply(clean_text)\n",
    "\n",
    "    # Perform the comparison\n",
    "    comparison = col1 != col2\n",
    "    if sum(comparison) == 0:\n",
    "        df = df.drop(columns=['pubmed_title'])\n",
    "    else:\n",
    "        df['flag_title'] = comparison\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_sources_table(text_df, col1='title', col2='pubmed_title', section=None):\n",
    "    references_df = add_pubmed_details(text_df, api_key, section=section)\n",
    "\n",
    "    references_df = compare_columns(references_df, col1=col1, col2=col2)\n",
    "    return references_df\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries'):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] if 'section' in row.index else None\n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "# # Set parameters\n",
    "# iteration_id = 1.6\n",
    "# article_limit = None\n",
    "# temperature = 1.5\n",
    "# n_choices = 2\n",
    "# pause_per_request=0\n",
    "# # summary_iteration_id = iteration_id\n",
    "# chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "# # model = 'gpt-4'\n",
    "# save_outputs=True\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=article_limit)\n",
    "# # sources_df\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # # chaining_dict[iteration_id]\n",
    "# qna_dict = create_summaries_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# qna_dict[iteration_id]\n",
    "\n",
    "\n",
    "iteration = 2\n",
    "\n",
    "\n",
    "\n",
    "text_df = parse_fulltext(folder_path)\n",
    "text_df\n",
    "# references_df_dict[iteration] = add_pubmed_details(text_df, api_key)\n",
    "\n",
    "references_df_dict[iteration] = create_sources_table(text_df, section='discussion')\n",
    "references_df_dict[iteration]\n",
    "\n",
    "\n",
    "# # # Add rows from results to summaries and prompts table\n",
    "# bulk_append(table='sources', input_df=references_df_dict[iteration])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** [final `sources` scripts] Add to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 5 rows to the database...\n",
      "\tComparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men\n",
      "\tEffect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tFood craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the laboratory\n",
      "\tHypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women\n",
      "\tWeight stigma and health behaviors: evidence from the Eating in America Study\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "bulk_append(table='sources', input_df=references_df_dict[iteration])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * from sources ORDER BY id ASC\n",
      "**Text #1 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #1 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #2 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #3 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #4 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #6 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #13 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #13 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #14 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #14 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #15 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #15 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #17 prompt #1 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #17 prompt #2 of 2**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo-16k-0613\n",
      "An error occurred on line 251 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_21772\\2819590810.py : The server is overloaded or not ready yet.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "1_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "1_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "2_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "3_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "4_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "5_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "6_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "13_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "13_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "14_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "14_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "15_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "15_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "16_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "16_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "17_prompt00\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "17_prompt01\n",
      "\treference_id\n",
      "\ttitle\n",
      "\ttext\n",
      "\tfolder\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "Object saved as JSON: ../text/2023-06-20 discussion//batch_Chaining_attributes_initial_2023-07-13_1124.json\n",
      "Processing 1_prompt00...\n",
      "Processing 1_prompt01...\n",
      "Processing 2_prompt00...\n",
      "Processing 2_prompt01...\n",
      "Processing 3_prompt00...\n",
      "Processing 3_prompt01...\n",
      "Processing 4_prompt00...\n",
      "Processing 4_prompt01...\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 6_prompt00...\n",
      "Processing 6_prompt01...\n",
      "Processing 13_prompt00...\n",
      "Processing 13_prompt01...\n",
      "Processing 14_prompt00...\n",
      "Processing 14_prompt01...\n",
      "Processing 15_prompt00...\n",
      "Processing 15_prompt01...\n",
      "Processing 16_prompt00...\n",
      "Processing 16_prompt01...\n",
      "Processing 17_prompt00...\n",
      "Processing 17_prompt01...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 423\u001b[0m\n\u001b[0;32m    414\u001b[0m chaining_dict \u001b[39m=\u001b[39m batch_summarize(\n\u001b[0;32m    415\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task, \n\u001b[0;32m    416\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    420\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[39m# # chaining_dict[iteration_id]\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m    424\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[39m# # Add rows from results to summaries and prompts table\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[39m# bulk_append(qna_dict[iteration_id])\u001b[39;00m\n\u001b[0;32m    428\u001b[0m qna_dict[iteration_id]\n",
      "Cell \u001b[1;32mIn[46], line 347\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mfor\u001b[39;00m chatbot_key \u001b[39min\u001b[39;00m chatbot_dict[chatbot_id]\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    344\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mchatbot_key\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    345\u001b[0m     dfs_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m    346\u001b[0m         chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39mqna, \n\u001b[1;32m--> 347\u001b[0m         index\u001b[39m=\u001b[39m[choice \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(chatbot_dict[chatbot_id][chatbot_key]\u001b[39m.\u001b[39;49mqna[\u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[0;32m    348\u001b[0m         )\n\u001b[0;32m    350\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    351\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = folder_path\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "sources_df = get_table(table='sources', limit=article_limit)\n",
    "# sources_df\n",
    "\n",
    "chaining_dict = batch_summarize(\n",
    "    sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chatbot_dict, temperature=temperature,\n",
    "    system_role=system_role, model=model, max_tokens=1000,\n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=save_outputs\n",
    "    )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\n  \"headline\": \"Ever wondered how aging affects muscle function and recovery?\",\\n  \"body\": \"A recent study looked into the differences in muscle function and recovery between young and middle-aged adults. The results showed that both groups experienced similar recovery responses after high-volume resistance exercise, regardless of age. Participants who regularly engaged in resistance training were not at increased risk for greater soreness or muscle damage. Although changes in strength may occur during middle age, recovery from exercise seems to be maintained in recreationally trained individuals. This information is helpful for understanding the impact of aging and the importance of regular exercise, especially resistance training, in minimizing declines in muscle function.\",\\n  \"audience\": \"Are you concerned about how aging may affect your ability to exercise and recover? Don\\'t worry, a recent study found that middle-aged adults who regularly engage in resistance training can maintain their recovery response to exercise similar to younger adults. So keep up with your exercise routine and don\\'t let the fear of getting older hold you back from staying fit and healthy!\"\\n}',\n",
       " '{\"headline\": \"Exciting New Research Findings on Muscle Aging and Recovery\", \\n\"body\": \"Hey! I just came across some interesting health research on muscle aging and recovery. The study suggests that decreases in muscle mass, function, and neuromuscular activation are significant factors in the decline of quality of life as we age. But here\\'s the exciting part - the research found that middle-aged individuals (40-59 years) who regularly engage in resistance training show comparable recovery from exercise as younger adults (18-30 years). The study involved a high-volume isokinetic resistance exercise protocol, and it found no significant differences between the age groups in muscle soreness, inflammation, or factors like creatine kinase levels. So it seems that staying physically active through resistance training can minimize declines in muscle function and help with age-related performance decreases. Pretty cool, right? :) Can\\'t wait to chat more about it!\",\\n\"audience\": \"Hey! I just read an interesting research article that explains how staying physically active by doing resistance training can help build strength and minimize age-related declines. The study showed that even middle-aged adults can recover from exercise just as well as younger adults. Great news for everyone who wants to maintain their strength and function as they age! Let me know if you want more details. :)\" }']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr(chaining_dict, iteration_id)['qna']['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.01 re-do porcessing in case there is a blank response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1_prompt00...\n",
      "Processing 1_prompt01...\n",
      "Processing 2_prompt00...\n",
      "Processing 2_prompt01...\n",
      "Processing 3_prompt00...\n",
      "Processing 3_prompt01...\n",
      "Processing 4_prompt00...\n",
      "Processing 4_prompt01...\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 6_prompt00...\n",
      "Processing 6_prompt01...\n",
      "Processing 13_prompt00...\n",
      "Processing 13_prompt01...\n",
      "Processing 14_prompt00...\n",
      "Processing 14_prompt01...\n",
      "Processing 15_prompt00...\n",
      "Processing 15_prompt01...\n",
      "Processing 16_prompt00...\n",
      "Processing 16_prompt01...\n",
      "Processing 17_prompt00...\n",
      "Processing 17_prompt01...\n",
      "\tAn error occurred on line 348 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_21772\\2149729075.py: 'summary'\n",
      "Error creating DataFrame from 17_prompt01: 'summary'\n",
      "Error converting summary column to JSON: Expecting value: line 1 column 1 (char 0); will do row by row\n",
      "Error converting summary 9 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 12 to JSON: Expecting ',' delimiter: line 4 column 1 (char 849)\n",
      "Error converting summary 15 to JSON: Invalid control character at: line 3 column 769 (char 860)\n",
      "Error converting summary 17 to JSON: Expecting ',' delimiter: line 3 column 230 (char 1170)\n",
      "Error converting summary 18 to JSON: Unterminated string starting at: line 3 column 13 (char 987)\n",
      "Error converting summary 21 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 29 to JSON: Invalid control character at: line 4 column 720 (char 2501)\n",
      "Error converting summary 31 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 32 to JSON: Invalid control character at: line 3 column 451 (char 527)\n",
      "Error converting summary 33 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 36 to JSON: Expecting ',' delimiter: line 4 column 523 (char 1132)\n",
      "Error converting summary 37 to JSON: Unterminated string starting at: line 3 column 14 (char 923)\n",
      "Error converting summary 40 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 41 to JSON: Expecting ',' delimiter: line 4 column 5 (char 846)\n",
      "Original summaries DataFrame shape: (42, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-13 11:21:24.432010-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>A recent study looked into the differences in muscle function and recovery between young and mid...</td>\n",
       "      <td>Ever wondered how aging affects muscle function and recovery?</td>\n",
       "      <td>Are you concerned about how aging may affect your ability to exercise and recover? Don't worry, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-13 11:21:24.432010-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>2</td>\n",
       "      <td>Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey! I just came across some interesting health research on muscle aging and recovery. The study...</td>\n",
       "      <td>Exciting New Research Findings on Muscle Aging and Recovery</td>\n",
       "      <td>Hey! I just read an interesting research article that explains how staying physically active by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-13 11:21:28.916762-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>1</td>\n",
       "      <td>Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>A recent study investigated the recovery response from a high-volume isokinetic resistance exerc...</td>\n",
       "      <td>New Study on Muscle Recovery in Middle-Aged Adults</td>\n",
       "      <td>A fascinating new study discovered that muscle recovery is maintained in middle-aged men who reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-13 11:21:28.916762-07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men</td>\n",
       "      <td>2</td>\n",
       "      <td>Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Did you know that decreases in muscle mass, function, and activation can contribute to a decline...</td>\n",
       "      <td>New Study Shows How Regular Resistance Training Can Improve Muscle Function in Middle-aged Adults</td>\n",
       "      <td>Regular resistance training, such as weightlifting, can keep your muscles strong and help you re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-13 11:21:32.710512-07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Longevity increases the proportion of older adults in the population. The accompanying increased...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>A recent study in residential aged care facilities found that providing high calcium and high pr...</td>\n",
       "      <td>New research shows that a simple nutrition intervention can reduce the risk of falls and fractur...</td>\n",
       "      <td>A recent study with over 7000 older adults found that providing extra servings of dairy foods co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-07-13 11:23:15.817575-07:00</td>\n",
       "      <td>16</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>2</td>\n",
       "      <td>This study examined the independent and combined effects of hypohydration and menstrual phase on...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey there! I just read an interesting health research study about dehydration and pain sensitivi...</td>\n",
       "      <td>New Research Findings: Dehydration May Increase Pain Sensitivity in Women</td>\n",
       "      <td>Hey there! I just read an interesting health research study about dehydration and pain sensitivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-07-13 11:23:20.650184-07:00</td>\n",
       "      <td>16</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>1</td>\n",
       "      <td>This study examined the independent and combined effects of hypohydration and menstrual phase on...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey! I just read a fascinating study that found that mild dehydration can make women more sensit...</td>\n",
       "      <td>New study finds dehydration increases pain sensitivity in women</td>\n",
       "      <td>Hey! I just read a really interesting study that found that not drinking enough fluids can actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-07-13 11:23:20.650184-07:00</td>\n",
       "      <td>16</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women</td>\n",
       "      <td>2</td>\n",
       "      <td>This study examined the independent and combined effects of hypohydration and menstrual phase on...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey there! I recently came across an interesting study that explored the effects of dehydration ...</td>\n",
       "      <td>New Research: Dehydration Increases Pain Sensitivity in Women</td>\n",
       "      <td>Hey there! I just read about this fascinating study investigating the influence of dehydration a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-07-13 11:23:25.678475-07:00</td>\n",
       "      <td>17</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>1</td>\n",
       "      <td>The present study employed a two-stage research investigation to examine the relationship betwee...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey there! I just read a really fascinating study on weight stigma and its effects on health beh...</td>\n",
       "      <td>New Research Shows How Weight Stigma Impacts Our Health</td>\n",
       "      <td>Hey there! I recently came across an interesting study examining weight stigma \\nand its effects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-07-13 11:23:25.678475-07:00</td>\n",
       "      <td>17</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study</td>\n",
       "      <td>2</td>\n",
       "      <td>The present study employed a two-stage research investigation to examine the relationship betwee...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey! I just read an interesting study about weight stigma and its impact on health behaviors. Th...</td>\n",
       "      <td>Surprising Findings on the Relationship between Weight Stigma and Health Behaviors</td>\n",
       "      <td>Hey! I just read a really interesting study on how judging people based oh how they look affects...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "0   2023-07-13 11:21:24.432010-07:00             1   \n",
       "1   2023-07-13 11:21:24.432010-07:00             1   \n",
       "2   2023-07-13 11:21:28.916762-07:00             1   \n",
       "3   2023-07-13 11:21:28.916762-07:00             1   \n",
       "4   2023-07-13 11:21:32.710512-07:00             2   \n",
       "..                               ...           ...   \n",
       "37  2023-07-13 11:23:15.817575-07:00            16   \n",
       "38  2023-07-13 11:23:20.650184-07:00            16   \n",
       "39  2023-07-13 11:23:20.650184-07:00            16   \n",
       "40  2023-07-13 11:23:25.678475-07:00            17   \n",
       "41  2023-07-13 11:23:25.678475-07:00            17   \n",
       "\n",
       "                                                                                          article_title  \\\n",
       "0       Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "1       Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "2       Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "3       Comparisons in the Recovery Response From Resistance Exercise Between Young and Middle-Aged Men   \n",
       "4   Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "..                                                                                                  ...   \n",
       "37                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "38                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "39                    Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women   \n",
       "40                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "41                        Weight stigma and health behaviors: evidence from the Eating in America Study   \n",
       "\n",
       "    choice  \\\n",
       "0        1   \n",
       "1        2   \n",
       "2        1   \n",
       "3        2   \n",
       "4        1   \n",
       "..     ...   \n",
       "37       2   \n",
       "38       1   \n",
       "39       2   \n",
       "40       1   \n",
       "41       2   \n",
       "\n",
       "                                                                                                   text  \\\n",
       "0   Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...   \n",
       "1   Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...   \n",
       "2   Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...   \n",
       "3   Decreases in muscle mass, function, and neuromuscular activation are significant factors contrib...   \n",
       "4   Longevity increases the proportion of older adults in the population. The accompanying increased...   \n",
       "..                                                                                                  ...   \n",
       "37  This study examined the independent and combined effects of hypohydration and menstrual phase on...   \n",
       "38  This study examined the independent and combined effects of hypohydration and menstrual phase on...   \n",
       "39  This study examined the independent and combined effects of hypohydration and menstrual phase on...   \n",
       "40  The present study employed a two-stage research investigation to examine the relationship betwee...   \n",
       "41  The present study employed a two-stage research investigation to examine the relationship betwee...   \n",
       "\n",
       "                                                                          system_role  \\\n",
       "0   You are someone who loves to read health research and tell your friends about it.   \n",
       "1   You are someone who loves to read health research and tell your friends about it.   \n",
       "2   You are someone who loves to read health research and tell your friends about it.   \n",
       "3   You are someone who loves to read health research and tell your friends about it.   \n",
       "4   You are someone who loves to read health research and tell your friends about it.   \n",
       "..                                                                                ...   \n",
       "37  You are someone who loves to read health research and tell your friends about it.   \n",
       "38  You are someone who loves to read health research and tell your friends about it.   \n",
       "39  You are someone who loves to read health research and tell your friends about it.   \n",
       "40  You are someone who loves to read health research and tell your friends about it.   \n",
       "41  You are someone who loves to read health research and tell your friends about it.   \n",
       "\n",
       "                     model  temperature  \\\n",
       "0   gpt-3.5-turbo-16k-0613          1.5   \n",
       "1   gpt-3.5-turbo-16k-0613          1.5   \n",
       "2   gpt-3.5-turbo-16k-0613          1.5   \n",
       "3   gpt-3.5-turbo-16k-0613          1.5   \n",
       "4   gpt-3.5-turbo-16k-0613          1.5   \n",
       "..                     ...          ...   \n",
       "37  gpt-3.5-turbo-16k-0613          1.5   \n",
       "38  gpt-3.5-turbo-16k-0613          1.5   \n",
       "39  gpt-3.5-turbo-16k-0613          1.5   \n",
       "40  gpt-3.5-turbo-16k-0613          1.5   \n",
       "41  gpt-3.5-turbo-16k-0613          1.5   \n",
       "\n",
       "                                                                                              prep_step  \\\n",
       "0   In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "1   In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "2   In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "3   In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "4   In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "..                                                                                                  ...   \n",
       "37  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "38  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "39  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "40  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "41  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "\n",
       "                                                    summarize_task  \\\n",
       "0   Write a casual text message to your friend about the research.   \n",
       "1   Write a casual text message to your friend about the research.   \n",
       "2   Write a casual text message to your friend about the research.   \n",
       "3   Write a casual text message to your friend about the research.   \n",
       "4   Write a casual text message to your friend about the research.   \n",
       "..                                                             ...   \n",
       "37  Write a casual text message to your friend about the research.   \n",
       "38  Write a casual text message to your friend about the research.   \n",
       "39  Write a casual text message to your friend about the research.   \n",
       "40  Write a casual text message to your friend about the research.   \n",
       "41  Write a casual text message to your friend about the research.   \n",
       "\n",
       "                                                                                              edit_task  \\\n",
       "0   Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "1   Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "2   Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "3   Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "4   Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "..                                                                                                  ...   \n",
       "37  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "38  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "39  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "40  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "41  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "\n",
       "                                                                                          simplify_task  \\\n",
       "0   3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "1   3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "2   3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "3   3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "4   3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "..                                                                                                  ...   \n",
       "37  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "38  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "39  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "40  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "41  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "\n",
       "                      simplify_audience  \\\n",
       "0   people without a science background   \n",
       "1   people without a science background   \n",
       "2   people without a science background   \n",
       "3   people without a science background   \n",
       "4   people without a science background   \n",
       "..                                  ...   \n",
       "37  people without a science background   \n",
       "38  people without a science background   \n",
       "39  people without a science background   \n",
       "40  people without a science background   \n",
       "41  people without a science background   \n",
       "\n",
       "                                                                                            format_task  \\\n",
       "0   4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "1   4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "2   4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "3   4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "4   4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "..                                                                                                  ...   \n",
       "37  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "38  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "39  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "40  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "41  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "\n",
       "                                                                                    full_summarize_task  \\\n",
       "0   Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "1   Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "2   Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "3   Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "4   Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "..                                                                                                  ...   \n",
       "37  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "38  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "39  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "40  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "41  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "\n",
       "                        folder  \\\n",
       "0   text/2023-06-20 discussion   \n",
       "1   text/2023-06-20 discussion   \n",
       "2   text/2023-06-20 discussion   \n",
       "3   text/2023-06-20 discussion   \n",
       "4   text/2023-06-20 discussion   \n",
       "..                         ...   \n",
       "37  text/2023-06-20 discussion   \n",
       "38  text/2023-06-20 discussion   \n",
       "39  text/2023-06-20 discussion   \n",
       "40  text/2023-06-20 discussion   \n",
       "41  text/2023-06-20 discussion   \n",
       "\n",
       "                                                                                                summary  \\\n",
       "0   A recent study looked into the differences in muscle function and recovery between young and mid...   \n",
       "1   Hey! I just came across some interesting health research on muscle aging and recovery. The study...   \n",
       "2   A recent study investigated the recovery response from a high-volume isokinetic resistance exerc...   \n",
       "3   Did you know that decreases in muscle mass, function, and activation can contribute to a decline...   \n",
       "4   A recent study in residential aged care facilities found that providing high calcium and high pr...   \n",
       "..                                                                                                  ...   \n",
       "37  Hey there! I just read an interesting health research study about dehydration and pain sensitivi...   \n",
       "38  Hey! I just read a fascinating study that found that mild dehydration can make women more sensit...   \n",
       "39  Hey there! I recently came across an interesting study that explored the effects of dehydration ...   \n",
       "40  Hey there! I just read a really fascinating study on weight stigma and its effects on health beh...   \n",
       "41  Hey! I just read an interesting study about weight stigma and its impact on health behaviors. Th...   \n",
       "\n",
       "                                                                                               headline  \\\n",
       "0                                         Ever wondered how aging affects muscle function and recovery?   \n",
       "1                                           Exciting New Research Findings on Muscle Aging and Recovery   \n",
       "2                                                    New Study on Muscle Recovery in Middle-Aged Adults   \n",
       "3     New Study Shows How Regular Resistance Training Can Improve Muscle Function in Middle-aged Adults   \n",
       "4   New research shows that a simple nutrition intervention can reduce the risk of falls and fractur...   \n",
       "..                                                                                                  ...   \n",
       "37                            New Research Findings: Dehydration May Increase Pain Sensitivity in Women   \n",
       "38                                      New study finds dehydration increases pain sensitivity in women   \n",
       "39                                        New Research: Dehydration Increases Pain Sensitivity in Women   \n",
       "40                                              New Research Shows How Weight Stigma Impacts Our Health   \n",
       "41                   Surprising Findings on the Relationship between Weight Stigma and Health Behaviors   \n",
       "\n",
       "                                                                                         simple_summary  \n",
       "0   Are you concerned about how aging may affect your ability to exercise and recover? Don't worry, ...  \n",
       "1   Hey! I just read an interesting research article that explains how staying physically active by ...  \n",
       "2   A fascinating new study discovered that muscle recovery is maintained in middle-aged men who reg...  \n",
       "3   Regular resistance training, such as weightlifting, can keep your muscles strong and help you re...  \n",
       "4   A recent study with over 7000 older adults found that providing extra servings of dairy foods co...  \n",
       "..                                                                                                  ...  \n",
       "37  Hey there! I just read an interesting health research study about dehydration and pain sensitivi...  \n",
       "38  Hey! I just read a really interesting study that found that not drinking enough fluids can actua...  \n",
       "39  Hey there! I just read about this fascinating study investigating the influence of dehydration a...  \n",
       "40  Hey there! I recently came across an interesting study examining weight stigma \\nand its effects...  \n",
       "41  Hey! I just read a really interesting study on how judging people based oh how they look affects...  \n",
       "\n",
       "[42 rows x 19 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "\n",
    "from db_session import *\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Text, TIMESTAMP, Numeric\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "import uuid\n",
    "import pandas as pd\n",
    "# from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Sources(Base):\n",
    "    __tablename__ = 'sources'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    title = mapped_column(String(255))\n",
    "    text = mapped_column(Text)\n",
    "    abstract = mapped_column(Text)\n",
    "    publication = mapped_column(String(100))\n",
    "    authors = mapped_column(String(300))\n",
    "    year = mapped_column(Integer)\n",
    "    month = mapped_column(String(10))\n",
    "    pub_volume = mapped_column(String(10))\n",
    "    pub_issue = mapped_column(String(10))\n",
    "    start_page = mapped_column(String(10))\n",
    "    end_page = mapped_column(String(10))\n",
    "    doi = mapped_column(String(50))\n",
    "    section = mapped_column(String(100))\n",
    "    summaries = relationship('Summaries', back_populates='sources')\n",
    "\n",
    "class Prompts(Base):\n",
    "    __tablename__ = 'prompts'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    full_template = mapped_column(Text)\n",
    "    system_role = mapped_column(String(300))\n",
    "    prep_steps = mapped_column(Text)\n",
    "    task = mapped_column(Text)\n",
    "    edit_steps = mapped_column(Text)\n",
    "    simplify_steps = mapped_column(Text)\n",
    "    audience = mapped_column(String(200))\n",
    "    format_steps = mapped_column(Text)\n",
    "\n",
    "    summaries = relationship('Summaries', back_populates='prompts')\n",
    "    \n",
    "class Summaries(Base):\n",
    "    __tablename__ = 'summaries'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    timestamp = mapped_column(TIMESTAMP(timezone=True))\n",
    "    original_summary = mapped_column(Text)\n",
    "    rating_original_content = mapped_column(Integer) \n",
    "    simple_summary = mapped_column(Text)\n",
    "    rating_simple_content = mapped_column(Integer) \n",
    "    original_headline = mapped_column(String(255))\n",
    "    prompt_id = mapped_column(Integer, ForeignKey('prompts.id'), autoincrement=False)\n",
    "    reference_id = mapped_column(Integer, ForeignKey('sources.id'), autoincrement=False)\n",
    "    choice = mapped_column(Integer)\n",
    "    model = mapped_column(String(70))\n",
    "    temperature = mapped_column(Numeric)\n",
    "\n",
    "    prompts = relationship('Prompts', back_populates='summaries')\n",
    "    sources = relationship('Sources', back_populates='summaries')\n",
    "\n",
    "@remote_sql_session\n",
    "def get_table(session, query='SELECT *', table='publications', limit=None, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return a database table as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    query_statement = f'{query} from {table}'\n",
    "    if order_by:\n",
    "        query_statement += f' ORDER BY {order_by} {order}'\n",
    "    if limit:\n",
    "        query_statement += f' LIMIT {limit}'\n",
    "    print(f'Query: {query_statement}')\n",
    "    q = session.execute(text(query_statement))\n",
    "    df = pd.DataFrame(q.fetchall())\n",
    "    return df\n",
    "\n",
    "\n",
    "def bulk_append(input_df, table='summaries', engine=None):\n",
    "    \"\"\"\n",
    "    Add articles to the `sources` table in the database from a dataframe containing article text and metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - references_df: pandas dataframe containing article text and metadata.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    @remote_sql_session\n",
    "    def insert_rows(session):\n",
    "        try:\n",
    "            print(f'Adding {len(input_df)} rows to the database...')\n",
    "            def insert_row(row):\n",
    "                if table == 'sources':\n",
    "                    data = Sources(\n",
    "                        title=row['title'],\n",
    "                        text=row['text'],\n",
    "                        abstract=row['abstract'],\n",
    "                        publication=row['publication'],\n",
    "                        authors=row['authors'],\n",
    "                        year=row['year'],\n",
    "                        month=row['month'],\n",
    "                        pub_volume=row['pub_volume'],\n",
    "                        pub_issue=row['pub_issue'],\n",
    "                        start_page=row['start_page'],\n",
    "                        end_page=row['end_page'],\n",
    "                        doi=row['doi'],\n",
    "                        section=row['section'] \n",
    "                    )\n",
    "                    session.add(data)\n",
    "                    print(f'\\t{row[\"title\"]}')\n",
    "                elif table == 'summaries':\n",
    "                    prompt = session.query(Prompts).filter_by(\n",
    "                        full_template=row['full_summarize_task'],\n",
    "                        system_role=row['system_role'],\n",
    "                    ).first()\n",
    "                    if prompt:\n",
    "                        prompt_id = prompt.id\n",
    "                    else:\n",
    "                        prompt = Prompts(\n",
    "                            full_template=row['full_summarize_task'],\n",
    "                            prep_steps=row['prep_step'],\n",
    "                            task=row['summarize_task'],\n",
    "                            edit_steps=row['edit_task'],\n",
    "                            audience=row['simplify_audience'],\n",
    "                            simplify_steps=row['simplify_task'],\n",
    "                            format_steps=row['format_task'],\n",
    "                            system_role=row['system_role']\n",
    "                        )\n",
    "                        session.add(prompt)\n",
    "                        session.flush()\n",
    "                        prompt_id = prompt.id\n",
    "\n",
    "                    summary = Summaries(\n",
    "                        timestamp=row['timestamp'],\n",
    "                        original_summary=row['summary'],\n",
    "                        simple_summary=row['simple_summary'],\n",
    "                        original_headline=row['headline'],\n",
    "                        prompt_id=prompt_id,\n",
    "                        reference_id=row['reference_id'],\n",
    "                        choice=row['choice'],\n",
    "                        model=row['model'],\n",
    "                        temperature=row['temperature']\n",
    "                    )\n",
    "                    session.add(summary)\n",
    "                    print(f'\\tReference #{row[\"reference_id\"]}: {row[\"headline\"]}')\n",
    "\n",
    "            input_df.apply(insert_row, axis=1)\n",
    "\n",
    "            session.commit()\n",
    "            print(\"Data added successfully!\")\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"Error adding data to the database: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    return insert_rows()\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "from response_processing import *\n",
    "import time\n",
    "import pytz\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "from prompts import *\n",
    "\n",
    "class Chaining:\n",
    "    def __init__(self, text_id, title, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=9000, \n",
    "        ):\n",
    "        self.reference_id = text_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*\\/.*)\\/?$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "        print(f'***OpenAI model: {self.model}')\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature, model=None):\n",
    "        model = self.model if model == None else model\n",
    "        print(f'\\tSending request to {model}')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(\n",
    "            self, task, prep_step, edit_task, simplify_task, simplify_audience,\n",
    "            format_task,\n",
    "            n_choices=5, task_first=True):\n",
    "        if task_first == True:\n",
    "            full_task = f'{task}\\n\\n{prep_step}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        else:\n",
    "            full_task = f'{prep_step}\\n\\n{task}\\n\\n{edit_task}\\n\\n{simplify_task} {simplify_audience}\\n\\n{format_task}'\n",
    "        prompt = self.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['timestamp'] = str(datetime.now(pytz.timezone('Canada/Pacific')))\n",
    "        self.qna['reference_id'] = self.reference_id\n",
    "        self.qna['article_title'] = self.title\n",
    "        self.qna['text'] = self.text\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model        \n",
    "        self.qna['temperature'] = self.temperature\n",
    "        self.qna['prep_step'] = prep_step.strip()\n",
    "        self.qna['summarize_task'] = task.strip()\n",
    "        self.qna['edit_task'] = edit_task.strip()\n",
    "        self.qna['simplify_task'] = simplify_task.strip()\n",
    "        self.qna['simplify_audience'] = simplify_audience.strip()\n",
    "        self.qna['format_task'] = format_task.strip()\n",
    "        self.qna['full_summarize_task'] = full_task.strip()\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = self.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "    \n",
    "def batch_summarize(sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "    simplify_task, simplify_audience, format_task,\n",
    "    chaining_bot_dict, iteration_id, task_first=True,\n",
    "    system_role=None, model='gpt-3.5-turbo', max_tokens=1000, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False\n",
    "    ):\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task, simplify_task, simplify_audience, format_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task', 'simplify_task', 'simplify_audience', 'format_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    def summarize_from_df_row(text_id, title, text, chaining_bot_dict):\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{text_id} prompt #{index+1} of {prompts_df.index.max()+1}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            simplify_task = prompts_df.loc[index, 'simplify_task']\n",
    "            simplify_audience = prompts_df.loc[index, 'simplify_audience']\n",
    "            format_task = prompts_df.loc[index, 'format_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text_id, title, text, folder_path=folder_path, system_role=system_role, \n",
    "                    model=model, max_tokens=max_tokens, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, \n",
    "                    simplify_task=simplify_task, simplify_audience=simplify_audience,\n",
    "                    format_task=format_task, n_choices=n_choices, task_first=task_first\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'{text_id}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Completed')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    sources_df.apply(lambda row: summarize_from_df_row(row['id'], row['title'], row['text'], chaining_bot_dict), axis=1)\n",
    "    \n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=folder_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try:\n",
    "            dfs_list.append(pd.DataFrame(\n",
    "                chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "                index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            print(f'\\tAn error occurred on line {lineno} in {filename}: {error}')    \n",
    "            print(f'Error creating DataFrame from {chatbot_key}: {error}')\n",
    "\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    qna_df = extract_summary(qna_df, 'summary')\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "import json\n",
    "def extract_summary(df, summary_column='summary'):\n",
    "    # Convert the string to JSON\n",
    "    try:\n",
    "        df[summary_column] = df[summary_column].apply(json.loads)\n",
    "    except Exception as error:\n",
    "        print(f'Error converting {summary_column} column to JSON: {error}; will do row by row')\n",
    "        summary_list = []\n",
    "        for index, summary in df[summary_column].items():\n",
    "            try:\n",
    "                summary_list.append(json.loads(summary))\n",
    "            except Exception as error:\n",
    "                print(f'Error converting summary {index} to JSON: {error}')\n",
    "                summary_list.append(summary)\n",
    "    def extract_value_from_key(summary, key):\n",
    "        try:\n",
    "            return summary[key]\n",
    "        except Exception as error:\n",
    "            match = re.search(rf'\"{key}\":\\s*\"([^\"]+)\"', summary)\n",
    "            value = match.group(1) if match else None\n",
    "            return value\n",
    "\n",
    "    # Extract 'headline' and 'body' values\n",
    "    df['headline'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'headline'))\n",
    "    df['simple_summary'] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'audience'))\n",
    "    df[summary_column] = df[summary_column].apply(lambda x: extract_value_from_key(x, 'body'))\n",
    "    df['simple_summary'] = df['simple_summary'].fillna(df[summary_column])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "article_limit = None\n",
    "temperature = 1.5\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=True\n",
    "folder_path = folder_path\n",
    "# summaries = get_table(table='summaries')\n",
    "\n",
    "\n",
    "# sources_df = get_table(table='sources', limit=article_limit)\n",
    "# # sources_df\n",
    "\n",
    "# chaining_dict = batch_summarize(\n",
    "#     sources_df, folder_path, prep_step, summarize_task, edit_task, \n",
    "#     simplify_task, simplify_audience, format_task,\n",
    "#     chatbot_dict, temperature=temperature,\n",
    "#     system_role=system_role, model=model, max_tokens=1000,\n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "# # chaining_dict[iteration_id]\n",
    "qna_dict = create_summaries_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "    )\n",
    "# # Add rows from results to summaries and prompts table\n",
    "# bulk_append(qna_dict[iteration_id])\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-13 11:21:41.933263-07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Exercise Snacks A Novel Strategy to Improve Cardiometabolic Health</td>\n",
       "      <td>2</td>\n",
       "      <td>We define exercise snacks as isolated ?1-min bouts of vigorous exercise performed periodically t...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>A recent study suggests that exercise snacks, which are short bursts of vigorous exercise perfor...</td>\n",
       "      <td>Exercise Snacks: A Time-Efficient Way to Improve Health</td>\n",
       "      <td>Did you know that exercising for just a minute here and there throughout the day can actually im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-07-13 11:21:56.705152-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...</td>\n",
       "      <td>1</td>\n",
       "      <td>The United States is at the forefront of the global obesity epidemic with 67% of its population ...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>Hey! I just read an interesting study about the effects of food cues and stress on food craving ...</td>\n",
       "      <td>New research on food cravings and stress</td>\n",
       "      <td>Hey! I just read a really interesting study about how our environment (like seeing food or feeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-07-13 11:22:02.529183-07:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...</td>\n",
       "      <td>2</td>\n",
       "      <td>The United States is at the forefront of the global obesity epidemic with 67% of its population ...</td>\n",
       "      <td>You are someone who loves to read health research and tell your friends about it.</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>1.5</td>\n",
       "      <td>In the summary, cover the following information:     \\n- Identify the key points and statistics ...</td>\n",
       "      <td>Write a casual text message to your friend about the research.</td>\n",
       "      <td>Once you have written your text message:     \\nEvaluate your text message to see if it may be co...</td>\n",
       "      <td>3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...</td>\n",
       "      <td>people without a science background</td>\n",
       "      <td>4. Return your final response in a JSON format with the following format:     \\n{\"headline\": &lt;su...</td>\n",
       "      <td>Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...</td>\n",
       "      <td>text/2023-06-20 discussion</td>\n",
       "      <td>A recent study examined the effects of food cue exposure and stress on highly palatable food cra...</td>\n",
       "      <td>New study explores the links between food cues, stress, and overeating</td>\n",
       "      <td>Can you believe this new study on how food cues and stress influence our cravings and food intak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "9   2023-07-13 11:21:41.933263-07:00             3   \n",
       "12  2023-07-13 11:21:56.705152-07:00             4   \n",
       "15  2023-07-13 11:22:02.529183-07:00             4   \n",
       "\n",
       "                                                                                          article_title  \\\n",
       "9                                    Exercise Snacks A Novel Strategy to Improve Cardiometabolic Health   \n",
       "12  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...   \n",
       "15  Food craving, cortisol and ghrelin responses in modeling highly palatable snack intake in the la...   \n",
       "\n",
       "    choice  \\\n",
       "9        2   \n",
       "12       1   \n",
       "15       2   \n",
       "\n",
       "                                                                                                   text  \\\n",
       "9   We define exercise snacks as isolated ?1-min bouts of vigorous exercise performed periodically t...   \n",
       "12  The United States is at the forefront of the global obesity epidemic with 67% of its population ...   \n",
       "15  The United States is at the forefront of the global obesity epidemic with 67% of its population ...   \n",
       "\n",
       "                                                                          system_role  \\\n",
       "9   You are someone who loves to read health research and tell your friends about it.   \n",
       "12  You are someone who loves to read health research and tell your friends about it.   \n",
       "15  You are someone who loves to read health research and tell your friends about it.   \n",
       "\n",
       "                     model  temperature  \\\n",
       "9   gpt-3.5-turbo-16k-0613          1.5   \n",
       "12  gpt-3.5-turbo-16k-0613          1.5   \n",
       "15  gpt-3.5-turbo-16k-0613          1.5   \n",
       "\n",
       "                                                                                              prep_step  \\\n",
       "9   In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "12  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "15  In the summary, cover the following information:     \\n- Identify the key points and statistics ...   \n",
       "\n",
       "                                                    summarize_task  \\\n",
       "9   Write a casual text message to your friend about the research.   \n",
       "12  Write a casual text message to your friend about the research.   \n",
       "15  Write a casual text message to your friend about the research.   \n",
       "\n",
       "                                                                                              edit_task  \\\n",
       "9   Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "12  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "15  Once you have written your text message:     \\nEvaluate your text message to see if it may be co...   \n",
       "\n",
       "                                                                                          simplify_task  \\\n",
       "9   3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "12  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "15  3. If needed, rewrite the text using terms appropriate for the audience. If not keep it the same...   \n",
       "\n",
       "                      simplify_audience  \\\n",
       "9   people without a science background   \n",
       "12  people without a science background   \n",
       "15  people without a science background   \n",
       "\n",
       "                                                                                            format_task  \\\n",
       "9   4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "12  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "15  4. Return your final response in a JSON format with the following format:     \\n{\"headline\": <su...   \n",
       "\n",
       "                                                                                    full_summarize_task  \\\n",
       "9   Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "12  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "15  Write a casual text message to your friend about the research.\\n\\nIn the summary, cover the foll...   \n",
       "\n",
       "                        folder  \\\n",
       "9   text/2023-06-20 discussion   \n",
       "12  text/2023-06-20 discussion   \n",
       "15  text/2023-06-20 discussion   \n",
       "\n",
       "                                                                                                summary  \\\n",
       "9   A recent study suggests that exercise snacks, which are short bursts of vigorous exercise perfor...   \n",
       "12  Hey! I just read an interesting study about the effects of food cues and stress on food craving ...   \n",
       "15  A recent study examined the effects of food cue exposure and stress on highly palatable food cra...   \n",
       "\n",
       "                                                                  headline  \\\n",
       "9                  Exercise Snacks: A Time-Efficient Way to Improve Health   \n",
       "12                                New research on food cravings and stress   \n",
       "15  New study explores the links between food cues, stress, and overeating   \n",
       "\n",
       "                                                                                         simple_summary  \n",
       "9   Did you know that exercising for just a minute here and there throughout the day can actually im...  \n",
       "12  Hey! I just read a really interesting study about how our environment (like seeing food or feeli...  \n",
       "15  Can you believe this new study on how food cues and stress influence our cravings and food intak...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].loc[[9, 12, 15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 42 rows to the database...\n",
      "\tReference #1: Ever wondered how aging affects muscle function and recovery?\n",
      "\tReference #1: Exciting New Research Findings on Muscle Aging and Recovery\n",
      "\tReference #1: New Study on Muscle Recovery in Middle-Aged Adults\n",
      "\tReference #1: New Study Shows How Regular Resistance Training Can Improve Muscle Function in Middle-aged Adults\n",
      "\tReference #2: New research shows that a simple nutrition intervention can reduce the risk of falls and fractures in older adults\n",
      "\tReference #2: Exciting Research: Nutrition Intervention Reduces Fracture Risk in Older Adults\n",
      "\tReference #2: Important research on fracture prevention and nutritional intervention!\n",
      "\tReference #2: New research shows how dairy foods may reduce fractures and falls in older adults\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Approach to Improve Health\n",
      "\tReference #3: Exercise Snacks: A Time-Efficient Way to Improve Health\n",
      "\tReference #3: Take exercise breaks to improve cardiorespiratory fitness and combat a sedentary lifestyle!\n",
      "\tReference #3: Exciting New Research: Exercise Snacks for a Healthy Lifestyle\n",
      "\tReference #4: New research on food cravings and stress\n",
      "\tReference #4: New Research Reveals how Food Cues and Stress Increase Cravings and Intake of Junk Food\n",
      "\tReference #4: New Research Shows How Food Cues and Stress affect Eating Behavior\n",
      "\tReference #4: New study explores the links between food cues, stress, and overeating\n",
      "\tReference #5: New Research Shows How Dehydration can Increase Pain Sensitivity\n",
      "\tReference #5: New Research Finds That Mild Dehydration Increases Pain Sensitivity in Women\n",
      "\tReference #5: New Research: Dehydration can Increase Pain Sensitivity in Women\n",
      "\tReference #5: New research suggests that not drinking enough water can increase pain sensitivity in women.\n",
      "\tReference #6: New research finds weight stigma affects various health behaviors\n",
      "\tReference #6: Weight Stigma Hurts Health Behaviors\n",
      "\tReference #6: New Research on Weight Stigma and Health Behaviors\n",
      "\tReference #6: New Research Shows Weight Stigma Contributes to Poor Health Behaviors\n",
      "\tReference #13: Exciting Findings on Exercise Recovery for Middle-Aged Adults\n",
      "\tReference #13: Interesting Findings on Muscle Recovery from Exercise\n",
      "\tReference #13: New Study Finds Middle-Aged Adults Can Recover Well After Exercise\n",
      "\tReference #13: New Research on Recovery from Exercise in Middle-Aged Adults\n",
      "\tReference #14: New Research: Dairy Foods Reduce Fracture Risk in Older Adults\n",
      "\tReference #14: Nutritional Approach Shows Promising Results for Reducing Fracture Risk in Older Adults\n",
      "\tReference #14: Research reveals calcium and protein-rich diet reduces risk of fractures in older adults\n",
      "\tReference #14: New Dairy-Based Health Discovery - Could This Be the Key to Fewer Fractures in Older Adults?\n",
      "\tReference #15: New Study Reveals the Link Between Food Craving and Stress\n",
      "\tReference #15: New study uncovers cravings for unhealthy food and their impact on weight gain\n",
      "\tReference #15: New Research on Food Craving and Intake in Relation to Stress and Food Cues\n",
      "\tReference #15: New study explores the influence of food cues and stress on food cravings and snacking\n",
      "\tReference #16: New Study Shows How Dehydration Might Increase Pain Sensitivity\n",
      "\tReference #16: New Research Findings: Dehydration May Increase Pain Sensitivity in Women\n",
      "\tReference #16: New study finds dehydration increases pain sensitivity in women\n",
      "\tReference #16: New Research: Dehydration Increases Pain Sensitivity in Women\n",
      "\tReference #17: New Research Shows How Weight Stigma Impacts Our Health\n",
      "\tReference #17: Surprising Findings on the Relationship between Weight Stigma and Health Behaviors\n",
      "Data added successfully!\n"
     ]
    }
   ],
   "source": [
    "bulk_append(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
