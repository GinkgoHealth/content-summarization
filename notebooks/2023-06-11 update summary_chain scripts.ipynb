{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "import time\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "\n",
    "from response_processing import *\n",
    "from article_processing import create_text_dict_from_folder\n",
    "import traceback\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wrangling import filter_df_all_conditions, filter_df_any_condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        system_role=\"You are an expert at science communication.\"):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            self.summaries_dict['prep_step'] = prep_step\n",
    "            self.summaries_dict['task'] = task\n",
    "            self.summaries_dict['prompt'] = full_task\n",
    "            return self.qna\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "            return self.qna\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, qna_dict, chaining_bot_dict, iteration_id, \n",
    "    temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna_dict: dict\n",
    "            A dictionary containing the results of the summarization process. The keys of the dictionary are the iteration IDs and the values are pandas dataframes containing the summaries for each text ID\n",
    "\n",
    "    \"\"\"\n",
    "    temp_qna_dict = dict()\n",
    "    qna_dfs_list = []\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task), \n",
    "        columns=['prep_step', 'summarize_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        temp_qna_dict[key] = dict()\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                temp_qna_dict[key][index] = chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            updated_qna_dict = (temp_qna_dict[key])\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('Error concatenating prompts DataFrame')\n",
    "            return temp_qna_dict, chaining_bot_dict\n",
    "        qna_dfs_list.append(updated_qna_dict)\n",
    "    try:\n",
    "        qna_dict[iteration_id] = pd.concat([\n",
    "            pd.DataFrame(\n",
    "                data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "            ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "        ])\n",
    "        qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "        print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "        if save_outputs:\n",
    "            try:\n",
    "                save_output(\n",
    "                    qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "                    csv_path=csv_path, pickle_path=pickle_path)\n",
    "                save_instance_to_dict(\n",
    "                    chaining_bot_dict[iteration_id], \n",
    "                    description=f'batch_Chaining_attributes',\n",
    "                    pickle_path=pickle_path, json_path=json_path\n",
    "                    )\n",
    "            except:\n",
    "                print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        qna_dict[iteration_id] = qna_dfs_list\n",
    "        print('Error creating DataFrame; dictionary returned instead')\n",
    "    return qna_dict, chaining_bot_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    summary_iteration_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    summary_iteration_id = summary_iteration_id if summary_iteration_id else iteration_id\n",
    "    print('summary_iteration_id:', summary_iteration_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a headline to hook the audience.\\\n",
    "    \\nReturn your response as the headline followed by the final version of the summary, \\\n",
    "    separated by a blank line.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text dictionary\n",
    "folder_path = '../text/2023-06-11' # ** UPDATE REQUIRED**\n",
    "\n",
    "encoding='ISO-8859-1'\n",
    "subset=None\n",
    "\n",
    "text_dict = create_text_dict_from_folder(folder_path, encoding=encoding, subset=subset)\n",
    "\n",
    "\n",
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "chain_results_dict = dict()\n",
    "qna_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 2: 'Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study employed a two-stage research investigation to examine the relationship between weight stigma and several health behaviors in a large sample of U.S. adults. As predicted, weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. No such relationship was observed for physical activity.\\nTargeting health behaviors (e.g., eating) to achieve weight loss is common in weight-focused health promotion policies. These policies assume that individuals can improve their health by losing weight, employing weight stigma as one strategy for motivating behavior change [5]. However, our findings indicate that weight stigma is associated with poorer health behaviors, independent of BMI. Given that physical health and weight are largely shaped by factors outside of an individual\\x92s control (i.e., genetics and social determinants like socioeconomic status) [5], it is concerning that multiple behaviors, for which individuals have some control over, may be undermined by weight stigma.\\nFurthermore, a lower BMI may not necessarily be protective against weight stigma. In our sample, individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. In fact, moderation analyses indicated that individuals with\\xa0lower\\xa0BMIs showed greater disordered eating and alcohol use in the face of weight stigma. These results emerged despite individuals with higher weight reporting greater daily weight stigma. One explanation for the observed differences in health behavioral outcomes across the weight spectrum is that infrequent health behaviors may be less likely to be enacted as coping strategies. For instance, previous research has shown that alcohol use decreases as BMI increases among females with higher weight [44]. Thus, using food, instead of alcohol, may be the more common coping strategy among individuals with higher BMIs, as previous research suggests [45]. Nonetheless, the sizes of the moderation effects were very small, with some confidence intervals functionally at zero, and thus further interpretation of the present findings should only be done with caution.\\nPrior research has found conflicting evidence for the relationship between weight stigma and physical activity. Some studies have found that greater weight stigma is associated with short-term increases in reported exercise behavior [16,\\xa046]. Others have shown that weight stigma is positively correlated with increased exercise avoidance, but has no direct link to self-reported exercise [14,\\xa047]. The current study adds to the latter base of evidence showing no relationship between weight stigma and physical activity. One possible explanation is that participants were asked about their daily experiences with weight stigma, which may not correspond to their level of physical activity over the past month. Ecological momentary assessment methodology may provide better insight into this relationship, as demonstrated by Vartanian et al. who examined health motivations following stigmatizing events in daily life [48].\\nDespite emerging evidence that weight stigma is prevalent among men [28], there is a lack of research on men\\x92s health outcomes related to weight stigma. In this study, moderation by gender was not observed for any outcome. These results are consistent with previous research reporting no gender differences in poor health outcomes such as mortality and obesity due to weight stigma [3,\\xa049]. Men may also feel pressured to meet societal body standards and thus may display the same magnitude of associations between weight stigma and health behaviors. It is recommended that the null gender findings are interpreted with caution, as more research is needed.\\nHow might weight stigma influence an individual\\x92s health behaviors? One potential mechanism is stress. Previous work suggests that weight stigma is stressful [6,\\xa050] and experimental lab studies manipulating weight stigma have shown that individuals with higher weight, as well as those who perceive themselves as overweight, show elevated levels of the stress hormone cortisol following exposure to a weight-stigmatizing event [51,\\xa052]. Additionally, some research has found that individuals who experience more weight-based discrimination have higher hair cortisol levels\\x97a finding most pronounced in those at the highest BMI [53]. Individuals who experience greater stress may engage in more unhealthy coping behaviors. Indeed, stress can drive changes in behaviors such as eating, physical activity, and sleep [54]. For example, Tataranni et al. administered synthetic cortisol vs. placebo and found greater food consumption in the cortisol group [55]. This early work is supported by accumulating evidence that cortisol is associated with increased caloric intake and greater abdominal fat storage [56]. The health behavior pathway may not be independent from that of stress but rather reflect a serial mediation model, wherein weight stigma increases stress that in turn causes decrements in health behaviors.\\nThe present study contributes to the weight stigma literature in several ways. As noted, a key strength of this study is the assessment of several health behaviors within a large, national census-matched sample. Previous studies that have examined weight stigma in relation to different health behaviors have often had small sample sizes or were limited to female subjects. Thus, the present study may provide more generalizable information about health behaviors in the U.S. A related strength of the study is that higher BMI scores were well-represented in the sample, with 31.4% meeting BMI criteria for obesity. This is a closer estimate of the proportion of the American population that is classified with obesity (42%) compared to previous studies [57]. Therefore, there is greater confidence that these findings reflect the experiences of individuals with obesity in the population, aiding generalizability. Lastly, we enhance reproducibility by presenting a two-stage research program of exploratory and confirmatory analyses based on recommended open science practices.\\nThere are some limitations to consider. First, a composite weight stigma score was used due to survey constraints. While early tests indicate good construct validity, additional psychometric testing is warranted (see Online Supplementary Materials\\xa04). Another limitation is the use of self-reported weight, which is subject to inaccuracies. Additionally, the data collection period overlapped with winter holidays. Individuals may have made new year\\x92s health resolutions, and therefore the self-reported health behaviors may be more indicative of newly established goals rather than typical health habits. However, such resolutions would likely dampen, rather than magnify, the relationship between weight stigma and poor health behaviors. Lastly, the study is cross-sectional and therefore causal direction cannot be determined. Weight stigma may operate as a feedback loop that leads to weight gain through certain behaviors such as comfort eating [6], but further investigation is required. Given survey constraints, weight bias internalization was not assessed. Future research should build on these findings to determine the potential role of weight bias internalization in these health behaviors.\\nDespite these limitations, these study\\x92s findings show that weight stigma is significantly associated with several health behaviors. If future research confirms that this is indeed a causal relationship, weight stigma could cumulatively undermine physical health over time. Taken together, these findings highlight weight stigma as a potential barrier to healthy behaviors, and suggest that one strategy to improve population health may be to reduce weight stigma. Though more research is needed, it may be important to employ more weight-inclusive approaches to health promotion, such as removing stigmatizing language or weight outcomes from health policies and program objectives [5].\\n\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(text_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Update messages and class attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        # try:\n",
    "        #     response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        # except Exception as error:\n",
    "        #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "        #     f = tb.tb_frame\n",
    "        #     lineno = tb.tb_lineno\n",
    "        #     filename = f.f_code.co_filename\n",
    "        #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        #     print('\\t**API request failed for `.summarize()`**')\n",
    "        #     return self.qna\n",
    "        # try:\n",
    "        #     for index, choice in enumerate(response.choices):\n",
    "        #         self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "        #     self.qna.setdefault('summary', [])\n",
    "        #     self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "        #     self.summaries_dict['prep_step'] = prep_step\n",
    "        #     self.summaries_dict['task'] = task\n",
    "        #     self.summaries_dict['prompt'] = full_task\n",
    "        #     return self.qna\n",
    "        # except Exception as error:\n",
    "        #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "        #     f = tb.tb_frame\n",
    "        #     lineno = tb.tb_lineno\n",
    "        #     filename = f.f_code.co_filename\n",
    "        #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        #     print('\\t**Error with response parsing**')\n",
    "        #     return self.qna\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna_dict: dict\n",
    "            A dictionary containing the results of the summarization process. The keys of the dictionary are the iteration IDs and the values are pandas dataframes containing the summaries for each text ID\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "    #     try:\n",
    "    #         updated_qna_dict = (temp_qna_dict[key])\n",
    "    #     except Exception as error:\n",
    "    #         exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #         f = tb.tb_frame\n",
    "    #         lineno = tb.tb_lineno\n",
    "    #         filename = f.f_code.co_filename\n",
    "    #         print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #         print('Error concatenating prompts DataFrame')\n",
    "    #         return temp_qna_dict, chaining_bot_dict\n",
    "    #     qna_dfs_list.append(updated_qna_dict)\n",
    "    # try:\n",
    "    #     qna_dict[iteration_id] = pd.concat([\n",
    "    #         pd.DataFrame(\n",
    "    #             data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "    #         ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "    #     ])\n",
    "    #     qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "    #     print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "    #     if save_outputs:\n",
    "    #         try:\n",
    "    #             save_output(\n",
    "    #                 qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "    #                 csv_path=csv_path, pickle_path=pickle_path)\n",
    "    #             save_instance_to_dict(\n",
    "    #                 chaining_bot_dict[iteration_id], \n",
    "    #                 description=f'batch_Chaining_attributes',\n",
    "    #                 pickle_path=pickle_path, json_path=json_path\n",
    "    #                 )\n",
    "    #         except:\n",
    "    #             print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    # except Exception as error:\n",
    "    #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #     f = tb.tb_frame\n",
    "    #     lineno = tb.tb_lineno\n",
    "    #     filename = f.f_code.co_filename\n",
    "    #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #     qna_dict[iteration_id] = qna_dfs_list\n",
    "    #     print('Error creating DataFrame; dictionary returned instead')\n",
    "    # return qna_dict, chaining_bot_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <__main__.Chaining at 0x198fa2e0d90>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x198fa2e1450>}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       " 'summarization task': 'summarize for a LinkedIn post.',\n",
       " 'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       " 'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict[1]['text1_prompt00'].qna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "Identify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \n",
      "Based on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \n",
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     separated by a blank line.\n"
     ]
    }
   ],
   "source": [
    "print(chaining_dict[1]['text1_prompt00'].qna['full summarization task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a helpful assistant.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.'},\n",
       " 'summaries_dict': {},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {},\n",
       " 'relevance_dict': {},\n",
       " 'n_previous_prompts': {}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(chaining_dict[1]['text1_prompt00'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Send to ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna_dict: dict\n",
    "            A dictionary containing the results of the summarization process. The keys of the dictionary are the iteration IDs and the values are pandas dataframes containing the summaries for each text ID\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "    #     try:\n",
    "    #         updated_qna_dict = (temp_qna_dict[key])\n",
    "    #     except Exception as error:\n",
    "    #         exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #         f = tb.tb_frame\n",
    "    #         lineno = tb.tb_lineno\n",
    "    #         filename = f.f_code.co_filename\n",
    "    #         print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #         print('Error concatenating prompts DataFrame')\n",
    "    #         return temp_qna_dict, chaining_bot_dict\n",
    "    #     qna_dfs_list.append(updated_qna_dict)\n",
    "    # try:\n",
    "    #     qna_dict[iteration_id] = pd.concat([\n",
    "    #         pd.DataFrame(\n",
    "    #             data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "    #         ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "    #     ])\n",
    "    #     qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "    #     print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "    #     if save_outputs:\n",
    "    #         try:\n",
    "    #             save_output(\n",
    "    #                 qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "    #                 csv_path=csv_path, pickle_path=pickle_path)\n",
    "    #             save_instance_to_dict(\n",
    "    #                 chaining_bot_dict[iteration_id], \n",
    "    #                 description=f'batch_Chaining_attributes',\n",
    "    #                 pickle_path=pickle_path, json_path=json_path\n",
    "    #                 )\n",
    "    #         except:\n",
    "    #             print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    # except Exception as error:\n",
    "    #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #     f = tb.tb_frame\n",
    "    #     lineno = tb.tb_lineno\n",
    "    #     filename = f.f_code.co_filename\n",
    "    #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #     qna_dict[iteration_id] = qna_dfs_list\n",
    "    #     print('Error creating DataFrame; dictionary returned instead')\n",
    "    # return qna_dict, chaining_bot_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <__main__.Chaining at 0x22979a07b90>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x229799d4250>}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text1_prompt00'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(chaining_dict[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Chaining at 0x22979a07b90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict[1][next(iter(chaining_dict[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a helpful assistant.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       "  'summary': ['High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       "   'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.']},\n",
       " 'summaries_dict': {'response_01': 'High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       "  'response_02': 'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {},\n",
       " 'relevance_dict': {},\n",
       " 'n_previous_prompts': {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(chaining_dict[1][next(iter(chaining_dict[1]))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sample_Chaining_attr` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def sample_Chaining_attr(chaining_dict=chaining_dict, iteration_id=iteration_id):\n",
    "    return (vars(chaining_dict[iteration_id][next(iter(chaining_dict[iteration_id]))]))\n",
    "\n",
    "# sample_Chaining_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_01': 'High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       " 'response_02': 'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr()['summaries_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'system_role': 'You are a helpful assistant.',\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       " 'summarization task': 'summarize for a LinkedIn post.',\n",
       " 'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       " 'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     separated by a blank line.',\n",
       " 'summary': ['High calcium and high protein dairy foods may reduce risk of fractures and falls in institutionalized older adults. This nutritional approach was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The study intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and compliance was optimized by supervised provision and consumption of the foods. Milk consumption did not differ between the intervention and control groups. This research could be helpful for healthcare professionals working with older adults in residential care. \\n\\nHeadline: Nutritional Approach May Reduce Risk of Fractures and Falls in Institutionalized Older Adults',\n",
       "  'High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA cluster randomized controlled trial found that older adults in residential care who consumed high calcium and protein dairy foods had a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls compared to controls. The study targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common. Compliance was optimized by supervised provision and consumption of the foods, and participants lost to follow-up were replaced by newly admitted residents. The intervention produced two unanticipated novel observations: the risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis.']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr()['qna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think about why this might be relevant for the audience in the grand scheme of things.    \n",
      "Identify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \n",
      "Based on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \n",
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     separated by a blank line.\n"
     ]
    }
   ],
   "source": [
    "print(sample_Chaining_attr()['qna']['full summarization task'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Create summaries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    iteration_id = chatbot_id if chatbot_id != None else iteration_id\n",
    "    for chatbot_key in chatbot_dict[iteration_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(chatbot_dict[iteration_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "    \n",
    "    return dfs_list\n",
    "    qna_df = pd.concat(dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df\n",
    "    return qna_dict\n",
    "\n",
    "    #     try:\n",
    "    #         updated_qna_dict = (temp_qna_dict[key])\n",
    "    #     except Exception as error:\n",
    "    #         exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #         f = tb.tb_frame\n",
    "    #         lineno = tb.tb_lineno\n",
    "    #         filename = f.f_code.co_filename\n",
    "    #         print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #         print('Error concatenating prompts DataFrame')\n",
    "    #         return temp_qna_dict, chaining_bot_dict\n",
    "    #     qna_dfs_list.append(updated_qna_dict)\n",
    "    # try:\n",
    "    #     qna_dict[iteration_id] = pd.concat([\n",
    "    #         pd.DataFrame(\n",
    "    #             data, index=[choice for choice in range(1, len(data['summary'])+1)]\n",
    "    #         ) for dictionary in qna_dfs_list for data in dictionary.values()\n",
    "    #     ])\n",
    "    #     qna_dict[iteration_id].reset_index(inplace=True, names=['choice'])\n",
    "    #     print('DataFrame shape:', qna_dict[iteration_id].shape)\n",
    "    #     if save_outputs:\n",
    "    #         try:\n",
    "    #             save_output(\n",
    "    #                 qna_dict[iteration_id], description='batch_Chaining_summaries',\n",
    "    #                 csv_path=csv_path, pickle_path=pickle_path)\n",
    "    #             save_instance_to_dict(\n",
    "    #                 chaining_bot_dict[iteration_id], \n",
    "    #                 description=f'batch_Chaining_attributes',\n",
    "    #                 pickle_path=pickle_path, json_path=json_path\n",
    "    #                 )\n",
    "    #         except:\n",
    "    #             print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "    # except Exception as error:\n",
    "    #     exc_type, exc_obj, tb = sys.exc_info()\n",
    "    #     f = tb.tb_frame\n",
    "    #     lineno = tb.tb_lineno\n",
    "    #     filename = f.f_code.co_filename\n",
    "    #     print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "    #     qna_dict[iteration_id] = qna_dfs_list\n",
    "    #     print('Error creating DataFrame; dictionary returned instead')\n",
    "    # return qna_dict, chaining_bot_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id\n",
    "#     )\n",
    "\n",
    "qna_dict = dict()\n",
    "qna_dict = create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <__main__.Chaining at 0x22979a07b90>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x229799d4250>}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   choice  \\\n",
       " 0       0   \n",
       " 1       1   \n",
       " \n",
       "                                                                                          article_title  \\\n",
       " 0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " 1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " \n",
       "                     system_role          model  \\\n",
       " 0  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " 1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " \n",
       "                                                                                                   text  \\\n",
       " 0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " 1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       " \n",
       "                                                                                              prep step  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                summarization task  \\\n",
       " 0  summarize for a LinkedIn post.   \n",
       " 1  summarize for a LinkedIn post.   \n",
       " \n",
       "                                                                                              edit task  \\\n",
       " 0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " 1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " \n",
       "                                                                                full summarization task  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                                                                                                summary  \n",
       " 0  High calcium and high protein dairy foods may reduce risk of fractures and falls in institutiona...  \n",
       " 1  High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA...  ,\n",
       "    choice  \\\n",
       " 0       0   \n",
       " 1       1   \n",
       " \n",
       "                                                                                          article_title  \\\n",
       " 0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " 1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " \n",
       "                     system_role          model  \\\n",
       " 0  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " 1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       " \n",
       "                                                                                                   text  \\\n",
       " 0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " 1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       " \n",
       "                                                                                              prep step  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                summarization task  \\\n",
       " 0  summarize for a LinkedIn post.   \n",
       " 1  summarize for a LinkedIn post.   \n",
       " \n",
       "                                                                                              edit task  \\\n",
       " 0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " 1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       " \n",
       "                                                                                full summarization task  \\\n",
       " 0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " 1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       " \n",
       "                                                                                                summary  \n",
       " 0  Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...  \n",
       " 1  Weight stigma may undermine healthy behaviors, according to a study in the International Journal...  ]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>article_title</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>edit task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight stigma may undermine healthy behaviors, according to a study in the International Journal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   choice  \\\n",
       "0       0   \n",
       "1       1   \n",
       "\n",
       "                                                                                         article_title  \\\n",
       "0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                    system_role          model  \\\n",
       "0  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                                                                                             prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "               summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit task  \\\n",
       "0  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "\n",
       "                                                                               full summarization task  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                               summary  \n",
       "0  Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...  \n",
       "1  Weight stigma may undermine healthy behaviors, according to a study in the International Journal...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 9)\n",
      "Original summaries Dataframe columns: Index(['article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>edit task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>High calcium and high protein dairy foods may reduce risk of fractures and falls in institutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description of the research participants, such as age and sex. ...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight stigma may undermine healthy behaviors, according to a study in the International Journal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         article_title  \\\n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                    system_role          model  \\\n",
       "1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "1  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "2  You are a helpful assistant.  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                                                                                             prep step  \\\n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "               summarization task  \\\n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                                             edit task  \\\n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "2  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "1  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "2  \\nIf applicable, include a brief description of the research participants, such as age and sex. ...   \n",
       "\n",
       "                                                                               full summarization task  \\\n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                               summary  \n",
       "1  High calcium and high protein dairy foods may reduce risk of fractures and falls in institutiona...  \n",
       "2  High calcium and protein dairy foods may reduce risk of fractures and falls in older adults\\n\\nA...  \n",
       "1  Headline: Weight Stigma Associated with Poorer Health Behaviors, Independent of BMI\\n\\nKey conce...  \n",
       "2  Weight stigma may undermine healthy behaviors, according to a study in the International Journal...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, filename=None, \n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output',\n",
    "    pickle_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\pickles',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\output\\json'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices,\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.13\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "summary_iteration_id = iteration_id\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, temp_qna_dict, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id\n",
    "#     )\n",
    "\n",
    "chatbot_id = 1\n",
    "qna_dict = dict()\n",
    "qna_dict = create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 save the API response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 9)\n",
      "Original summaries Dataframe columns: Index(['article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>edit task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Nutritional approach reduces fractures and fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poor H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  \\\n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Effect of dietary sources of calcium and prote...   \n",
       "1  Weight stigma and health behaviors: evidence f...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                         system_role          model  \\\n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                                text  \\\n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Effect of dietary sources of calcium and prote...   \n",
       "1  Weight stigma and health behaviors: evidence f...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                           prep step  \\\n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "\n",
       "               summarization task  \\\n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit task  \\\n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "\n",
       "                             full summarization task  \\\n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "\n",
       "                                             summary  \n",
       "1  Nutritional approach reduces fractures and fal...  \n",
       "2  High calcium and high protein dairy foods may ...  \n",
       "1  Headline: Weight Stigma Linked to Poor Health ...  \n",
       "2  Headline: Weight Stigma Associated with Poor H...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description='batch_Chaining_responses',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[prompt_chaining_dict()] Unable to save outputs')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list)\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.14\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1\n",
    "qna_dict = create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.14: {'text1_prompt00': <__main__.Chaining at 0x17bd1300590>,\n",
       "  'text2_prompt00': <__main__.Chaining at 0x17bce185ad0>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaining_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_responses_2023-06-12_1100.sav\n",
      "Time completed: 2023-06-12 11:00:13.074088\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_responses_2023-06-12_1100.json\n"
     ]
    }
   ],
   "source": [
    "save_outputs = True\n",
    "pickle_path=folder_path\n",
    "json_path=folder_path\n",
    "if save_outputs:\n",
    "    try:\n",
    "        save_instance_to_dict(\n",
    "            chaining_dict[iteration_id], \n",
    "            description=f'batch_Chaining_responses',\n",
    "            pickle_path=pickle_path, json_path=json_path\n",
    "            )\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        file = f.f_code.co_filename\n",
    "        print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "        print('[prompt_chaining_dict()] Unable to save outputs')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 10)\n",
      "Original summaries Dataframe columns: Index(['choice', 'article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.sav\n",
      "Time completed: 2023-06-12 11:39:43.138043\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.csv\n",
      "Time completed: 2023-06-12 11:39:43.176313\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B: article_title</th>\n",
       "      <th>C: choice</th>\n",
       "      <th>D: system_role</th>\n",
       "      <th>E: model</th>\n",
       "      <th>F: text</th>\n",
       "      <th>G: prep step</th>\n",
       "      <th>H: summarization task</th>\n",
       "      <th>I: edit task</th>\n",
       "      <th>J: full summarization task</th>\n",
       "      <th>K: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Nutritional approach reduces fractures and fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poor H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    B: article_title  C: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      D: system_role       E: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             F: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        G: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            H: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        I: edit task  \\\n",
       "0  \\nIf applicable, include a brief description o...   \n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "3  \\nIf applicable, include a brief description o...   \n",
       "\n",
       "                          J: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          K: summary  \n",
       "0  Nutritional approach reduces fractures and fal...  \n",
       "1  High calcium and high protein dairy foods may ...  \n",
       "2  Headline: Weight Stigma Linked to Poor Health ...  \n",
       "3  Headline: Weight Stigma Associated with Poor H...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.15\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=True\n",
    "#     )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "chatbot_id = 1.14\n",
    "save = True\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    If applicable, include a brief description of ...\n",
      "1    If applicable, include a brief description of ...\n",
      "2    If applicable, include a brief description of ...\n",
      "3    If applicable, include a brief description of ...\n",
      "Name: I: edit task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(qna_dict[iteration_id]['I: edit task'].str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \n",
      "Evaluate whether or not your writing may be confusing.     \n",
      "If so, re-write it so it is clear. Otherwise, keep it the same.     \n",
      "Create a headline to hook the audience.    \n",
      "Return your response as the headline followed by the final version of the summary,     separated by a blank line.\n"
     ]
    }
   ],
   "source": [
    "print(qna_dict[iteration_id].loc[0, 'I: edit task'].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 10)\n",
      "Original summaries Dataframe columns: Index(['choice', 'article_title', 'system_role', 'model', 'text', 'prep step',\n",
      "       'summarization task', 'edit task', 'full summarization task',\n",
      "       'summary'],\n",
      "      dtype='object')\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.sav\n",
      "Time completed: 2023-06-12 11:39:43.138043\n",
      "\tObject saved as pickle\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_summaries_initial_2023-06-12_1139.csv\n",
      "Time completed: 2023-06-12 11:39:43.176313\n",
      "\tDataFrame saved as CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B: article_title</th>\n",
       "      <th>C: choice</th>\n",
       "      <th>D: system_role</th>\n",
       "      <th>E: model</th>\n",
       "      <th>F: text</th>\n",
       "      <th>G: prep step</th>\n",
       "      <th>H: summarization task</th>\n",
       "      <th>I: edit task</th>\n",
       "      <th>J: full summarization task</th>\n",
       "      <th>K: summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Nutritional approach reduces fractures and fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and prote...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>High calcium and high protein dairy foods may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Linked to Poor Health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence f...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>Headline: Weight Stigma Associated with Poor H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    B: article_title  C: choice  \\\n",
       "0  Effect of dietary sources of calcium and prote...          1   \n",
       "1  Effect of dietary sources of calcium and prote...          2   \n",
       "2  Weight stigma and health behaviors: evidence f...          1   \n",
       "3  Weight stigma and health behaviors: evidence f...          2   \n",
       "\n",
       "                                      D: system_role       E: model  \\\n",
       "0  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "1  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "2  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "3  You are a journalist writing content based on ...  gpt-3.5-turbo   \n",
       "\n",
       "                                             F: text  \\\n",
       "0  Effect of dietary sources of calcium and prote...   \n",
       "1  Effect of dietary sources of calcium and prote...   \n",
       "2  Weight stigma and health behaviors: evidence f...   \n",
       "3  Weight stigma and health behaviors: evidence f...   \n",
       "\n",
       "                                        G: prep step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "            H: summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                        I: edit task  \\\n",
       "0  \\nIf applicable, include a brief description o...   \n",
       "1  \\nIf applicable, include a brief description o...   \n",
       "2  \\nIf applicable, include a brief description o...   \n",
       "3  \\nIf applicable, include a brief description o...   \n",
       "\n",
       "                          J: full summarization task  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "1  Think about why this might be relevant for the...   \n",
       "2  Think about why this might be relevant for the...   \n",
       "3  Think about why this might be relevant for the...   \n",
       "\n",
       "                                          K: summary  \n",
       "0  Nutritional approach reduces fractures and fal...  \n",
       "1  High calcium and high protein dairy foods may ...  \n",
       "2  Headline: Weight Stigma Linked to Poor Health ...  \n",
       "3  Headline: Weight Stigma Associated with Poor H...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.15\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=True\n",
    "#     )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "chatbot_id = 1.14\n",
    "save = True\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about why this might be relevant for the...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>\\nIf applicable, include a brief description o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prep_step  \\\n",
       "0  Think about why this might be relevant for the...   \n",
       "\n",
       "                   summarize_task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "\n",
       "                                           edit_task  \n",
       "0  \\nIf applicable, include a brief description o...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing. \\\n",
    "    \\nIf so, re-write it so it is clear. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response as the headline followed by the final version of the summary, \\\n",
    "    where the summary is in paragraph form.\\\n",
    "    \\nDo not label the headline and summary, but separate them by a blank line.\\\n",
    "    \\nDo not include a list of the key concepts as they should already be in the summary.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "prompts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 new prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_attributes_initial_2023-06-12_1308.sav\n",
      "Time completed: 2023-06-12 13:08:58.970939\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1308.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.2\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save = True\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=True\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "# chatbot_id = 1.14\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1_prompt00': <__main__.Chaining at 0x17bd1aeb590>,\n",
       " 'text2_prompt00': <__main__.Chaining at 0x17bce736f50>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       " 'system_role': 'You are a journalist writing content based on science research articles.',\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 1000,\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'qna': {'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       "  'system_role': 'You are a journalist writing content based on science research articles.',\n",
       "  'model': 'gpt-3.5-turbo',\n",
       "  'text': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\\nDiscussion\\nThis nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalised older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. We found no group difference in all cause mortality.\\nMost interventions aimed at reducing fracture risk target a drug therapy to people with osteoporosis because they are at high risk of fracture. This approach confers a large benefit to the individual and does so cost effectively, because few people need to be treated to avert one event. However, averting fractures in small numbers of people at high risk does not reduce the burden of fractures in the community.\\nThe population burden of fractures\\x97the number of events, morbidity, mortality, and cost to the community\\x97arises from the vast numbers of people with risk factors that confer a modest attributable risk to the individual.17\\xa0For example, most fragility fractures in the community arise among women with osteopenia (bone mineral density T score \\x962.5 to \\x961 SD) because they form the largest segment of the community.18\\xa0Likewise, most fractures attributable to nutritional inadequacy arise among the great many people with intakes of calcium and protein that are below recommended levels.19\\xa0This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. This is the Geoffrey Rose prevention paradox\\x97a community based approach producing a small benefit to an individual may still confer a large benefit to the community.17\\xa0Safety is essential because most individuals treated may derive little or no benefit from the intervention. For example, the Dietary Approach to Stop Hypertension study reduced blood pressure by replacing a \\x93western\\x94 diet with a diet rich in fruit, vegetables, and low fat dairy foods\\x97an approach associated with fewer cardiovascular events.20\\nComparison with other studies\\nMost nutrition based studies assessing antifracture efficacy in aged care residents and people in the community used pharmacological doses of calcium with or without vitamin D.21\\xa0In a meta-analysis of 17 of these studies, only two studies reported a reduction in fracture risk\\x97a study of nursing home residents with calcium intakes <600 mg/day and vitamin D concentrations <50 nmol/L and a community based study in women and men ?65 years of age with mean calcium intakes of 700 mg/day.21\\xa0In the remaining 15 studies, poor compliance, large numbers of dropouts, and a low prevalence of the risk factor may have contributed to the null findings.2223\\xa0Benefits are unlikely if the prevalence of a risk factor (such as inadequate calcium and protein intakes) is low.24\\xa0For example, in the meta-analysis, reduction in fracture risk reported with treatment was confined to the 7272 individuals with calcium intakes <700 mg/day (risk ratio 0.80, 95% confidence interval 0.71 to 0.89), not the 45?241 individuals with calcium intakes above 700 mg daily.21\\xa0The reduction in fracture risk observed with calcium and protein rich foods in this study may have been the result of attention to several of the above factors. Compliance was optimised by supervised provision and consumption of the foods. Participants lost to follow-up were replaced by newly admitted residents. We intentionally targeted a cohort at high risk for fracture in whom low calcium and protein intakes were common and so were likely to partly contribute to the already high fracture burden in this community.\\nMechanisms of fracture risk reduction\\nThis nutritional intervention produced two unanticipated novel observations. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The two most likely explanations for each of these observations is a risk reduction for falls and slowing progression of bone fragility. Insulin-like growth factor 1 increased in the intervention group only, whereas the decrease in appendicular lean mass was confined to controls, consistent with the notion that protein intakes of 1-1.5 g/kg/day is needed to prevent protein catabolism and preserve or increase muscle mass in older adults, particularly those at risk of malnutrition or frailty.25\\xa0The increase in serum C terminal telopeptide of type 1 collagen and deterioration in tibial and radial total volumetric bone mineral density in controls was not seen in the intervention group, consistent with slowing of bone loss and slowing of microstructural deterioration.26\\xa0These changes were modest, but slowing microstructural deterioration disproportionately reduces progression of bone fragility because fragility increases as a power function to the bone loss producing it.27\\nMortality did not differ between the groups. Some, but not all, studies suggest that milk consumption is associated with increased mortality but consumption of yoghurt and cheese (fermented foods) with reduced mortality and favourable blood lipid profiles.282930\\xa0Fermented and non-fermented dairy foods were used during the intervention. Milk consumption did not differ between the intervention and control groups (data not shown).\\n',\n",
       "  'prep step': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to',\n",
       "  'summarization task': 'summarize for a LinkedIn post.',\n",
       "  'edit task': '\\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form.    \\nDo not label the headline and summary, but separate them by a blank line.    \\nDo not include a list of the key concepts as they should already be in the summary.',\n",
       "  'full summarization task': 'Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content.     Exclude details that do not add value to the audience.    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to summarize for a LinkedIn post. \\nIf applicable, include a brief description of the research participants, such as age and sex.    Otherwise, you can skip this step.    \\nEvaluate whether or not your writing may be confusing.     \\nIf so, re-write it so it is clear. Otherwise, keep it the same.     \\nCreate a journalistic headline to hook the audience.    \\nReturn your response as the headline followed by the final version of the summary,     where the summary is in paragraph form.    \\nDo not label the headline and summary, but separate them by a blank line.    \\nDo not include a list of the key concepts as they should already be in the summary.',\n",
       "  'summary': ['High calcium and protein dairy foods reduce risk of hip fractures and falls in older adults, according to a recent study. The study found that this nutritional approach resulted in a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The study targeted institutionalized older adults replete in vitamin D, in whom low calcium and protein intakes were common and were likely to contribute to the already high fracture burden in this community. The study used high calcium and protein dairy foods to increase calcium and protein intakes. The study found no group difference in all-cause mortality.',\n",
       "   'High calcium and high protein dairy foods may reduce the risk of fractures and falls in institutionalized older adults, according to a cluster randomized controlled trial. The study found a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls. This nutritional approach may benefit the community by reducing the burden of fractures among those with a small attributable risk to the individual. Compliance was optimized by supervised provision and consumption of the foods, and the cohort was intentionally targeted at high risk for fracture. Participants consumed 1-1.5 g/kg/day of protein to prevent protein catabolism and preserve or increase muscle mass. The study used fermented and non-fermented dairy foods, and milk consumption did not differ between the intervention and control groups.']},\n",
       " 'summaries_dict': {'response_01': 'High calcium and protein dairy foods reduce risk of hip fractures and falls in older adults, according to a recent study. The study found that this nutritional approach resulted in a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The risk reduction for falls and fractures was detected by three and five months, respectively, and the relative risk reduction for fractures was similar to that found in trials using potent antiresorptive therapy to treat people at high risk due to osteoporosis. The study targeted institutionalized older adults replete in vitamin D, in whom low calcium and protein intakes were common and were likely to contribute to the already high fracture burden in this community. The study used high calcium and protein dairy foods to increase calcium and protein intakes. The study found no group difference in all-cause mortality.',\n",
       "  'response_02': 'High calcium and high protein dairy foods may reduce the risk of fractures and falls in institutionalized older adults, according to a cluster randomized controlled trial. The study found a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls. This nutritional approach may benefit the community by reducing the burden of fractures among those with a small attributable risk to the individual. Compliance was optimized by supervised provision and consumption of the foods, and the cohort was intentionally targeted at high risk for fracture. Participants consumed 1-1.5 g/kg/day of protein to prevent protein catabolism and preserve or increase muscle mass. The study used fermented and non-fermented dairy foods, and milk consumption did not differ between the intervention and control groups.'},\n",
       " 'article_title': 'Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial',\n",
       " 'response_regex': 'response_(.*)',\n",
       " 'simple_summary_dict': {},\n",
       " 'relevance_dict': {},\n",
       " 'n_previous_prompts': {}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Chaining_attr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time completed: 2023-06-12 14:25:25.752201\n",
      "Dictionary keys: ['text1_prompt00', 'text2_prompt00']\n",
      "Article title: Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 0\n",
      "\t\t\tAdded relevance: 0\n",
      "Article title: Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: []\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 0\n",
      "\t\t\tAdded relevance: 0\n",
      "\n",
      "\n",
      "New chatbot dict keys: ['text1_prompt00', 'text2_prompt00']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'batch_Chaining_attributes_initial_2023-06-12_1308.sav'\n",
    "\n",
    "loaded_pickle = loadpickle(filename, folder_path)\n",
    "chatbot_dict[1.2] = revive_chatbot_dict(loaded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text1_prompt00', 'text2_prompt00'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict[1.2].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.21 strip white space; format CSV for easier copy/paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text #1 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "**Text #2 prompt #0 of 0**\n",
      "Creating Chaining class instance\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to GPT-3\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Success!\n",
      "text1_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "text2_prompt00\n",
      "\ttext\n",
      "\tsystem_role\n",
      "\ttemperature\n",
      "\tmax_tokens\n",
      "\tmodel\n",
      "\tqna\n",
      "\tsummaries_dict\n",
      "\tarticle_title\n",
      "\tresponse_regex\n",
      "\tsimple_summary_dict\n",
      "\trelevance_dict\n",
      "\tn_previous_prompts\n",
      "File saved:  ../text/2023-06-11/batch_Chaining_attributes_initial_2023-06-12_1308.sav\n",
      "Time completed: 2023-06-12 13:08:58.970939\n",
      "\tObject saved as pickle\n",
      "Dictionary keys: dict_keys(['text1_prompt00', 'text2_prompt00'])\n",
      "Object saved as JSON: batch_Chaining_attributes_initial_2023-06-12_1308.json\n"
     ]
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    # simplify_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(text, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        # dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    # Move 'choice' to second column\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(1, 'choice')\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, csv_path=folder_path, pickle_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index+1]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], description=description, append_version=True,\n",
    "                csv_path=csv_path, pickle_path=pickle_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1.2\n",
    "n_choices = 2\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save = True\n",
    "\n",
    "# Create initial summaries\n",
    "chaining_dict = batch_summarize_chain(\n",
    "    text_dict, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "    system_role=system_role, \n",
    "    n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "    iteration_id=iteration_id, save_outputs=True\n",
    "    )\n",
    "\n",
    "# chatbot_id = 1.15\n",
    "# qna_dict = create_qna_df(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "#     )\n",
    "# chatbot_id = 1.14\n",
    "# qna_dict = spreadsheet_columns(\n",
    "#     qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "#     )\n",
    "# qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
