{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.environ['api_key_openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "# pd.reset_option('all')\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "#########\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-07-14 full'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 1\n",
    "article_limit = 4\n",
    "temperature = 1\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=local, article_limit=article_limit)\n",
    "    print(qna_dict[iteration_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
