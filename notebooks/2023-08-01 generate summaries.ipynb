{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from silvhua import *\n",
    "# from datetime import datetime\n",
    "# sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from `main.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 5_prompt02...\n",
      "Processing 5_prompt03...\n",
      "Error converting summary column to JSON: Invalid control character at: line 2 column 795 (char 885); will do row by row\n",
      "Error converting summary 3 to JSON: Invalid control character at: line 2 column 795 (char 885)\n",
      "Original summaries DataFrame shape: (12, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 12 rows to the database...\n",
      "\tReference #5: New research shows that not drinking enough water can increase pain sensitivity\n",
      "\tReference #5: Did you know: Dehydration can increase pain sensitivity?\n",
      "\tReference #5: Discover how dehydration can affect pain sensitivity in women\n",
      "\tReference #5: New research shows that dehydration can increase pain sensitivity in women\n",
      "\tReference #5: New Research Shows How Hydration Affects Pain Sensitivity in Women\n",
      "\tReference #5: New research shows how hydration affects pain sensitivity in women\n",
      "\tReference #5: Discover how being dehydrated can make you more sensitive to pain!\n",
      "\tReference #5: Discover how hydration affects pain sensitivity in women!\n",
      "\tReference #5: Discover how hydration affects pain sensitivity in women!\n",
      "\tReference #5: New Research: Hydration and Pain Sensitivity in Women\n",
      "\tReference #5: New research shows how dehydration can increase pain sensitivity\n",
      "\tReference #5: New Research Shows How Dehydration Can Affect Pain Sensitivity\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 3\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>text</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prep_step</th>\n",
       "      <th>summarize_task</th>\n",
       "      <th>edit_task</th>\n",
       "      <th>simplify_task</th>\n",
       "      <th>simplify_audience</th>\n",
       "      <th>format_task</th>\n",
       "      <th>full_summarize_task</th>\n",
       "      <th>folder</th>\n",
       "      <th>summary</th>\n",
       "      <th>headline</th>\n",
       "      <th>simple_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01 15:12:13.534524-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New research shows that not drinking enough wa...</td>\n",
       "      <td>Did you know that not drinking enough water ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-01 15:12:13.534524-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>Did you know: Dehydration can increase pain se...</td>\n",
       "      <td>Hey! Just read this interesting study that fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-01 15:12:13.534524-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>Discover how dehydration can affect pain sensi...</td>\n",
       "      <td>Hey! Did you know that dehydration can actuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-01 15:12:18.518566-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>a lay audience</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>According to a recent study, mild dehydration ...</td>\n",
       "      <td>New research shows that dehydration can increa...</td>\n",
       "      <td>Hey! Just read this fascinating study that sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-01 15:12:18.518566-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>a lay audience</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>Hey! I just read some fascinating research abo...</td>\n",
       "      <td>New Research Shows How Hydration Affects Pain ...</td>\n",
       "      <td>Hey! I just read this super cool study about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-01 15:12:18.518566-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>a lay audience</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>A recent study found that mild dehydration can...</td>\n",
       "      <td>New research shows how hydration affects pain ...</td>\n",
       "      <td>Hey! Did you know that staying hydrated can af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-08-01 15:12:27.423427-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>Did you know that being dehydrated can increas...</td>\n",
       "      <td>Discover how being dehydrated can make you mor...</td>\n",
       "      <td>Hey! Did you know that not drinking enough wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-08-01 15:12:27.423427-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>Did you know that mild dehydration can increas...</td>\n",
       "      <td>Discover how hydration affects pain sensitivit...</td>\n",
       "      <td>Hey! Did you know that being dehydrated can ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-08-01 15:12:27.423427-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>people who like fun facts but don't know much ...</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>Hey friend! I just read an interesting researc...</td>\n",
       "      <td>Discover how hydration affects pain sensitivit...</td>\n",
       "      <td>Hey there! Just read this cool study about how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-08-01 15:12:33.066832-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>a lay audience</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>Pain is a major public health issue, and chron...</td>\n",
       "      <td>New Research: Hydration and Pain Sensitivity i...</td>\n",
       "      <td>Hey! I just read this interesting new research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-08-01 15:12:33.066832-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>a lay audience</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>According to a recent study, mild dehydration ...</td>\n",
       "      <td>New research shows how dehydration can increas...</td>\n",
       "      <td>Hey! I just read this interesting study that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-08-01 15:12:33.066832-07:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypohydration but not Menstrual Phase Influenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain is recognized as a public health problem ...</td>\n",
       "      <td>You are someone who loves to read health resea...</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In the summary, cover the following informatio...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>Once you have written your text message:     \\...</td>\n",
       "      <td>3. Rewrite the text in a fun tone.    Follow t...</td>\n",
       "      <td>a lay audience</td>\n",
       "      <td>4. Return your final response in a JSON format...</td>\n",
       "      <td>Write a casual text message to your friend abo...</td>\n",
       "      <td>text/2023-08-01</td>\n",
       "      <td>Pain is recognized as a public health problem,...</td>\n",
       "      <td>New Research Shows How Dehydration Can Affect ...</td>\n",
       "      <td>Hey! Just read this interesting research that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  reference_id  \\\n",
       "0   2023-08-01 15:12:13.534524-07:00             5   \n",
       "1   2023-08-01 15:12:13.534524-07:00             5   \n",
       "2   2023-08-01 15:12:13.534524-07:00             5   \n",
       "3   2023-08-01 15:12:18.518566-07:00             5   \n",
       "4   2023-08-01 15:12:18.518566-07:00             5   \n",
       "5   2023-08-01 15:12:18.518566-07:00             5   \n",
       "6   2023-08-01 15:12:27.423427-07:00             5   \n",
       "7   2023-08-01 15:12:27.423427-07:00             5   \n",
       "8   2023-08-01 15:12:27.423427-07:00             5   \n",
       "9   2023-08-01 15:12:33.066832-07:00             5   \n",
       "10  2023-08-01 15:12:33.066832-07:00             5   \n",
       "11  2023-08-01 15:12:33.066832-07:00             5   \n",
       "\n",
       "                                        article_title  choice  \\\n",
       "0   Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "1   Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "2   Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "3   Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "4   Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "5   Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "6   Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "7   Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "8   Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "9   Hypohydration but not Menstrual Phase Influenc...       1   \n",
       "10  Hypohydration but not Menstrual Phase Influenc...       2   \n",
       "11  Hypohydration but not Menstrual Phase Influenc...       3   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Pain is recognized as a public health problem ...   \n",
       "1   Pain is recognized as a public health problem ...   \n",
       "2   Pain is recognized as a public health problem ...   \n",
       "3   Pain is recognized as a public health problem ...   \n",
       "4   Pain is recognized as a public health problem ...   \n",
       "5   Pain is recognized as a public health problem ...   \n",
       "6   Pain is recognized as a public health problem ...   \n",
       "7   Pain is recognized as a public health problem ...   \n",
       "8   Pain is recognized as a public health problem ...   \n",
       "9   Pain is recognized as a public health problem ...   \n",
       "10  Pain is recognized as a public health problem ...   \n",
       "11  Pain is recognized as a public health problem ...   \n",
       "\n",
       "                                          system_role                   model  \\\n",
       "0   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "1   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "2   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "3   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "4   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "5   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "6   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "7   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "8   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "9   You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "10  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "11  You are someone who loves to read health resea...  gpt-3.5-turbo-16k-0613   \n",
       "\n",
       "    temperature                                          prep_step  \\\n",
       "0           0.7  In the summary, cover the following informatio...   \n",
       "1           0.7  In the summary, cover the following informatio...   \n",
       "2           0.7  In the summary, cover the following informatio...   \n",
       "3           0.7  In the summary, cover the following informatio...   \n",
       "4           0.7  In the summary, cover the following informatio...   \n",
       "5           0.7  In the summary, cover the following informatio...   \n",
       "6           0.7  In the summary, cover the following informatio...   \n",
       "7           0.7  In the summary, cover the following informatio...   \n",
       "8           0.7  In the summary, cover the following informatio...   \n",
       "9           0.7  In the summary, cover the following informatio...   \n",
       "10          0.7  In the summary, cover the following informatio...   \n",
       "11          0.7  In the summary, cover the following informatio...   \n",
       "\n",
       "                                       summarize_task  \\\n",
       "0   Write a casual text message to your friend abo...   \n",
       "1   Write a casual text message to your friend abo...   \n",
       "2   Write a casual text message to your friend abo...   \n",
       "3   Write a casual text message to your friend abo...   \n",
       "4   Write a casual text message to your friend abo...   \n",
       "5   Write a casual text message to your friend abo...   \n",
       "6   Write a casual text message to your friend abo...   \n",
       "7   Write a casual text message to your friend abo...   \n",
       "8   Write a casual text message to your friend abo...   \n",
       "9   Write a casual text message to your friend abo...   \n",
       "10  Write a casual text message to your friend abo...   \n",
       "11  Write a casual text message to your friend abo...   \n",
       "\n",
       "                                            edit_task  \\\n",
       "0   Once you have written your text message:     \\...   \n",
       "1   Once you have written your text message:     \\...   \n",
       "2   Once you have written your text message:     \\...   \n",
       "3   Once you have written your text message:     \\...   \n",
       "4   Once you have written your text message:     \\...   \n",
       "5   Once you have written your text message:     \\...   \n",
       "6   Once you have written your text message:     \\...   \n",
       "7   Once you have written your text message:     \\...   \n",
       "8   Once you have written your text message:     \\...   \n",
       "9   Once you have written your text message:     \\...   \n",
       "10  Once you have written your text message:     \\...   \n",
       "11  Once you have written your text message:     \\...   \n",
       "\n",
       "                                        simplify_task  \\\n",
       "0   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "1   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "2   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "3   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "4   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "5   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "6   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "7   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "8   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "9   3. Rewrite the text in a fun tone.    Follow t...   \n",
       "10  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "11  3. Rewrite the text in a fun tone.    Follow t...   \n",
       "\n",
       "                                    simplify_audience  \\\n",
       "0   people who like fun facts but don't know much ...   \n",
       "1   people who like fun facts but don't know much ...   \n",
       "2   people who like fun facts but don't know much ...   \n",
       "3                                      a lay audience   \n",
       "4                                      a lay audience   \n",
       "5                                      a lay audience   \n",
       "6   people who like fun facts but don't know much ...   \n",
       "7   people who like fun facts but don't know much ...   \n",
       "8   people who like fun facts but don't know much ...   \n",
       "9                                      a lay audience   \n",
       "10                                     a lay audience   \n",
       "11                                     a lay audience   \n",
       "\n",
       "                                          format_task  \\\n",
       "0   4. Return your final response in a JSON format...   \n",
       "1   4. Return your final response in a JSON format...   \n",
       "2   4. Return your final response in a JSON format...   \n",
       "3   4. Return your final response in a JSON format...   \n",
       "4   4. Return your final response in a JSON format...   \n",
       "5   4. Return your final response in a JSON format...   \n",
       "6   4. Return your final response in a JSON format...   \n",
       "7   4. Return your final response in a JSON format...   \n",
       "8   4. Return your final response in a JSON format...   \n",
       "9   4. Return your final response in a JSON format...   \n",
       "10  4. Return your final response in a JSON format...   \n",
       "11  4. Return your final response in a JSON format...   \n",
       "\n",
       "                                  full_summarize_task           folder  \\\n",
       "0   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "1   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "2   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "3   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "4   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "5   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "6   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "7   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "8   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "9   Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "10  Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "11  Write a casual text message to your friend abo...  text/2023-08-01   \n",
       "\n",
       "                                              summary  \\\n",
       "0   A recent study found that mild dehydration can...   \n",
       "1   A recent study found that mild dehydration can...   \n",
       "2   A recent study found that mild dehydration can...   \n",
       "3   According to a recent study, mild dehydration ...   \n",
       "4   Hey! I just read some fascinating research abo...   \n",
       "5   A recent study found that mild dehydration can...   \n",
       "6   Did you know that being dehydrated can increas...   \n",
       "7   Did you know that mild dehydration can increas...   \n",
       "8   Hey friend! I just read an interesting researc...   \n",
       "9   Pain is a major public health issue, and chron...   \n",
       "10  According to a recent study, mild dehydration ...   \n",
       "11  Pain is recognized as a public health problem,...   \n",
       "\n",
       "                                             headline  \\\n",
       "0   New research shows that not drinking enough wa...   \n",
       "1   Did you know: Dehydration can increase pain se...   \n",
       "2   Discover how dehydration can affect pain sensi...   \n",
       "3   New research shows that dehydration can increa...   \n",
       "4   New Research Shows How Hydration Affects Pain ...   \n",
       "5   New research shows how hydration affects pain ...   \n",
       "6   Discover how being dehydrated can make you mor...   \n",
       "7   Discover how hydration affects pain sensitivit...   \n",
       "8   Discover how hydration affects pain sensitivit...   \n",
       "9   New Research: Hydration and Pain Sensitivity i...   \n",
       "10  New research shows how dehydration can increas...   \n",
       "11  New Research Shows How Dehydration Can Affect ...   \n",
       "\n",
       "                                       simple_summary  \n",
       "0   Did you know that not drinking enough water ca...  \n",
       "1   Hey! Just read this interesting study that fou...  \n",
       "2   Hey! Did you know that dehydration can actuall...  \n",
       "3   Hey! Just read this fascinating study that sho...  \n",
       "4   Hey! I just read this super cool study about h...  \n",
       "5   Hey! Did you know that staying hydrated can af...  \n",
       "6   Hey! Did you know that not drinking enough wat...  \n",
       "7   Hey! Did you know that being dehydrated can ac...  \n",
       "8   Hey there! Just read this cool study about how...  \n",
       "9   Hey! I just read this interesting new research...  \n",
       "10  Hey! I just read this interesting study that s...  \n",
       "11  Hey! Just read this interesting research that ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch 2 update prompts 15:21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #5 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "Processing 5_prompt01...\n",
      "Processing 5_prompt02...\n",
      "Processing 5_prompt03...\n",
      "Original summaries DataFrame shape: (12, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 12 rows to the database...\n",
      "\tReference #5: Discover how staying hydrated can affect your pain sensitivity!\n",
      "\tReference #5: Discover the Surprising Link Between Hydration and Pain Sensitivity\n",
      "\tReference #5: Exciting new research on pain and hydration!\n",
      "\tReference #5: New research shows that dehydration may increase pain sensitivity in women\n",
      "\tReference #5: New Research Shows How Dehydration Can Affect Pain Sensitivity in Women\n",
      "\tReference #5: Exciting new research on pain and hydration!\n",
      "\tReference #5: Discover how hydration affects pain sensitivity in women!\n",
      "\tReference #5: Interesting Research on Pain and Hydration\n",
      "\tReference #5: Discover how hydration affects pain sensitivity in women!\n",
      "\tReference #5: New Research: Dehydration Increases Pain Sensitivity in Women\n",
      "\tReference #5: New Research: How Hydration Affects Pain Sensitivity in Women\n",
      "\tReference #5: New research shows how dehydration can increase pain sensitivity in women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 3\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat after refreshing kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #5: Hypohydration Increases Pain Sensitivity in Women\n",
      "\tReference #5: The Surprising Link Between Dehydration and Pain Sensitivity\n",
      "\tReference #5: Hypohydration and Pain: A Surprising Connection\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 3\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 3 discussion only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #5: The Impact of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #5: Hypohydration Increases Pain Sensitivity in Women, Water Intake Doesn't Immediately Help\n",
      "\tReference #5: Pain and Hydration: Surprising Connections\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 3\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 4 use gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : This model's maximum context length is 4097 tokens. However, your messages resulted in 9075 tokens. Please reduce the length of the messages.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 5_prompt00: 'summary'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m qna_dict[iteration_id]\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 104\u001b[0m     qna_dict \u001b[39m=\u001b[39m generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, article_limit\u001b[39m=\u001b[39;49marticle_limit)\n\u001b[0;32m    105\u001b[0m     \u001b[39m# print(qna_dict[iteration_id)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     qna_dict\n",
      "Cell \u001b[1;32mIn[3], line 93\u001b[0m, in \u001b[0;36mgenerate_summaries\u001b[1;34m(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit)\u001b[0m\n\u001b[0;32m     83\u001b[0m chatbot_dict \u001b[39m=\u001b[39m batch_summarize( \u001b[39m# orm_summarize.py\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task,  \u001b[39m# parameter values found in prompts.py\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m     90\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[39m#########\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m# Step 5: Create summaries table\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m     94\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     97\u001b[0m \u001b[39m##########\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m# Step 5: Add results to summaries and prompts table \u001b[39;00m\n\u001b[0;32m     99\u001b[0m bulk_append(table\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummaries\u001b[39m\u001b[39m'\u001b[39m, input_df\u001b[39m=\u001b[39mqna_dict[iteration_id]) \u001b[39m# db_orm.py\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py:206\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mAn error occurred on line \u001b[39m\u001b[39m{\u001b[39;00mlineno\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)    \n\u001b[0;32m    203\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError creating DataFrame from \u001b[39m\u001b[39m{\u001b[39;00mchatbot_key\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    207\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m columns \u001b[39m=\u001b[39m qna_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try with GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-4\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-4\n",
      "\t\tRequesting 2 choices using gpt-4\n",
      "An error occurred on line 89 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py : Rate limit reached for 10KTPM-200RPM in organization org-4l8HUKDtXhH0T7iFErf1JSJg on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\t**API request failed for `.summarize()`**\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "\tAn error occurred on line 195 in C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py: 'summary'\n",
      "Error creating DataFrame from 5_prompt00: 'summary'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m qna_dict[iteration_id]\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 104\u001b[0m     qna_dict \u001b[39m=\u001b[39m generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, article_limit\u001b[39m=\u001b[39;49marticle_limit)\n\u001b[0;32m    105\u001b[0m     \u001b[39m# print(qna_dict[iteration_id)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     qna_dict\n",
      "Cell \u001b[1;32mIn[5], line 93\u001b[0m, in \u001b[0;36mgenerate_summaries\u001b[1;34m(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit)\u001b[0m\n\u001b[0;32m     83\u001b[0m chatbot_dict \u001b[39m=\u001b[39m batch_summarize( \u001b[39m# orm_summarize.py\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     sources_df, folder_path, prep_step, summarize_task, edit_task,  \u001b[39m# parameter values found in prompts.py\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     simplify_task, simplify_audience, format_task,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m     iteration_id\u001b[39m=\u001b[39miteration_id, save_outputs\u001b[39m=\u001b[39msave_outputs\n\u001b[0;32m     90\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[39m#########\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m# Step 5: Create summaries table\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m qna_dict \u001b[39m=\u001b[39m create_summaries_df(\n\u001b[0;32m     94\u001b[0m     qna_dict, chatbot_dict, iteration_id, chatbot_id\u001b[39m=\u001b[39;49mchatbot_id\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     97\u001b[0m \u001b[39m##########\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m# Step 5: Add results to summaries and prompts table \u001b[39;00m\n\u001b[0;32m     99\u001b[0m bulk_append(table\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummaries\u001b[39m\u001b[39m'\u001b[39m, input_df\u001b[39m=\u001b[39mqna_dict[iteration_id]) \u001b[39m# db_orm.py\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\\orm_summarize.py:206\u001b[0m, in \u001b[0;36mcreate_summaries_df\u001b[1;34m(qna_dict, chatbot_dict, iteration_id, chatbot_id)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mAn error occurred on line \u001b[39m\u001b[39m{\u001b[39;00mlineno\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)    \n\u001b[0;32m    203\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError creating DataFrame from \u001b[39m\u001b[39m{\u001b[39;00mchatbot_key\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m qna_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(dfs_list)\u001b[39m.\u001b[39mreset_index(names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mchoice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    207\u001b[0m qna_df \u001b[39m=\u001b[39m extract_summary(qna_df, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m columns \u001b[39m=\u001b[39m qna_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\ginkgo\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-3.5-turbo'\n",
    "\n",
    "model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch 5 reduce prompt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Original summaries DataFrame shape: (2, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 2 rows to the database...\n",
      "\tReference #16: Effects of Hypohydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_tokens = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #16: Effects of Hypohydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #16: Effects of Hypohydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration and Menstrual Phase Effects on Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 3\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=1000,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch 6: add back system role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Original summaries DataFrame shape: (2, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 2 rows to the database...\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women, Menstrual Phase Does Not\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0613-alpha-internal\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-0613-alpha-shared\n",
      "gpt-3.5-turbo-0613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Model model id=gpt-3.5-turbo-16k-0613 at 0x1915f37c6b0> JSON: {\n",
       "   \"created\": 1685474247,\n",
       "   \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690865619,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-0WUfVWoQgban6U6wF2YQVlq7\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-16k-0613\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo at 0x1915f37dc70> JSON: {\n",
       "   \"created\": 1677610602,\n",
       "   \"id\": \"gpt-3.5-turbo\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690864883,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-zy5TOjnE2zVaicIcKO9bQDgX\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-0613-alpha-internal at 0x1915f37d3d0> JSON: {\n",
       "   \"created\": 1690928952,\n",
       "   \"id\": \"gpt-3.5-turbo-0613-alpha-internal\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"system\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": true,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": true,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690930797,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-melDwNsma5KOGrxleJZBx6w6\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-0613-alpha-internal\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-0301 at 0x1915f37fa10> JSON: {\n",
       "   \"created\": 1677649963,\n",
       "   \"id\": \"gpt-3.5-turbo-0301\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690842565,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-7WmfQzsq5FJ92UAnn24LduAN\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-0301\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-16k at 0x1915f37fdd0> JSON: {\n",
       "   \"created\": 1683758102,\n",
       "   \"id\": \"gpt-3.5-turbo-16k\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai-internal\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690866609,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-r2x739b21PqZv0StkJePepPC\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-16k\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-0613-alpha-shared at 0x1915f37e9f0> JSON: {\n",
       "   \"created\": 1690864031,\n",
       "   \"id\": \"gpt-3.5-turbo-0613-alpha-shared\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"system\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": true,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": true,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690928362,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-6gtF4RKRUKCbALiMduHaTEfY\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-0613-alpha-shared\"\n",
       " },\n",
       " <Model model id=gpt-3.5-turbo-0613 at 0x1915f448950> JSON: {\n",
       "   \"created\": 1686587434,\n",
       "   \"id\": \"gpt-3.5-turbo-0613\",\n",
       "   \"object\": \"model\",\n",
       "   \"owned_by\": \"openai\",\n",
       "   \"parent\": null,\n",
       "   \"permission\": [\n",
       "     {\n",
       "       \"allow_create_engine\": false,\n",
       "       \"allow_fine_tuning\": false,\n",
       "       \"allow_logprobs\": true,\n",
       "       \"allow_sampling\": true,\n",
       "       \"allow_search_indices\": false,\n",
       "       \"allow_view\": true,\n",
       "       \"created\": 1690842445,\n",
       "       \"group\": null,\n",
       "       \"id\": \"modelperm-XIXH7QF7QM60DDcON9eaGFfk\",\n",
       "       \"is_blocking\": false,\n",
       "       \"object\": \"model_permission\",\n",
       "       \"organization\": \"*\"\n",
       "     }\n",
       "   ],\n",
       "   \"root\": \"gpt-3.5-turbo-0613\"\n",
       " }]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_models(query='gpt-3.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch 7 gpt-3.5-turbo-0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 3 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Original summaries DataFrame shape: (3, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 3 rows to the database...\n",
      "\tReference #16: Study shows hypohydration increases pain sensitivity in women\n",
      "\tReference #16: Effects of Hypohydration on Experimental Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women, But Menstrual Phase Does Not Affect Pain Sensitivity\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 3\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-3.5-turbo'\n",
    "model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch 8: swap order of prep step and summarize task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 2 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Original summaries DataFrame shape: (2, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 2 rows to the database...\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "\tReference #16: Effects of Hypohydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 2\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #5 prompt #1 of 1**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 5_prompt00...\n",
      "Original summaries DataFrame shape: (4, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 4 rows to the database...\n",
      "\tReference #5: Effects of Hypohydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #5: Effects of Hypohydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #5: Hypohydration Increases Pain Sensitivity in Women, Menstrual Phase Does Not Impact Pain\n",
      "\tReference #5: Hypohydration Increases Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01'\n",
    "# section = 'discussion'\n",
    "section = None\n",
    "local = False\n",
    "n_choices = 4\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-3.5-turbo'\n",
    "# model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch 9 add back simplify task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-16k-0613\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-16k-0613\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-16k-0613\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Processing 16_prompt01...\n",
      "Processing 16_prompt02...\n",
      "Processing 16_prompt03...\n",
      "Original summaries DataFrame shape: (16, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 16 rows to the database...\n",
      "\tReference #16: Water intake affects pain sensitivity in women\n",
      "\tReference #16: Does Dehydration Make Pain Worse?\n",
      "\tReference #16: Hypohydration can increase pain sensitivity in women\n",
      "\tReference #16: Thirsty and in pain? Stay hydrated!\n",
      "\tReference #16: Effects of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: Effects of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "\tReference #16: Effects of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: Water and Pain Sensitivity in Women\n",
      "\tReference #16: The Impact of Hydration on Pain Sensitivity in Women\n",
      "\tReference #16: Fascinating Study on Pain Sensitivity and Hydration in Women\n",
      "\tReference #16: Can Dehydration Increase Pain Sensitivity in Women?\n",
      "\tReference #16: The Impact of Hydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration and Pain Sensitivity in Women\n",
      "\tReference #16: Effects of Hypohydration on Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 4\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Processing 16_prompt01...\n",
      "Processing 16_prompt02...\n",
      "Processing 16_prompt03...\n",
      "Original summaries DataFrame shape: (16, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 16 rows to the database...\n",
      "\tReference #16: Does being dehydrated make you more sensitive to pain?\n",
      "\tReference #16: Does being dehydrated make you more sensitive to pain?\n",
      "\tReference #16: Does being dehydrated make pain worse?\n",
      "\tReference #16: Water intake may affect pain perception in women\n",
      "\tReference #16: Effects of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: Impact of Hydration on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "\tReference #16: Effects of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: The Impact of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: The effects of hypohydration and menstrual phase on pain sensitivity in women\n",
      "\tReference #16: Pain sensitivity in women and the impact of hydration\n",
      "\tReference #16: The Effects of Hypohydration on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration and Pain Sensitivity in Women\n",
      "\tReference #16: The Impact of Hydration on Pain Sensitivity in Women\n",
      "\tReference #16: The Impact of Hydration and Menstrual Phase on Pain Sensitivity in Women\n",
      "\tReference #16: Hypohydration Increases Pain Sensitivity in Women\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 4\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt-3.5-turbo-0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Processing 16_prompt01...\n",
      "Processing 16_prompt02...\n",
      "Processing 16_prompt03...\n",
      "Error converting summary column to JSON: Extra data: line 1 column 2 (char 1); will do row by row\n",
      "Error converting summary 0 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 1 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 2 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 3 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 4 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 5 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 6 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 7 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 8 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 9 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 10 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 11 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 12 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 13 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 14 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 15 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Original summaries DataFrame shape: (16, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 16 rows to the database...\n",
      "\tReference #16: Surprising link between hydration and pain sensitivity in women\n",
      "\tReference #16: Fun fact: Dehydration and pain in women\n",
      "\tReference #16: Fun fact: Dehydration can make pain worse!\n",
      "\tReference #16: Water and pain sensitivity in women\n",
      "\tReference #16: The Surprising Link Between Water Intake and Pain in Women\n",
      "\tReference #16: Surprising findings on dehydration and pain in women\n",
      "\tReference #16: None\n",
      "\tReference #16: New study shows how dehydration affects pain perception in women\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 4\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-3.5-turbo'\n",
    "model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1])\n",
      "\n",
      "Adding 1 rows to the database...\n",
      "\t** Already exists in the database: Hypohydration but not Menstrual Phase Influences Pain Perception in Healthy Women.\n",
      "New records added successfully (if applicable)!\n",
      "**Text #16 prompt #1 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #2 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #3 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "**Text #16 prompt #4 of 4**\n",
      "Creating Chaining class instance\n",
      "***OpenAI model: gpt-3.5-turbo-0301\n",
      "Chaining class instance created\n",
      "\tDone creating prompt\n",
      "\tSending request to gpt-3.5-turbo-0301\n",
      "\t\tRequesting 4 choices using gpt-3.5-turbo-0301\n",
      "\tDone sending request to GPT-3\n",
      "\t...Completed\n",
      "Processing 16_prompt00...\n",
      "Processing 16_prompt01...\n",
      "Processing 16_prompt02...\n",
      "Processing 16_prompt03...\n",
      "Error converting summary column to JSON: Extra data: line 1 column 2 (char 1); will do row by row\n",
      "Error converting summary 0 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 1 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 2 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 3 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 4 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 5 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 6 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 7 to JSON: Extra data: line 1 column 2 (char 1)\n",
      "Error converting summary 8 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 9 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 10 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 11 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 12 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 13 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 14 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Error converting summary 15 to JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Original summaries DataFrame shape: (16, 19)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'timestamp', 'reference_id', 'article_title', 'text',\n",
      "       'system_role', 'model', 'temperature', 'prep_step', 'summarize_task',\n",
      "       'edit_task', 'simplify_task', 'simplify_audience', 'format_task',\n",
      "       'full_summarize_task', 'folder', 'summary', 'headline',\n",
      "       'simple_summary'],\n",
      "      dtype='object')\n",
      "Adding 16 rows to the database...\n",
      "\tReference #16: Surprising link between hydration and pain sensitivity in women\n",
      "\tReference #16: Fun fact: Dehydration and pain in women\n",
      "\tReference #16: Fun fact: Dehydration can make pain worse!\n",
      "\tReference #16: Water and pain sensitivity in women\n",
      "\tReference #16: The Surprising Link Between Water Intake and Pain in Women\n",
      "\tReference #16: Surprising findings on dehydration and pain in women\n",
      "\tReference #16: None\n",
      "\tReference #16: New study shows how dehydration affects pain perception in women\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "\tReference #16: None\n",
      "New records added successfully (if applicable)!\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\private\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from prompts import * # .py file stored in the path above\n",
    "from db_orm import * \n",
    "from sources import *\n",
    "from orm_summarize import *\n",
    "from article_processing import *\n",
    "\n",
    "@remote_sql_session\n",
    "def get_from_queue(session, input_df, order_by='id', order='ASC'):\n",
    "    \"\"\"\n",
    "    Return the matching records from the sources table as a pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - input_df: A pandas DataFrame with the article records from the gpt_queue table or equivalent. Columns include 'title' and 'section'.\n",
    "    - limit: The number of records to return.\n",
    "    \"\"\"\n",
    "    def row_to_dict(row):\n",
    "        result = session.query(Sources).filter_by(\n",
    "            title=row['title'],\n",
    "            section=row['section']\n",
    "        ).limit(1).all()[0]\n",
    "        \n",
    "        sources_series = pd.Series({column.name: getattr(result, column.name) for column in result.__table__.columns})\n",
    "        return sources_series\n",
    "\n",
    "    sources_df = input_df.apply(row_to_dict, axis=1)\n",
    "    ascending = True if order == 'ASC' else False\n",
    "    sources_df.sort_values(order_by, ascending=ascending, inplace=True)\n",
    "    return sources_df\n",
    "\n",
    "\n",
    "#########\n",
    "# Prep: Set parameters\n",
    "folder_path = '../text/2023-08-01 discussion'\n",
    "section = 'discussion'\n",
    "local = False\n",
    "n_choices = 4\n",
    "article_limit = 1\n",
    "temperature = 0.7\n",
    "pause_per_request=0\n",
    "# summary_iteration_id = iteration_id\n",
    "iteration_id = 1\n",
    "chatbot_id = iteration_id\n",
    "# model = 'gpt-3.5-turbo-16k-0613'\n",
    "# model = 'gpt-3.5-turbo'\n",
    "model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "# model = 'gpt-4'\n",
    "save_outputs=False\n",
    "\n",
    "def generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local, article_limit=article_limit):\n",
    "    ### Set up\n",
    "    qna_dict = dict()\n",
    "    chatbot_dict = dict()\n",
    "    references_df_dict = dict()\n",
    "\n",
    "    # set the option to wrap text within cells\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    ####### \n",
    "    # Step 1: Create sources table\n",
    "    if local:\n",
    "        text_df = parse_fulltext(folder_path, section).iloc[:article_limit if article_limit else len(text_df)]\n",
    "    else:\n",
    "        text_df = get_table(table='gpt_queue', limit=article_limit) # db_orm.py\n",
    "    references_df_dict[iteration_id] = create_sources_table(text_df) # sources.py\n",
    "\n",
    "    ###### \n",
    "    # Step 2:  Add rows from gpt_queue table to sources table \n",
    "    bulk_append(table='sources', input_df=references_df_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    # ##### \n",
    "    # Step 3: Get the new sources for summarization\n",
    "    sources_df = get_from_queue(input_df=text_df, order_by='id', order='ASC')\n",
    "\n",
    "    # ##### \n",
    "    # Step 4: Create summaries (functions contained in orm_summarize.py)\n",
    "    chatbot_dict = batch_summarize( # orm_summarize.py\n",
    "        sources_df, folder_path, prep_step, summarize_task, edit_task,  # parameter values found in prompts.py\n",
    "        simplify_task, simplify_audience, format_task,\n",
    "        chatbot_dict, temperature=temperature,\n",
    "        system_role=system_role, model=model, max_tokens=800,\n",
    "        n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "        iteration_id=iteration_id, save_outputs=save_outputs\n",
    "        )\n",
    "    #########\n",
    "    # Step 5: Create summaries table\n",
    "    qna_dict = create_summaries_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id\n",
    "        )\n",
    "\n",
    "    ##########\n",
    "    # Step 5: Add results to summaries and prompts table \n",
    "    bulk_append(table='summaries', input_df=qna_dict[iteration_id]) # db_orm.py\n",
    "\n",
    "    return qna_dict[iteration_id]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qna_dict = generate_summaries(n_choices, temperature, model, pause_per_request, folder_path, section, local=True, article_limit=article_limit)\n",
    "    # print(qna_dict[iteration_id)\n",
    "    qna_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
