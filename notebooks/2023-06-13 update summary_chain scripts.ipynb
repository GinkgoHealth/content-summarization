{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\Ginkgo coding\\content-summarization\\src\")\n",
    "from file_functions import *\n",
    "import time\n",
    "import re\n",
    "from itertools import product\n",
    "import openai\n",
    "\n",
    "from response_processing import *\n",
    "from article_processing import create_text_dict_from_folder\n",
    "import traceback\n",
    "from file_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_dict = dict()\n",
    "simple_summaries_dict = dict()\n",
    "relevance_dict = dict()\n",
    "chain_results_dict = dict()\n",
    "qna_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys for text_dict: dict_keys([1, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create text dictionary\n",
    "folder_path = '../text/2023-06-12 1' # ** UPDATE REQUIRED**\n",
    "\n",
    "encoding='ISO-8859-1'\n",
    "subset=None\n",
    "\n",
    "text_dict = create_text_dict_from_folder(folder_path, encoding=encoding, subset=subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load most recent response for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: folder\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['date', 'folder', 'article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: ['1']\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: ['1', '2']\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: ['simply_summary', 'relevance']\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 1\n",
      "\t\t\tAdded relevance: 2\n",
      "Article title: Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\n",
      "\tNew chatbot attribute added: text\n",
      "\tNew chatbot attribute added: folder\n",
      "\tNew chatbot attribute added: system_role\n",
      "\tNew chatbot attribute added: temperature\n",
      "\tNew chatbot attribute added: max_tokens\n",
      "\tNew chatbot attribute added: model\n",
      "\tNew chatbot attribute added: qna\n",
      "\t\tAttribute dictionary keys: ['date', 'folder', 'article_title', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'edit task', 'full summarization task', 'summary']\n",
      "\tNew chatbot attribute added: summaries_dict\n",
      "\t\tAttribute dictionary keys: ['response_01', 'response_02']\n",
      "\tNew chatbot attribute added: article_title\n",
      "\tNew chatbot attribute added: response_regex\n",
      "\tNew chatbot attribute added: simple_summary_dict\n",
      "\t\tAttribute dictionary keys: ['1']\n",
      "\tNew chatbot attribute added: relevance_dict\n",
      "\t\tAttribute dictionary keys: ['1', '2']\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tAttribute dictionary keys: ['simply_summary', 'relevance']\n",
      "\tNew chatbot attribute added: date_created\n",
      "\tNew chatbot attribute added: n_previous_prompts\n",
      "\t\tPrevious number of prompts:\n",
      "\t\t\tOriginal summaries: 2 ['response_01', 'response_02']\n",
      "\t\t\tSimple summaries: 1\n",
      "\t\t\tAdded relevance: 2\n",
      "\n",
      "\n",
      "New chatbot dict keys: ['text1_prompt00', 'text2_prompt00']\n"
     ]
    }
   ],
   "source": [
    "filename = '/batch_Chaining_attributes_2023-06-12_2110.json'\n",
    "\n",
    "# loaded_pickle = loadpickle(filename, folder_path)\n",
    "# chatbot_dict[0] = revive_chatbot_dict(loaded_pickle)\n",
    "# sample_Chaining_attr(iteration_id=0)\n",
    "\n",
    "with open(folder_path+filename) as file:\n",
    "    jsonfile = json.load(file)\n",
    "\n",
    "chatbot_dict[1] = revive_chatbot_dict(jsonfile, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text1_prompt00': <summary_chain.Chaining at 0x23c4fecb290>,\n",
       "  'text2_prompt00': <summary_chain.Chaining at 0x23c51415250>}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'response_01': {'0': {'simple summary choice': 1,\n",
       "    'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "    'audience': 'people who are not science experts',\n",
       "    'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "    'simple summary': 'A recent study has found that a diet high in calcium and protein may help reduce the risk of fractures and falls in older adults. The study focused on older adults who were living in institutions and had enough vitamin D. The researchers found that those who consumed high amounts of dairy products with high calcium and protein had a 33% lower risk of any type of fracture, a 46% lower risk of hip fractures, and an 11% lower risk of falls compared to those who did not. The study suggests that not getting enough calcium and protein in your diet may be a significant factor in the risk of fractures in the community. The study participants were at high risk for fractures, and many of them did not consume enough calcium and protein. The study did not find any difference in all-cause mortality between the two groups.',\n",
       "    'original summary': \"High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study conducted on institutionalized older adults replete in vitamin D has found that a nutritional approach using high calcium and high protein dairy foods may reduce the risk of fractures of any type by 33%, hip fractures by 46%, and falls by 11% relative to controls. The study also found no group difference in all-cause mortality. The study's findings suggest that nutritional inadequacy in the intake of calcium and protein may account for a large fraction of the fracture burden in the community as a whole. The participants in the study were at high risk for fracture, and low calcium and protein intakes were common.\"}},\n",
       "  'response_02': {'0': {'simple summary choice': 1,\n",
       "    'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "    'audience': 'people who are not science experts',\n",
       "    'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "    'simple summary': 'A recent study found that older adults who consume a diet rich in calcium and protein have a lower risk of hip fractures and falls. The study suggests that a diet high in dairy products can reduce the risk of fractures by 33% and hip fractures by 46%. The research also found that many people do not consume enough calcium and protein, which increases the risk of fractures. The study suggests that a dietary approach to reducing fracture risk could have a significant impact on the community.',\n",
       "    'original summary': 'Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study found that a nutritional approach using high calcium and high protein dairy foods to increase calcium and protein intakes in institutionalized older adults replete in vitamin D was associated with a 33% reduction in risk of fractures of any type, a 46% reduction in risk of hip fractures, and an 11% reduction in risk of falls relative to controls. The population burden of fractures arises from the great many people with intakes of calcium and protein that are below recommended levels. This nutritional inadequacy confers a small attributable risk to the individual but accounts for a large attributable fraction of the fracture burden in the community as a whole. These findings suggest that a dietary approach to reducing fracture risk could have a significant impact on the community.'}}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(chatbot_dict[1]['text1_prompt00'])['simple_summary_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_01': {'0': {'simple summary choice': 1,\n",
       "   'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "   'audience': 'people who are not science experts',\n",
       "   'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "   'simple summary': \"Weight stigma can negatively impact health behaviors, regardless of a person's weight, according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep problems, but not physical activity. The researchers also discovered that people of all weights reported experiencing weight stigma. This suggests that weight stigma can be a barrier to healthy behaviors and reducing it could improve overall health.\",\n",
       "   'original summary': 'Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with poorer health behaviors, independent of BMI, according to a new study published in the International Journal of Obesity. The study found that weight stigma was significantly associated with greater disordered eating, comfort eating, alcohol use, and sleep disturbance, after controlling for covariates. However, no such relationship was observed for physical activity. The study also found that individuals across the weight spectrum, not only those with overweight or obese BMIs, reported weight stigma. The authors suggest that weight stigma may undermine multiple behaviors, for which individuals have some control over. This highlights weight stigma as a potential barrier to healthy behaviors, and suggests that one strategy to improve population health may be to reduce weight stigma.'}},\n",
       " 'response_02': {'0': {'simple summary choice': 1,\n",
       "   'simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is',\n",
       "   'audience': 'people who are not science experts',\n",
       "   'full simplify task': 'If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.    Follow these steps to accomplish this:     \\n1. Check if the content and language are appropriate for the audience.     \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\\\ \\n    \\n3. Return the final version of the summary to be shown to the audience.     \\n\\nYour audience is for people who are not science experts',\n",
       "   'simple summary': \"Weight discrimination, or being treated unfairly because of one's weight, is a common problem that can lead to unhealthy behaviors, according to a recent study published in the International Journal of Obesity. The study found that weight discrimination was linked to disordered eating, comfort eating, alcohol use, and sleep problems, regardless of a person's body mass index (BMI). Interestingly, the study found no connection between weight discrimination and physical activity. These findings suggest that weight discrimination can make it harder for people to adopt healthy habits, and that promoting a more inclusive approach to health may be more effective. More research is needed to understand how weight bias affects people's health behaviors. The study was conducted with a large group of adults from across the United States.\",\n",
       "   'original summary': \"Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a person's weight, is prevalent and associated with poor health behaviors, according to a study published in the International Journal of Obesity. The study found weight stigma was significantly associated with disordered eating, comfort eating, alcohol use, and sleep disturbance, independent of BMI. The study also found no relationship between weight stigma and physical activity. These findings suggest weight stigma may be a barrier to healthy behaviors and that weight-inclusive approaches to health promotion may be more effective. Further research is needed to determine the potential role of weight bias internalization in these health behaviors. \\n\\nNote: The study was conducted with a large, national census-matched sample of U.S. adults.\"}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(chatbot_dict[1]['text2_prompt00'])['simple_summary_dict']['1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_step = [\n",
    "    \"Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "    \\nIdentify 1 or 2 key concepts from this article that would make interesting or helpful health content. \\\n",
    "    Exclude details that do not add value to the audience.\\\n",
    "    \\nBased on the key concepts from the previous steps, extract the key points and numerical descriptors to\",\n",
    "]\n",
    "\n",
    "summarize_task = [\n",
    "    \"summarize for a LinkedIn post.\",\n",
    "    # \"Describe the interesting points to your coworker at the water cooler\",\n",
    "    # \"Create an Instagram post without hashtags.\",\n",
    "]\n",
    "edit_task = [\n",
    "    \"\\nIf applicable, include a brief description of the research participants, such as age and sex.\\\n",
    "    Otherwise, you can skip this step.\\\n",
    "    \\nEvaluate whether or not your writing may be confusing or redundant. \\\n",
    "    \\nIf so, re-write it so it is clear and concise. Otherwise, keep it the same. \\\n",
    "    \\nCreate a journalistic headline to hook the audience.\\\n",
    "    \\nReturn your response in this format:\\\n",
    "    \\n<headline>\\n\\n<summary>\\\n",
    "    \\nwhere the summary is in paragraph form.\\\n",
    "    \\nDo not label the headline and summary.\",\n",
    "]\n",
    "\n",
    "system_role = \"You are a journalist writing content based on science research articles.\"\n",
    "prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "    columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "user_simplify_task = [\n",
    "    \"\"\"If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.\\\n",
    "    Follow these steps to accomplish this: \\\n",
    "    \\n1. Check if the content and language are appropriate for the audience. \\\n",
    "    \\n2. If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "    \\n3. Return the final version of the summary to be shown to the audience. \\\n",
    "    \\n\\nYour audience is\"\"\",\n",
    "]\n",
    "\n",
    "simplify_audience = [\n",
    "    # \"a lay audience\",\n",
    "    \"people who are not science experts\",\n",
    "]\n",
    "\n",
    "user_relevance_task = [\n",
    "    \"\"\"Rewrite this summary to include a statement of how it is relevant for the audience. \\\n",
    "        Follow these steps to accomplish this: \\\n",
    "        \\n1. Think about why this might be relevant for the audience in the grand scheme of things.\\\n",
    "        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things, \\\n",
    "        add a sentence to inform the audience. Otherwise, keep it the same. \\\n",
    "        \\n3. Modify the summary if needed to reduce redundancy. \\\n",
    "        \\n4. Check if the content and language are appropriate for the audience. \\\n",
    "        If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \n",
    "        \\n5. Return the final version of the summary to be shown to the audience. \\\n",
    "        \\n6. Remove the backticks.\n",
    "        \\n\\nYour audience consists of\"\"\",\n",
    "]\n",
    "\n",
    "relevance_audience = [\n",
    "    \"seniors\",\n",
    "    \"people who enjoy sports\",\n",
    "    # \"people new to resistance training\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1: Carry over code from previous notebook to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "\n",
      "original summaries df columns: Index(['date', 'folder', 'article_title', 'choice', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "** Merged dataframe shape: (4, 20)\n",
      "['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'relevance task', 'full relevance task', 'people who enjoy sports', 'add relevance task 2', 'full add relevance task 2', 'seniors']\n",
      "Original summary time: 2023-06-12_2110\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "      <th>simple summary choice</th>\n",
       "      <th>audience</th>\n",
       "      <th>simplify task</th>\n",
       "      <th>full simplify task</th>\n",
       "      <th>simple summary</th>\n",
       "      <th>relevance task</th>\n",
       "      <th>full relevance task</th>\n",
       "      <th>people who enjoy sports</th>\n",
       "      <th>add relevance task 2</th>\n",
       "      <th>full add relevance task 2</th>\n",
       "      <th>seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study c...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein may help reduce the risk of fra...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein, particularly from dairy foods,...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein from dairy foods may reduce the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>A recent study found that older adults who consume a diet rich in calcium and protein have a low...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with p...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of a person's weight, according...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a per...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>Weight discrimination, or being treated unfairly because of one's weight, is a common problem th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         article_title  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "3  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       2   \n",
       "2       1   \n",
       "3       2   \n",
       "\n",
       "                                                                system_role  \\\n",
       "0  You are a journalist writing content based on science research articles.   \n",
       "1  You are a journalist writing content based on science research articles.   \n",
       "2  You are a journalist writing content based on science research articles.   \n",
       "3  You are a journalist writing content based on science research articles.   \n",
       "\n",
       "           model  \\\n",
       "0  gpt-3.5-turbo   \n",
       "1  gpt-3.5-turbo   \n",
       "2  gpt-3.5-turbo   \n",
       "3  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "3  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                                                                                             prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "               summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                               full summarization task  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study c...   \n",
       "1  Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study...   \n",
       "2  Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with p...   \n",
       "3  Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a per...   \n",
       "\n",
       "  simple summary choice                            audience  \\\n",
       "0                     1  people who are not science experts   \n",
       "1                     1  people who are not science experts   \n",
       "2                     1  people who are not science experts   \n",
       "3                     1  people who are not science experts   \n",
       "\n",
       "                                                                                         simplify task  \\\n",
       "0  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "1  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "2  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "3  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "\n",
       "                                                                                    full simplify task  \\\n",
       "0  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "1  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "2  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "3  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "\n",
       "                                                                                        simple summary  \\\n",
       "0  A recent study has found that a diet high in calcium and protein may help reduce the risk of fra...   \n",
       "1  A recent study found that older adults who consume a diet rich in calcium and protein have a low...   \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of a person's weight, according...   \n",
       "3  Weight discrimination, or being treated unfairly because of one's weight, is a common problem th...   \n",
       "\n",
       "                                                                                        relevance task  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                                   full relevance task  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                               people who enjoy sports  \\\n",
       "0  A recent study has found that a diet high in calcium and protein, particularly from dairy foods,...   \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...   \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...   \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...   \n",
       "\n",
       "                                                                                  add relevance task 2  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                             full add relevance task 2  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                                               seniors  \n",
       "0  A recent study has found that a diet high in calcium and protein from dairy foods may reduce the...  \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...  \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...  \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    chatbot_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    chatbot_id = chatbot_id if chatbot_id else iteration_id\n",
    "    print('chatbot_id:', chatbot_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            try:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "            except:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[str(prompt_number)]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            try:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "            except:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[str(prompt_number_relevance)]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = create_qna_df(qna_dict, chatbot_dict, iteration_id, chatbot_id)[iteration_id]\n",
    "    # qna_df.rename(columns={'summary': 'original summary'}, inplace=True)\n",
    "    # print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    # print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "    print(f'\\noriginal summaries df columns: {qna_df.columns}\\n')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results['full relevance task'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results['add relevance task 2'] = new_results[\"relevance task\"]\n",
    "        new_results['full add relevance task 2'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[0])\n",
    "        spreadsheet_column_names.append('add relevance task 2')\n",
    "        spreadsheet_column_names.append('full add relevance task 2')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_column_names]\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_column_names = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_column_names)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_column_names[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    qna_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return qna_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "# save = True\n",
    "save = False\n",
    "empty_columns = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# Merge the results\n",
    "try:\n",
    "    df_dict = merge_all_chaining_results2(\n",
    "        chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "        empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "        save_df=save, save_chatbot=save, \n",
    "            csv_path=folder_path,\n",
    "    )\n",
    "    print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "except Exception as error:\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    file = f.f_code.co_filename\n",
    "    print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "    print('Unable to merge results')\n",
    "    if save:\n",
    "        save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "        print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "# qna_dict = merge_all_chaining_results2(\n",
    "#     chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "#     empty_columns=empty_columns, chatbot_id=iteration_id,\n",
    "#         csv_path=folder_path,\n",
    "# )\n",
    "# print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "\n",
      "original summaries df columns: Index(['date', 'folder', 'article_title', 'choice', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "** Merged dataframe shape: (4, 20)\n",
      "['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'add relevance task people who enjoy sports', 'full relevance task people who enjoy sports', 'summary: people who enjoy sports', 'add relevance task seniors', 'full add relevance task seniors', 'summary: seniors']\n",
      "Original summary time: 2023-06-12_2110\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>...</th>\n",
       "      <th>add relevance task people who enjoy sports</th>\n",
       "      <th>full relevance task people who enjoy sports</th>\n",
       "      <th>summary: people who enjoy sports</th>\n",
       "      <th>add relevance task seniors</th>\n",
       "      <th>full add relevance task seniors</th>\n",
       "      <th>summary: seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in old...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         article_title  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "2                                      Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity   \n",
       "3                                      Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       2   \n",
       "2       1   \n",
       "3       2   \n",
       "\n",
       "                                                                system_role  \\\n",
       "0  You are a journalist writing content based on science research articles.   \n",
       "1  You are a journalist writing content based on science research articles.   \n",
       "2  You are a journalist writing content based on science research articles.   \n",
       "3  You are a journalist writing content based on science research articles.   \n",
       "\n",
       "           model  \\\n",
       "0  gpt-3.5-turbo   \n",
       "1  gpt-3.5-turbo   \n",
       "2  gpt-3.5-turbo   \n",
       "3  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...   \n",
       "3  Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...   \n",
       "\n",
       "                                                                                                                                               prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "\n",
       "                                                                                                              add relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                             full relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                                        summary: people who enjoy sports  \\\n",
       "0  A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in old...   \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...   \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...   \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...   \n",
       "\n",
       "                                                                                                                              add relevance task seniors  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                                         full add relevance task seniors  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                                                        summary: seniors  \n",
       "0  A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The ...  \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...  \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...  \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...  \n",
       "\n",
       "[4 rows x 20 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    chatbot_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    chatbot_id = chatbot_id if chatbot_id else iteration_id\n",
    "    print('chatbot_id:', chatbot_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            try:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "            except:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[str(prompt_number)]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            try:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "            except:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[str(prompt_number_relevance)]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = create_qna_df(qna_dict, chatbot_dict, iteration_id, chatbot_id)[iteration_id]\n",
    "    # qna_df.rename(columns={'summary': 'original summary'}, inplace=True)\n",
    "    # print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    # print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "    print(f'\\noriginal summaries df columns: {qna_df.columns}\\n')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            # \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results[f'full relevance task {relevance_audience_list[0]}'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results[f'add relevance task {relevance_audience_list[1]}'] = new_results[\"relevance task\"]\n",
    "        new_results[f'full add relevance task {relevance_audience_list[1]}'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(f'full relevance task {relevance_audience_list[0]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[0])\n",
    "        spreadsheet_column_names.append(f'add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(f'full add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_column_names]\n",
    "    new_results.rename(columns={\n",
    "        'relevance task': f'add relevance task {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[0]: f'summary: {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[1]: f'summary: {relevance_audience_list[1]}',\n",
    "    }, inplace=True)\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_column_names = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_column_names)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_column_names[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    qna_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return qna_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "# save = True\n",
    "save = False\n",
    "empty_columns = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Merge the results\n",
    "# try:\n",
    "#     df_dict = merge_all_chaining_results2(\n",
    "#         chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "#         empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         save_df=save, save_chatbot=save, \n",
    "#             csv_path=folder_path,\n",
    "#     )\n",
    "#     print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "# except Exception as error:\n",
    "#     exc_type, exc_obj, tb = sys.exc_info()\n",
    "#     f = tb.tb_frame\n",
    "#     lineno = tb.tb_lineno\n",
    "#     file = f.f_code.co_filename\n",
    "#     print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "#     print('Unable to merge results')\n",
    "#     if save:\n",
    "#         save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "#         print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "qna_dict = merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "    empty_columns=empty_columns, chatbot_id=iteration_id,\n",
    "        csv_path=folder_path,\n",
    ")\n",
    "print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>add relevance task people who enjoy sports</th>\n",
       "      <th>full relevance task people who enjoy sports</th>\n",
       "      <th>summary: people who enjoy sports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. This is important for sports enthusiasts who are aging and want to maintain their physical activity levels. The study suggests that inadequate intake of calcium and protein may contribute to fractures and falls in older adults, and a diet rich in these nutrients may help prevent these injuries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially relevant for sports enthusiasts who want to maintain their physical health and avoid injuries. The study showed that many people have inadequate calcium and protein intake, which increases their risk of fractures. By incorporating high calcium and protein foods into their diet, sports enthusiasts can reduce their risk of fractures and falls, and maintain their active lifestyle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, but not physical activity. Interestingly, individuals across the weight spectrum reported experiencing weight stigma. This study highlights the potential barriers that weight stigma can create for healthy behaviors, and suggests that reducing weight stigma could be a strategy to improve population health. This information is relevant for sports enthusiasts who may be interested in understanding how weight stigma can impact their overall health and well-being.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, regardless of BMI. Interestingly, there was no relationship found between weight stigma and physical activity. These findings suggest that weight stigma may be a barrier to healthy behaviors, and that weight-inclusive approaches to health promotion may be more effective. This study was conducted with a large, national census-matched sample of U.S. adults. As a sports enthusiast, understanding the impact of weight stigma on health behaviors can help you make informed decisions about your own health and well-being.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              add relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     full relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Think about why this might be relevant for the audience in the grand scheme of things.        \\n2. If it is not evident why the text is relevant for the audience in the grand scheme of things,         add a sentence to inform the audience. Otherwise, keep it the same.         \\n3. Modify the summary if needed to reduce redundancy.         \\n4. Check if the content and language are appropriate for the audience.         If it is suitable for the audience, keep it the same. If not, rewrite using terms appropriate for the audience. \\ \\n        \\n5. Return the final version of the summary to be shown to the audience.         \\n6. Remove the backticks.\\n        \\n\\nYour audience consists of people who enjoy sports   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   summary: people who enjoy sports  \n",
       "0                                                                                                                                                        A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in older adults. The study showed a 33% reduction in the risk of fractures of any type, a 46% reduction in hip fractures, and an 11% reduction in falls compared to the control group. This is important for sports enthusiasts who are aging and want to maintain their physical activity levels. The study suggests that inadequate intake of calcium and protein may contribute to fractures and falls in older adults, and a diet rich in these nutrients may help prevent these injuries.  \n",
       "1                                                                                                                                                                                                        A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures and falls in older adults. This is especially relevant for sports enthusiasts who want to maintain their physical health and avoid injuries. The study showed that many people have inadequate calcium and protein intake, which increases their risk of fractures. By incorporating high calcium and protein foods into their diet, sports enthusiasts can reduce their risk of fractures and falls, and maintain their active lifestyle.  \n",
       "2                 Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the International Journal of Obesity. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, but not physical activity. Interestingly, individuals across the weight spectrum reported experiencing weight stigma. This study highlights the potential barriers that weight stigma can create for healthy behaviors, and suggests that reducing weight stigma could be a strategy to improve population health. This information is relevant for sports enthusiasts who may be interested in understanding how weight stigma can impact their overall health and well-being.  \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found that weight stigma was linked to disordered eating, comfort eating, alcohol use, and sleep disturbance, regardless of BMI. Interestingly, there was no relationship found between weight stigma and physical activity. These findings suggest that weight stigma may be a barrier to healthy behaviors, and that weight-inclusive approaches to health promotion may be more effective. This study was conducted with a large, national census-matched sample of U.S. adults. As a sports enthusiast, understanding the impact of weight stigma on health behaviors can help you make informed decisions about your own health and well-being.  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_dict[iteration_id].filter(regex='who enjoy sports')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "\n",
      "original summaries df columns: Index(['date', 'folder', 'article_title', 'choice', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "** Merged dataframe shape: (4, 22)\n",
      "['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'relevance audience 1', 'add relevance task people who enjoy sports', 'full relevance task people who enjoy sports', 'summary: people who enjoy sports', 'relevance audience 2', 'add relevance task seniors', 'full add relevance task seniors', 'summary: seniors']\n",
      "Original summary time: 2023-06-12_2110\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>summarization task</th>\n",
       "      <th>full summarization task</th>\n",
       "      <th>summary</th>\n",
       "      <th>simple summary choice</th>\n",
       "      <th>audience</th>\n",
       "      <th>simplify task</th>\n",
       "      <th>full simplify task</th>\n",
       "      <th>simple summary</th>\n",
       "      <th>relevance audience 1</th>\n",
       "      <th>add relevance task people who enjoy sports</th>\n",
       "      <th>full relevance task people who enjoy sports</th>\n",
       "      <th>summary: people who enjoy sports</th>\n",
       "      <th>relevance audience 2</th>\n",
       "      <th>add relevance task seniors</th>\n",
       "      <th>full add relevance task seniors</th>\n",
       "      <th>summary: seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study c...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein may help reduce the risk of fra...</td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein, particularly from dairy foods,...</td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein from dairy foods may reduce the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>A recent study found that older adults who consume a diet rich in calcium and protein have a low...</td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...</td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with p...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of a person's weight, according...</td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...</td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>summarize for a LinkedIn post.</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...</td>\n",
       "      <td>Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a per...</td>\n",
       "      <td>1</td>\n",
       "      <td>people who are not science experts</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...</td>\n",
       "      <td>Weight discrimination, or being treated unfairly because of one's weight, is a common problem th...</td>\n",
       "      <td>people who enjoy sports</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...</td>\n",
       "      <td>seniors</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         article_title  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "3  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       2   \n",
       "2       1   \n",
       "3       2   \n",
       "\n",
       "                                                                system_role  \\\n",
       "0  You are a journalist writing content based on science research articles.   \n",
       "1  You are a journalist writing content based on science research articles.   \n",
       "2  You are a journalist writing content based on science research articles.   \n",
       "3  You are a journalist writing content based on science research articles.   \n",
       "\n",
       "           model  \\\n",
       "0  gpt-3.5-turbo   \n",
       "1  gpt-3.5-turbo   \n",
       "2  gpt-3.5-turbo   \n",
       "3  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in r...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "3  Weight stigma and health behaviors: evidence from the Eating in America Study. International Jou...   \n",
       "\n",
       "                                                                                             prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "               summarization task  \\\n",
       "0  summarize for a LinkedIn post.   \n",
       "1  summarize for a LinkedIn post.   \n",
       "2  summarize for a LinkedIn post.   \n",
       "3  summarize for a LinkedIn post.   \n",
       "\n",
       "                                                                               full summarization task  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIden...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  High calcium and protein diet may reduce fractures and falls in older adults: Study\\n\\nA study c...   \n",
       "1  Calcium and protein-rich diet reduces risk of hip fractures and falls in older adults\\n\\nA study...   \n",
       "2  Weight Stigma Linked to Poor Health Behaviors, Study Finds\\n\\nWeight stigma is associated with p...   \n",
       "3  Weight Stigma Linked to Poor Health Behaviors\\n\\nWeight stigma, or discrimination based on a per...   \n",
       "\n",
       "  simple summary choice                            audience  \\\n",
       "0                     1  people who are not science experts   \n",
       "1                     1  people who are not science experts   \n",
       "2                     1  people who are not science experts   \n",
       "3                     1  people who are not science experts   \n",
       "\n",
       "                                                                                         simplify task  \\\n",
       "0  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "1  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "2  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "3  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "\n",
       "                                                                                    full simplify task  \\\n",
       "0  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "1  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "2  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "3  If needed, rewrite the text using terms appropriate for the audience. If not keep it the same.  ...   \n",
       "\n",
       "                                                                                        simple summary  \\\n",
       "0  A recent study has found that a diet high in calcium and protein may help reduce the risk of fra...   \n",
       "1  A recent study found that older adults who consume a diet rich in calcium and protein have a low...   \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of a person's weight, according...   \n",
       "3  Weight discrimination, or being treated unfairly because of one's weight, is a common problem th...   \n",
       "\n",
       "      relevance audience 1  \\\n",
       "0  people who enjoy sports   \n",
       "1  people who enjoy sports   \n",
       "2  people who enjoy sports   \n",
       "3  people who enjoy sports   \n",
       "\n",
       "                                                            add relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                           full relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                      summary: people who enjoy sports  \\\n",
       "0  A recent study has found that a diet high in calcium and protein, particularly from dairy foods,...   \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...   \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...   \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...   \n",
       "\n",
       "  relevance audience 2  \\\n",
       "0              seniors   \n",
       "1              seniors   \n",
       "2              seniors   \n",
       "3              seniors   \n",
       "\n",
       "                                                                            add relevance task seniors  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                       full add relevance task seniors  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Foll...   \n",
       "\n",
       "                                                                                      summary: seniors  \n",
       "0  A recent study has found that a diet high in calcium and protein from dairy foods may reduce the...  \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can...  \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), accor...  \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behavi...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    chatbot_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    chatbot_id = chatbot_id if chatbot_id else iteration_id\n",
    "    print('chatbot_id:', chatbot_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            try:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "            except:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[str(prompt_number)]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            try:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "            except:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[str(prompt_number_relevance)]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = create_qna_df(qna_dict, chatbot_dict, iteration_id, chatbot_id)[iteration_id]\n",
    "    # qna_df.rename(columns={'summary': 'original summary'}, inplace=True)\n",
    "    # print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    # print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "    print(f'\\noriginal summaries df columns: {qna_df.columns}\\n')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance audience 1\",\n",
    "            \"relevance task\",\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results[f'full relevance task {relevance_audience_list[0]}'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results[f'add relevance task {relevance_audience_list[1]}'] = new_results[\"relevance task\"]\n",
    "        new_results[f'full add relevance task {relevance_audience_list[1]}'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        new_results['relevance audience 1'] = pd.Series(relevance_audience_list[0], index=new_results.index)\n",
    "        new_results['relevance audience 2'] = pd.Series(relevance_audience_list[1], index=new_results.index)\n",
    "        spreadsheet_column_names.append(f'full relevance task {relevance_audience_list[0]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[0])\n",
    "        spreadsheet_column_names.append('relevance audience 2')\n",
    "        spreadsheet_column_names.append(f'add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(f'full add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_column_names]\n",
    "    new_results.rename(columns={\n",
    "        'relevance task': f'add relevance task {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[0]: f'summary: {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[1]: f'summary: {relevance_audience_list[1]}',\n",
    "    }, inplace=True)\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_column_names = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_column_names)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_column_names[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    qna_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return qna_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "# save = True\n",
    "save = False\n",
    "empty_columns = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Merge the results\n",
    "# try:\n",
    "#     df_dict = merge_all_chaining_results2(\n",
    "#         chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "#         empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         save_df=save, save_chatbot=save, \n",
    "#             csv_path=folder_path,\n",
    "#     )\n",
    "#     print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "# except Exception as error:\n",
    "#     exc_type, exc_obj, tb = sys.exc_info()\n",
    "#     f = tb.tb_frame\n",
    "#     lineno = tb.tb_lineno\n",
    "#     file = f.f_code.co_filename\n",
    "#     print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "#     print('Unable to merge results')\n",
    "#     if save:\n",
    "#         save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "#         print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "qna_dict = merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "    empty_columns=empty_columns, chatbot_id=iteration_id,\n",
    "        csv_path=folder_path,\n",
    ")\n",
    "print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Processing text1_prompt00...\n",
      "\tNo previous simple prompts for text1_prompt00.\n",
      "\tNo previous relevance prompts for text1_prompt00.\n",
      "Processing text2_prompt00...\n",
      "\tNo previous simple prompts for text2_prompt00.\n",
      "\tNo previous relevance prompts for text2_prompt00.\n",
      "Processing text1_prompt00...\n",
      "Processing text2_prompt00...\n",
      "Original summaries DataFrame shape: (4, 12)\n",
      "\tOriginal summaries Dataframe columns: Index(['choice', 'date', 'folder', 'article_title', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "Simple summaries DataFrame shape: (4, 6)\n",
      "\tSimple summaries DataFrame columns: ['audience', 'full simplify task', 'original summary', 'simple summary', 'simple summary choice', 'simplify task']\n",
      "Relevance summaries DataFrame shape: (8, 6)\n",
      "\tRelevance summaries DataFrame columns: ['audience', 'full relevance task', 'preceding summary', 'relevance choice', 'relevance statement', 'relevance task']\n",
      "Unique relevance audience values: ['people who enjoy sports', 'seniors']\n",
      "\n",
      "original summaries df columns: Index(['date', 'folder', 'article_title', 'choice', 'system_role', 'model',\n",
      "       'text', 'prep step', 'summarization task', 'edit task',\n",
      "       'full summarization task', 'summary'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "** Merged dataframe shape: (4, 20)\n",
      "['article_title', 'choice', 'system_role', 'model', 'text', 'prep step', 'summarization task', 'full summarization task', 'summary', 'simple summary choice', 'audience', 'simplify task', 'full simplify task', 'simple summary', 'add relevance task people who enjoy sports', 'full relevance task people who enjoy sports', 'summary: people who enjoy sports', 'add relevance task seniors', 'full add relevance task seniors', 'summary: seniors']\n",
      "Original summary time: 2023-06-12_2110\n",
      "\n",
      "Completed merge_all_chaining_results!:)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>choice</th>\n",
       "      <th>system_role</th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>prep step</th>\n",
       "      <th>...</th>\n",
       "      <th>add relevance task people who enjoy sports</th>\n",
       "      <th>full relevance task people who enjoy sports</th>\n",
       "      <th>summary: people who enjoy sports</th>\n",
       "      <th>add relevance task seniors</th>\n",
       "      <th>full add relevance task seniors</th>\n",
       "      <th>summary: seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in old...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity</td>\n",
       "      <td>2</td>\n",
       "      <td>You are a journalist writing content based on science research articles.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...</td>\n",
       "      <td>Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...</td>\n",
       "      <td>Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         article_title  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled trial   \n",
       "2                                      Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity   \n",
       "3                                      Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity   \n",
       "\n",
       "   choice  \\\n",
       "0       1   \n",
       "1       2   \n",
       "2       1   \n",
       "3       2   \n",
       "\n",
       "                                                                system_role  \\\n",
       "0  You are a journalist writing content based on science research articles.   \n",
       "1  You are a journalist writing content based on science research articles.   \n",
       "2  You are a journalist writing content based on science research articles.   \n",
       "3  You are a journalist writing content based on science research articles.   \n",
       "\n",
       "           model  \\\n",
       "0  gpt-3.5-turbo   \n",
       "1  gpt-3.5-turbo   \n",
       "2  gpt-3.5-turbo   \n",
       "3  gpt-3.5-turbo   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...   \n",
       "1  Effect of dietary sources of calcium and protein on hip fractures and falls in older adults in residential care cluster randomised controlled tria...   \n",
       "2  Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...   \n",
       "3  Weight stigma and health behaviors: evidence from the Eating in America Study. International Journal of Obesity\\n\\nDiscussion\\nThe present study e...   \n",
       "\n",
       "                                                                                                                                               prep step  \\\n",
       "0  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "1  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "2  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "3  Think about why this might be relevant for the audience in the grand scheme of things.    \\nIdentify 1 or 2 key concepts from this article that wo...   \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "\n",
       "                                                                                                              add relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                             full relevance task people who enjoy sports  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                                        summary: people who enjoy sports  \\\n",
       "0  A recent study has found that a diet high in calcium and protein, particularly from dairy foods, may reduce the risk of fractures and falls in old...   \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...   \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...   \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...   \n",
       "\n",
       "                                                                                                                              add relevance task seniors  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                                         full add relevance task seniors  \\\n",
       "0  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "1  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "2  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "3  Rewrite this summary to include a statement of how it is relevant for the audience.         Follow these steps to accomplish this:         \\n1. Th...   \n",
       "\n",
       "                                                                                                                                        summary: seniors  \n",
       "0  A recent study has found that a diet high in calcium and protein from dairy foods may reduce the risk of fractures and falls in older adults. The ...  \n",
       "1  A recent study found that a diet rich in calcium and protein, particularly from dairy foods, can significantly reduce the risk of hip fractures an...  \n",
       "2  Weight stigma can negatively impact health behaviors, regardless of body mass index (BMI), according to a recent study published in the Internatio...  \n",
       "3  Weight stigma, or discrimination based on a person's weight, can negatively impact health behaviors, according to a recent study. The study found ...  \n",
       "\n",
       "[4 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chaining:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to feed to GPT for summarization.\n",
    "\n",
    "    Optional parameters:\n",
    "    --------------------\n",
    "    system_role : str\n",
    "        The role of the ChatGPT system in the conversation. Default is \"You are an expert at science communication.\"\n",
    "    temperature : float\n",
    "        Controls the randomness of responses. Lower values result in more predictable responses. Default is 0.7.\n",
    "    n_choices : int\n",
    "        Number of ChatGPT responses to generate. Default is 5.\n",
    "    max_tokens : int\n",
    "        Token limit for ChatGPT response. Default is 1000.\n",
    "    model : str\n",
    "        ChatGPT model to use. Default is \"gpt-3.5-turbo\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, folder_path, system_role=\"You are a helpful assistant.\", \n",
    "            model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000, \n",
    "        ):\n",
    "        self.text = text\n",
    "        self.folder = re.sub(r'(?:.*\\/)?(.*)$', r'\\1', folder_path)\n",
    "        self.system_role = system_role\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, task, text):\n",
    "        \"\"\"\n",
    "        Creates a prompt for ChatGPT with the given task and text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        text : str\n",
    "            The text to include in the ChatGPT prompt.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        \"\"\"\n",
    "        system_role = f'{self.system_role}'\n",
    "        user_input = f\"\"\"Given the following text delimited by triple backticks: ```{text}``` \\n {task}\"\"\"\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_input},]\n",
    "\n",
    "        print('\\tDone creating prompt')\n",
    "        return messages\n",
    "\n",
    "    def gpt(self, messages, n_choices, temperature):\n",
    "        \"\"\"\n",
    "        Sends a request to the ChatGPT API with the given messages.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        messages : list\n",
    "            A list of dictionaries representing the system and user messages in the prompt.\n",
    "        n_choices : int\n",
    "            Number of ChatGPT responses to generate.\n",
    "        temperature : float\n",
    "            Controls the randomness of responses. Lower values result in more predictable responses.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        response : dict\n",
    "            A dictionary representing the ChatGPT response.\n",
    "        \"\"\"\n",
    "        print('\\tSending request to GPT-3')\n",
    "        print(f'\\t\\tRequesting {n_choices} choices using {self.model}')\n",
    "        openai.api_key = os.getenv('api_openai')\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model, messages=messages, \n",
    "            temperature=temperature, \n",
    "            max_tokens=self.max_tokens,\n",
    "            n=n_choices\n",
    "            )\n",
    "        print('\\tDone sending request to GPT-3')\n",
    "        return response\n",
    "\n",
    "    def summarize(self, task, prep_step=None, edit_task=None, n_choices=5):\n",
    "        \"\"\"\n",
    "        Generates summaries from the text using ChatGPT.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        task : str\n",
    "            The task to include in the ChatGPT prompt.\n",
    "        prep_step : str, optional\n",
    "            A preparatory step for the task, if applicable.\n",
    "        edit_task : str, optional\n",
    "            The final step for the task, if applicable.\n",
    "        n_choices : int, optional\n",
    "            Number of ChatGPT responses to generate. Default is 5.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        qna : dict\n",
    "            A dictionary representing the summarization task and the generated summaries.\n",
    "        \"\"\"\n",
    "        chatbot = Chaining(self.text, self.folder)\n",
    "        full_task = f'{prep_step} {task} {edit_task}'\n",
    "        prompt = chatbot.create_prompt(full_task, self.text)\n",
    "        firstline_pattern = r'\\s?(\\S*)(\\n*)(.+)'\n",
    "        title = re.match(firstline_pattern, self.text)[0]\n",
    "        self.qna = dict() \n",
    "        self.qna['date'] = datetime.now().strftime(\"%Y-%m-%d %H%M\")\n",
    "        self.qna['folder'] = self.folder\n",
    "        self.qna['article_title'] = title\n",
    "        self.qna['system_role'] = self.system_role\n",
    "        self.qna['model'] = self.model\n",
    "        self.qna[f'text'] = self.text\n",
    "        self.qna['prep step'] = prep_step\n",
    "        self.qna['summarization task'] = task\n",
    "        self.qna['edit task'] = edit_task\n",
    "        self.qna['full summarization task'] = full_task\n",
    "        self.summaries_dict = dict()\n",
    "        self.article_title = title\n",
    "        self.response_regex = r'response_(.*)'\n",
    "        self.simple_summary_dict = dict()\n",
    "        self.relevance_dict = dict()\n",
    "        self.n_previous_prompts = dict()\n",
    "\n",
    "        try:\n",
    "            response = chatbot.gpt(prompt, n_choices=n_choices, temperature=self.temperature)\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**API request failed for `.summarize()`**')\n",
    "            return self.qna\n",
    "        try:\n",
    "            for index, choice in enumerate(response.choices):\n",
    "                self.summaries_dict[f'response_{\"{:02d}\".format(index+1)}'] = choice[\"message\"][\"content\"]\n",
    "            self.qna.setdefault('summary', [])\n",
    "            self.qna['summary'].extend([value for value in self.summaries_dict.values()])\n",
    "            # self.summaries_dict['prep_step'] = prep_step\n",
    "            # self.summaries_dict['task'] = task\n",
    "            # self.summaries_dict['edit_task'] = edit_task\n",
    "            # self.summaries_dict['prompt'] = full_task\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print('\\t**Error with response parsing**')\n",
    "\n",
    "\n",
    "    def simplify(self, simplify_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        simplify_iteration = len(self.simple_summary_dict) + 1 \n",
    "        self.n_previous_prompts['simply_summary'] = len(self.simple_summary_dict)\n",
    "        self.simple_summary_dict[simplify_iteration] = dict()\n",
    "        if simplify_iteration == None:\n",
    "            simplify_iteration = 1\n",
    "        full_simplify_task = f'{simplify_task} {audience}'\n",
    "        print('simplify_iteration: ', simplify_iteration)\n",
    "        print('Task:', full_simplify_task)\n",
    "        summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(self.response_regex, rf'simple_summary\\1', key)\n",
    "            print(f'\\t\\t...Preparing to summarize {key}')\n",
    "            simplify_prompt = self.create_prompt(full_simplify_task, self.summaries_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(simplify_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.simplify()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.simple_summary_dict[simplify_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.simple_summary_dict[simplify_iteration][key][index] = {\n",
    "                        'simple summary choice': index+1, \n",
    "                        'simplify task': simplify_task,\n",
    "                        'audience': audience,\n",
    "                        'full simplify task': f'{simplify_task} {\"for\" if audience else \"\"} {audience}',\n",
    "                        'simple summary': choice[\"message\"][\"content\"],\n",
    "                        'original summary': self.summaries_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Summary given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.simple_summary_dict[simplify_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for summary request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.simplify()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.simple_summary_dict\n",
    "    \n",
    "    def add_relevance(self, relevance_task, audience, \n",
    "                    model=\"gpt-3.5-turbo\", temperature=0.0, n_choices=1, summary_type='original',\n",
    "                    # relevance_iteration=None, \n",
    "                    pause_per_request=0\n",
    "                    ):\n",
    "        relevance_iteration = len(self.relevance_dict) + 1 \n",
    "        self.n_previous_prompts['relevance'] = len(self.relevance_dict)\n",
    "        self.relevance_dict[relevance_iteration] = dict()\n",
    "        if relevance_iteration == None:\n",
    "            relevance_iteration = 1\n",
    "        full_relevance_task = f'{relevance_task} {audience}'\n",
    "        print('relevance_iteration: ', relevance_iteration)\n",
    "        print('Task:', full_relevance_task)\n",
    "        if summary_type=='original':\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.response_regex, key)]\n",
    "            summary_regex = self.response_regex\n",
    "        else:\n",
    "            self.simple_summary_response_regex = r'simple_summary_(.*)'\n",
    "            summaries_keys = [key for key in self.summaries_dict.keys() if re.match(self.simple_summary_response_regex, key)]\n",
    "            summary_regex = self.simple_summary_response_regex\n",
    "        print('summaries_keys: \\n\\t', summaries_keys)\n",
    "        input_summary_dict = self.summaries_dict if summary_type=='original' else self.simple_summary_dict\n",
    "        for key in summaries_keys:\n",
    "            new_key = re.sub(summary_regex, rf'relevance_\\1', key)\n",
    "            print(f'\\t\\t...Preparing to add relevance to {key}')\n",
    "            relevance_prompt = self.create_prompt(full_relevance_task, input_summary_dict[key])\n",
    "            try:\n",
    "                response = self.gpt(relevance_prompt, n_choices=n_choices, temperature=temperature)\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                print('\\t**API request failed for `.add_relevance()`**')\n",
    "                return self.qna\n",
    "            try:\n",
    "                self.relevance_dict[relevance_iteration][key] = dict()\n",
    "                for index, choice in enumerate(response.choices):\n",
    "                    self.relevance_dict[relevance_iteration][key][index] = {\n",
    "                        'relevance choice': index+1, \n",
    "                        'relevance task': relevance_task,\n",
    "                        'audience': audience,\n",
    "                        'full relevance task': full_relevance_task,\n",
    "                        'relevance statement': choice[\"message\"][\"content\"],\n",
    "                        'preceding summary': input_summary_dict[key]\n",
    "                    }\n",
    "                    print(f'\\t...Relevance statement given')\n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                filename = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "                self.relevance_summary_dict[relevance_iteration][new_key] = response\n",
    "                print(f'\\t...Error parsing response for relevance request')\n",
    "            if pause_per_request > 0:\n",
    "                print(f'[.add_relevance()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                time.sleep(pause_per_request)\n",
    "        return self.relevance_dict\n",
    "    \n",
    "def batch_summarize_chain(text_dict, folder_path, prep_step, summarize_task, edit_task, chaining_bot_dict, iteration_id, \n",
    "    system_role=None, temperature=0.7, pause_per_request=0, n_choices=5,\n",
    "    save_outputs=False, csv_path=folder_path, pickle_path=folder_path, json_path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Summarize multiple texts using the same prompts.\n",
    "    Parameters:\n",
    "        - text_dict (dict) A dictionary containing the text data to be summarized. \n",
    "            The keys of the dictionary are the text IDs and the values are the full texts.\n",
    "        - prep_step, summarize_task, edit task (list)\n",
    "        - qna_dict: Dictionary to store the input and outputs.\n",
    "        - iteration_id (int, float, or string): Unique ID serving as the key for results in the qna_dict\n",
    "\n",
    "        iteration_id: int, float or string\n",
    "            A unique identifier for the current iteration.\n",
    "        temperature: float, optional (default=0.7)\n",
    "            The level of \"creativity\" to use when generating summaries. Higher temperatures will result in more diverse summaries, but may also result in lower quality summaries.\n",
    "        pause_per_request: int or float, optional (default=0)\n",
    "            The number of seconds to pause between requests to avoid exceeding API rate limits. Defaults to 0, which means no pause.\n",
    "        save_outputs: bool, optional (default=False)\n",
    "            Whether to save the outputs of the summarization process to disk.\n",
    "        filename: str, optional (default=None)\n",
    "            The name of the file to save the outputs to. If no filename is specified, a default filename will be used.\n",
    "        csv_path: str, optional \n",
    "            The path to the directory where CSV output files will be saved. Defaults to the 'output' folder in the project directory.\n",
    "        pickle_path: str, optional \n",
    "            The path to the directory where pickle output files will be saved. Defaults to the 'pickles' folder in the project directory.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chaining_bot_dict: dict\n",
    "            A dictionary containing the Chaining instances. \n",
    "                The keys of the dictionary are the iteration IDs and the values are dictionaries whose\n",
    "                values are the Chaining instances.\n",
    "\n",
    "    \"\"\"\n",
    "    prompts_df = pd.DataFrame(product(prep_step, summarize_task, edit_task), \n",
    "        columns=['prep_step', 'summarize_task', 'edit_task'])\n",
    "\n",
    "    chaining_bot_dict[iteration_id] = dict()\n",
    "    for key in text_dict:\n",
    "        text = text_dict[key]\n",
    "        for index in prompts_df.index:\n",
    "            print(f'**Text #{key} prompt #{index} of {prompts_df.index.max()}**')\n",
    "            task = prompts_df.loc[index, 'summarize_task']\n",
    "            prep_step = prompts_df.loc[index, 'prep_step']\n",
    "            edit_task = prompts_df.loc[index, 'edit_task']\n",
    "            try:\n",
    "                print('Creating Chaining class instance')\n",
    "                chatbot = Chaining(\n",
    "                    text, folder_path=folder_path, temperature=temperature, system_role=system_role)\n",
    "                print('Chaining class instance created')\n",
    "                chatbot.summarize(\n",
    "                    task=task, prep_step=prep_step, edit_task=edit_task, n_choices=n_choices\n",
    "                    )\n",
    "                chaining_bot_dict[iteration_id][f'text{key}_prompt{\"{:02d}\".format(index)}'] = chatbot\n",
    "                print('\\t...Success!')\n",
    "                if pause_per_request > 0:\n",
    "                    print(f'[batch_summarize()] Sleeping {pause_per_request} sec to avoid exceeding API rate limit')\n",
    "                    time.sleep(pause_per_request) # Account for API rate limit of 3 API requests/limit \n",
    "            except Exception as error:\n",
    "                exc_type, exc_obj, tb = sys.exc_info()\n",
    "                f = tb.tb_frame\n",
    "                lineno = tb.tb_lineno\n",
    "                file = f.f_code.co_filename\n",
    "                print(\"An error occurred on line\", lineno, \"in\", file, \":\", error)\n",
    "                print('\\t...Error making chatbot request')\n",
    "                break\n",
    "    if save_outputs:\n",
    "        try:\n",
    "            save_instance_to_dict(\n",
    "                chaining_bot_dict[iteration_id], \n",
    "                description=f'batch_Chaining_attributes_initial',\n",
    "                ext=None, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[batch_summarize_chain()] Unable to save API response')\n",
    "\n",
    "    return chaining_bot_dict\n",
    "\n",
    "def create_qna_df(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=None, \n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create DataFrame from initial ChatGPT summaries.\n",
    "    \"\"\"\n",
    "    dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        dfs_list.append(pd.DataFrame(\n",
    "            chatbot_dict[chatbot_id][chatbot_key].qna, \n",
    "            index=[choice for choice in range(1, len(chatbot_dict[chatbot_id][chatbot_key].qna['summary'])+1)])\n",
    "            )\n",
    "    \n",
    "    qna_df = pd.concat(dfs_list).reset_index(names=['choice'])\n",
    "    columns = qna_df.columns.tolist()\n",
    "    columns.remove('choice')\n",
    "    columns.insert(3, 'choice') # Move 'choice' column\n",
    "\n",
    "    # qna_df['date'] = pd.Series('2023-06-12', index=qna_df.index)\n",
    "    # columns.insert(0, 'date')\n",
    "\n",
    "    qna_dict[iteration_id] = qna_df[columns]\n",
    "    print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    print(f'\\tOriginal summaries Dataframe columns: {qna_df.columns}')\n",
    "    return qna_dict\n",
    "\n",
    "def spreadsheet_columns(qna_dict, chatbot_dict, iteration_id, chatbot_id=None,\n",
    "    save=False, filename=None, path=folder_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Update column names to include corresponding column in a spreadsheet (e.g. A, B, C)\n",
    "    \"\"\"\n",
    "    qna_dict = create_qna_df(\n",
    "        qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, \n",
    "        )\n",
    "    qna_dict[iteration_id]['date'] = qna_dict[iteration_id]['date'].str.replace(r'_\\d*', r'', regex=True)\n",
    "    spreadsheet_columns = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "    qna_dict[iteration_id].columns = [\n",
    "        f'{spreadsheet_columns[index]}: {column}' for index, column in enumerate(qna_dict[iteration_id].columns)\n",
    "        ]\n",
    "    str_columns = qna_dict[iteration_id].dtypes[qna_dict[iteration_id].dtypes == 'O'].index.tolist()\n",
    "    for column in str_columns:\n",
    "        qna_dict[iteration_id][column] = qna_dict[iteration_id][column].str.strip()\n",
    "    if save:\n",
    "        description = filename if filename else 'batch_Chaining_summaries_initial'\n",
    "        try:\n",
    "            save_csv(\n",
    "                qna_dict[iteration_id], filename=description, append_version=True,\n",
    "                path=path, index=False\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            file = f.f_code.co_filename\n",
    "            print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "            print('[spreadsheet_columns()] Unable to save original summaries DataFrame')\n",
    "    return qna_dict\n",
    "\n",
    "def prompt_chaining_dict(simplify_prompts, audience, simple_summaries_dict, chaining_bot_dict, iteration_id,\n",
    "    chatbot_id=None, n_choices=None, pause_per_request=0,\n",
    "    prompt_column='simplify', \n",
    "    # simplify_iteration=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Simplify or add context to a summary.\n",
    "    \"\"\"\n",
    "    chatbot_id = chatbot_id if chatbot_id else iteration_id\n",
    "    print('chatbot_id:', chatbot_id)\n",
    "    prompts_df = pd.DataFrame(product(simplify_prompts, audience), columns=[prompt_column, 'audience'])\n",
    "    if n_choices == None:\n",
    "        n_choices = 1 if prompt_column == 'simplify' else 5\n",
    "    print('n_choices:', n_choices)\n",
    "\n",
    "    simple_summaries_master_list = []\n",
    "    for text_prompt_key in chaining_bot_dict.keys():\n",
    "        print(f'**{text_prompt_key}')\n",
    "\n",
    "        for index in prompts_df.index:\n",
    "            prompt = prompts_df.loc[index, prompt_column]\n",
    "            audience = prompts_df.loc[index, 'audience']\n",
    "            if prompt_column == 'simplify':\n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].simplify(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            else: \n",
    "                summary_dict = chaining_bot_dict[text_prompt_key].add_relevance(\n",
    "                    prompt, audience, n_choices=n_choices, pause_per_request=pause_per_request, \n",
    "                    )\n",
    "            simple_summaries_master_list.append(summary_dict)\n",
    "  \n",
    "    simple_summaries_dict[iteration_id] = simple_summaries_master_list\n",
    "    return simple_summaries_dict\n",
    "\n",
    "def merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id, \n",
    "    empty_columns=None, pivot=True, validate=None,\n",
    "    chatbot_id=None, save_df=False, save_chatbot=False, \n",
    "    csv_path=folder_path,\n",
    "    pickle_path=None,\n",
    "    json_path=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a dataframe of original, 'simple', 'relevance' summaries from a Chaining object.\n",
    "    Merge it with the original summaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - chain_results_dict (dict): dictionary of DataFrames.\n",
    "        - chatbot_dict (dict): dictionary of Chaining objects.\n",
    "        - iteration_id (int, float, or string): iteration_id (dict key) of the chatbot_dict to process.\n",
    "        - empty_columns (Bool, int, or dict): dictionary of empty columns to add to the DataFrame. \n",
    "            If True or 1, default dictionary is used.\n",
    "            If False or 0, no empty columns are added.\n",
    "        - pivot (Bool): whether to pivot the relevance summaries DataFrame. Default is True.\n",
    "        - validate (str): Argument to pass to pd.merge() to validate the merge.\n",
    "        - chatbot_id (int, float, or string): chatbot_id (dict key) of the chatbot_dict to process.\n",
    "        - save_df, save_chatbot (Bool): whether to save the DataFrame and chatbot_dict.\n",
    "        - csv_path, pickle_path, and json_path (raw string or string): Location to save the \n",
    "            outputs. Must provide csv_path to save; pickle_path and json_path are optional and \n",
    "            default to the same as csv_path if not provided.\n",
    "    \"\"\"\n",
    "    df_list_simple = []\n",
    "    df_list_relevance = []\n",
    "    qna_dfs_list = []\n",
    "    chatbot_id = iteration_id if chatbot_id == None else chatbot_id\n",
    "    for chatbot_key in chatbot_dict[chatbot_id].keys():\n",
    "        print(f'Processing {chatbot_key}...')\n",
    "        try: \n",
    "            n_previous_prompts_simple = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['simple']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_simple}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_simple = 0\n",
    "            print(f'\\tNo previous simple prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "        try: \n",
    "            n_previous_prompts_relevance = chatbot_dict[chatbot_id][chatbot_key].previous_n_prompts['relevance']\n",
    "            print(f'\\tNumber of previous relevance prompts: {n_previous_prompts_relevance}', end='.')\n",
    "        except:\n",
    "            n_previous_prompts_relevance = 0\n",
    "            print(f'\\tNo previous relevance prompts for {chatbot_key}', end='.')\n",
    "        print('')\n",
    "            \n",
    "        qna_dfs_list.append(pd.DataFrame(chatbot_dict[chatbot_id][chatbot_key].qna).reset_index(names=['choice']))\n",
    "\n",
    "        # create results dictionaries that only grabs the results of the new prompts instead of all\n",
    "        results_dict_simple = dict()\n",
    "        total_n_prompts_simple = len(chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict)\n",
    "        for prompt_number in range(n_previous_prompts_simple+1, total_n_prompts_simple+1):\n",
    "            try:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[prompt_number]\n",
    "            except:\n",
    "                results_dict_simple[prompt_number] = chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict[str(prompt_number)]\n",
    "        chatbot_dict[chatbot_id][chatbot_key].simple_summary_dict\n",
    "\n",
    "        results_dict_relevance = dict()\n",
    "        total_n_prompts_relevance = len(chatbot_dict[chatbot_id][chatbot_key].relevance_dict)\n",
    "        for prompt_number_relevance in range(n_previous_prompts_relevance+1, total_n_prompts_relevance+1):\n",
    "            # print(f'\\tAppending results for prompt {prompt_number_relevance} of {total_n_prompts_relevance}')\n",
    "            try:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[prompt_number_relevance]\n",
    "            except:\n",
    "                results_dict_relevance[prompt_number_relevance] = chatbot_dict[chatbot_id][chatbot_key].relevance_dict[str(prompt_number_relevance)]\n",
    "\n",
    "        for iteration_key_simple in results_dict_simple.keys():\n",
    "            response_keys_simple = sorted([text_prompt_key for text_prompt_key in results_dict_simple[iteration_key_simple].keys()])\n",
    "            # print(f'\\tAppending results for {iteration_key_simple}: ', end='')\n",
    "\n",
    "            for response_key_simple in response_keys_simple:\n",
    "                df_list_simple.append(pd.DataFrame(results_dict_simple[iteration_key_simple][response_key_simple]).transpose())\n",
    "        for iteration_key_relevance in results_dict_relevance.keys():\n",
    "            response_keys_relevance = sorted([text_prompt_key for text_prompt_key in results_dict_relevance[iteration_key_relevance].keys()])\n",
    "            for response_key_relevance in response_keys_relevance:\n",
    "                df_list_relevance.append(pd.DataFrame(results_dict_relevance[iteration_key_relevance][response_key_relevance]).transpose())\n",
    "    \n",
    "    simple_summary_df = pd.concat(df_list_simple)\n",
    "    relevance_df = pd.concat(df_list_relevance)\n",
    "    qna_df = create_qna_df(qna_dict, chatbot_dict, iteration_id, chatbot_id)[iteration_id]\n",
    "    # qna_df.rename(columns={'summary': 'original summary'}, inplace=True)\n",
    "    # print(f'Original summaries DataFrame shape: {qna_df.shape}')\n",
    "    # print(f'Original summaries Dataframe columns: {qna_df.columns}')\n",
    "    print('Simple summaries DataFrame shape:', simple_summary_df.shape)\n",
    "    print(f'\\tSimple summaries DataFrame columns: {[col for col in simple_summary_df.columns]}')\n",
    "    print('Relevance summaries DataFrame shape:', relevance_df.shape)\n",
    "    print(f'\\tRelevance summaries DataFrame columns: {[col for col in relevance_df.columns]}')\n",
    "\n",
    "    relevance_audience_list = sorted(relevance_df.audience.unique().tolist())\n",
    "    print(f'Unique relevance audience values: {relevance_audience_list}')\n",
    "    print(f'\\noriginal summaries df columns: {qna_df.columns}\\n')\n",
    "\n",
    "    new_results = qna_df.merge(\n",
    "        simple_summary_df, how='right',\n",
    "        right_on='original summary',\n",
    "        left_on='summary',\n",
    "        validate=validate\n",
    "        ).drop(columns='original summary')\n",
    "    if pivot == False:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience simplify\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"audience relevance\",\n",
    "            \"relevance task\",\n",
    "            \"full relevance task\",\n",
    "            \"relevance statement\"\n",
    "        ]  \n",
    "\n",
    "        validate=None\n",
    "        \n",
    "        print(f'DataFrame shape after merging with simple summaries: {new_results.shape}')\n",
    "        print(f'\\tColumns after merging with simple summaries: {[col for col in new_results.columns]}')\n",
    "        new_results= new_results.merge(\n",
    "            relevance_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary', validate=validate\n",
    "            ).drop(columns='preceding summary')\n",
    "    else:\n",
    "        spreadsheet_column_names = [\n",
    "            \"article_title\",\n",
    "            \"choice\",\n",
    "            \"system_role\",\n",
    "            \"model\",\n",
    "            \"text\",\n",
    "            \"prep step\",\n",
    "            \"summarization task\",\n",
    "            \"full summarization task\",\n",
    "            \"summary\",\n",
    "            \"simple summary choice\",\n",
    "            \"audience\",\n",
    "            \"simplify task\",\n",
    "            \"full simplify task\",\n",
    "            \"simple summary\",\n",
    "            \"relevance task\",\n",
    "            # \"full relevance task\"\n",
    "        ] \n",
    "        relevance_pivot_df = relevance_df.pivot(\n",
    "            columns=['audience'],\n",
    "            values='relevance statement',\n",
    "            index=['preceding summary', 'relevance task',]\n",
    "        ).sort_index().reset_index()\n",
    "        new_results = new_results.merge(\n",
    "            relevance_pivot_df, how='outer', suffixes=(' simplify', ' relevance'),\n",
    "            left_on='summary', right_on='preceding summary',\n",
    "            validate='m:1' if validate else None\n",
    "        ).drop(columns='preceding summary')\n",
    "        new_results[f'full relevance task {relevance_audience_list[0]}'] = new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[0]}')\n",
    "        new_results[f'add relevance task {relevance_audience_list[1]}'] = new_results[\"relevance task\"]\n",
    "        new_results[f'full add relevance task {relevance_audience_list[1]}'] =new_results['relevance task'].apply(lambda x: f'{x} {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(f'full relevance task {relevance_audience_list[0]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[0])\n",
    "        spreadsheet_column_names.append(f'add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(f'full add relevance task {relevance_audience_list[1]}')\n",
    "        spreadsheet_column_names.append(relevance_audience_list[1])\n",
    "        \n",
    "    new_results = new_results[spreadsheet_column_names]\n",
    "    new_results.rename(columns={\n",
    "        'relevance task': f'add relevance task {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[0]: f'summary: {relevance_audience_list[0]}',\n",
    "        relevance_audience_list[1]: f'summary: {relevance_audience_list[1]}',\n",
    "    }, inplace=True)\n",
    "    if empty_columns:\n",
    "        if pivot == False:\n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    \"top simple summary\": \"U\",\n",
    "                }\n",
    "        else:           \n",
    "            if (type(empty_columns) != dict):\n",
    "                empty_columns = {\n",
    "                    # \"choice numnber\": \"C\",\n",
    "                    \"original summary content rating\": \"K\",\n",
    "                    \"original summary language rating\": \"L\",\n",
    "                    \"top summary\": \"M\",\n",
    "                    \"simple summary content rating\": \"S\",\n",
    "                    \"simple summary language rating\": \"T\",\n",
    "                    'top simple summary': 'u',\n",
    "                    # 'full add relevance task': 'w',\n",
    "                    'added relevance content rating': 'y',\n",
    "                    'added relevance language rating': 'z',\n",
    "                    'top added relevance': 'aa',\n",
    "                }\n",
    "        print(f'Merged DataFrame shape: {new_results.shape}')\n",
    "        print('\\nColumns before adding empty columns:', [column for column in new_results.columns])\n",
    "        print('Inserting empty columns...', end='\\n\\t')\n",
    "        spreadsheet_column_names = [letter for letter in string.ascii_uppercase]+['A'+letter for letter in string.ascii_uppercase]\n",
    "        alphabet_dict = {char:idx for idx, char in enumerate(spreadsheet_column_names)}\n",
    "        for column_name, column_number in empty_columns.items():\n",
    "            empty_column_loc = alphabet_dict[empty_columns[column_name].upper()] -1\n",
    "            new_results.insert(loc=empty_column_loc, column=column_name, value='')\n",
    "            print(f'{empty_columns[column_name].upper()} ({empty_column_loc}): {column_name}', end=', ')\n",
    "        new_results.columns = [\n",
    "            f'{spreadsheet_column_names[index+1]}: {column}' for index, column in enumerate(new_results.columns)\n",
    "            ]\n",
    "\n",
    "    print(f'\\n** Merged dataframe shape:', new_results.shape)\n",
    "    print([column for column in new_results.columns])\n",
    "    qna_dict[iteration_id] = new_results\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "    except:\n",
    "        description_tag=''\n",
    "    try:\n",
    "        original_summary_time = next(iter(chatbot_dict[chatbot_id].values())).date_created\n",
    "        description_tag = f'_{original_summary_time}_updated'\n",
    "        print(f'Original summary time: {original_summary_time}')\n",
    "    except:\n",
    "        description_tag=''\n",
    "    if save_df:\n",
    "        try:\n",
    "            save_output(\n",
    "                qna_dict[iteration_id], \n",
    "                description=f'batch_Chaining_summaries{description_tag}',\n",
    "                csv_path=csv_path, pickle_path=pickle_path)\n",
    "            print('')\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save DataFrame')\n",
    "    if save_chatbot:\n",
    "        json_path = csv_path if json_path is None else json_path\n",
    "        try:\n",
    "            print('Saving Chaining object (chatbot)...')\n",
    "            save_instance_to_dict(\n",
    "                chatbot_dict[chatbot_id], \n",
    "                description=f'batch_Chaining_attributes{description_tag}',\n",
    "                pickle_path=pickle_path, json_path=json_path\n",
    "                )\n",
    "        except Exception as error:\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "            print(f'Unable to save chatbot')\n",
    "            \n",
    "    return qna_dict\n",
    "\n",
    "# Set parameters\n",
    "iteration_id = 1\n",
    "n_choices = 1\n",
    "pause_per_request=0\n",
    "chatbot_id = iteration_id\n",
    "save_outputs = False\n",
    "# save = True\n",
    "save = False\n",
    "empty_columns = False\n",
    "\n",
    "# # Create initial summaries\n",
    "# chaining_dict = batch_summarize_chain(\n",
    "#     text_dict, folder_path, prep_step, summarize_task, edit_task, chatbot_dict,\n",
    "#     system_role=system_role, \n",
    "#     n_choices=n_choices, pause_per_request=pause_per_request,\n",
    "#     iteration_id=iteration_id, save_outputs=save_outputs\n",
    "#     )\n",
    "qna_dict = spreadsheet_columns(\n",
    "    qna_dict, chatbot_dict, iteration_id, chatbot_id=chatbot_id, save=save\n",
    "    )\n",
    "\n",
    "# # Create simple summaries\n",
    "# audience = simplify_audience\n",
    "# simple_summaries = prompt_chaining_dict(user_simplify_task, simplify_audience, simple_summaries_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id,\n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Add relevance\n",
    "# relevance = prompt_chaining_dict(user_relevance_task, relevance_audience, relevance_dict, \n",
    "#     chatbot_dict[chatbot_id], iteration_id, prompt_column='relevance', \n",
    "#     n_choices=1, pause_per_request=pause_per_request, chatbot_id=chatbot_id\n",
    "#     )\n",
    "\n",
    "# # Merge the results\n",
    "# try:\n",
    "#     df_dict = merge_all_chaining_results2(\n",
    "#         chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "#         empty_columns=empty_columns, chatbot_id=chatbot_id,\n",
    "#         save_df=save, save_chatbot=save, \n",
    "#             csv_path=folder_path,\n",
    "#     )\n",
    "#     print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "# except Exception as error:\n",
    "#     exc_type, exc_obj, tb = sys.exc_info()\n",
    "#     f = tb.tb_frame\n",
    "#     lineno = tb.tb_lineno\n",
    "#     file = f.f_code.co_filename\n",
    "#     print(f'An error occurred on line {lineno} in {file}: {error}')\n",
    "#     print('Unable to merge results')\n",
    "#     if save:\n",
    "#         save_instance_to_dict(chatbot_dict[chatbot_id], ext=None, json_path=folder_path)\n",
    "#         print(f'\\nCould not merge; saved Chaining instances as JSON.')\n",
    "qna_dict = merge_all_chaining_results2(\n",
    "    chatbot_dict, qna_dict, iteration_id=iteration_id, pivot=True,\n",
    "    empty_columns=empty_columns, chatbot_id=iteration_id,\n",
    "        csv_path=folder_path,\n",
    ")\n",
    "print(f'\\nCompleted merge_all_chaining_results!:)')\n",
    "\n",
    "qna_dict[iteration_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
